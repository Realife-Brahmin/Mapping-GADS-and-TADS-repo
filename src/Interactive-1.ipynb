{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted .conda (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1983a93a-1ebc-4a57-9c6c-2562b45751aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d275fe15-597b-4917-a05c-5994f70a8bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # pylint: disable=undefined-variable line-too-long invalid-name\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14a8408-7f4c-491f-ae5f-7e6efd855d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TADS db before filtering: 301152, 47\n",
      "There are 304 unique companies owning tlines in the entire TADS database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-081c3e414d19>:3: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfTads0 = pd.read_csv(tadsFileAddr)\n"
     ]
    }
   ],
   "source": [
    "tadsFileAddr = os.path.join(rawDataFolder, \"TADS 2024 AC Inventory.csv\")\n",
    "dfTads0 = pd.read_csv(tadsFileAddr)\n",
    "sizeTads0 = dfTads0.shape\n",
    "print(f\"Size of TADS db before filtering: {sizeTads0[0]}, {sizeTads0[1]}\")\n",
    "companyNamesTads0 = set(dfTads0.CompanyName)\n",
    "numCompaniesTads0 = len(companyNamesTads0)\n",
    "print(f\"There are {numCompaniesTads0} unique companies owning tlines in the entire TADS database.\")\n",
    "# display(dftads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e19bda-8a1f-44a6-9a86-c8618993a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\tlines-near-chicago-ohare-raw.xlsx\n",
      "Size of velocity suite db before any filtering: 524, 21\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "veloFileAddr = os.path.join(rawDataFolder, \"tlines-near-chicago-ohare-raw.xlsx\") # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16248bc-f92a-442e-a331-16de2fbe8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': 459, 21\n",
      "There are 6 named companies owning the tlines near chicago-ohare\n",
      "Their names are:\n",
      "{'Undetermined Company', 'Northern Indiana Public Service Co LLC', 'Northern Municipal Power Agency', 'AmerenIP', 'American Transmission Co LLC', 'Commonwealth Edison Co'}\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69419489-b8a7-46fb-b392-f57a0933e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's see how many tlines are owned by these 6 companies in the entire TADS database:\n",
      "But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\n",
      "{'American Transmission Company', 'Commonwealth Edison Company', 'Ameren Services Company', 'Northern Indiana Public Service Company [BA'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now let's see how many tlines are owned by these {numCompaniesVelo} \"       \"companies in the entire TADS database:\")\n",
    "\n",
    "print(\"\"f\"But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\")\n",
    "\n",
    "companyNamesVelo2Tads = companyNamesVelo.copy()  # Create a copy to avoid modifying the original\n",
    "\n",
    "# Replace the element using the 'discard' method (more efficient for sets)\n",
    "companyNamesVelo2Tads.discard(\"Commonwealth Edison Co\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "companyNamesVelo2Tads.discard(\"AmerenIP\")\n",
    "companyNamesVelo2Tads.add(\"Ameren Services Company\")\n",
    "companyNamesVelo2Tads.discard(\"American Transmission Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"American Transmission Company\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Indiana Public Service Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Municipal Power Agency\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Undetermined Company\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "print(companyNamesVelo2Tads)\n",
    "\n",
    "dfVeloSorted = sort_and_shift_columns_dfVelo(dfVelo)\n",
    "\n",
    "veloSortedAddr = os.path.join(processedDataFolder, \"dfVelo-Chicago-Ohare-Sorted.xlsx\")\n",
    "dfVeloSorted.to_excel(veloSortedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f21d97e-9871-4bab-8c64-e5309069a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'200-299 kV', '100-199 kV', '600-799 kV', '300-399 kV'}\n",
      "Size of TADS db after filtering: 16052, 47\n",
      "Size of TADS db after filtering for only latest reported year: 1705, 47\n"
     ]
    }
   ],
   "source": [
    "dfTads = dfTads0.copy()\n",
    "dfTads = dfTads[dfTads['CompanyName'].isin(companyNamesVelo2Tads)]\n",
    "voltageClassesTads0 = set(dfTads['VoltageClassCodeName'])\n",
    "print(voltageClassesTads0)\n",
    "voltageClassesAllowedTads = voltageClassesTads0.copy()\n",
    "voltageClassesAllowedTads.discard(\"0-99 kV\")\n",
    "\n",
    "dfTads = dfTads[dfTads['VoltageClassCodeName'].isin(voltageClassesAllowedTads)]\n",
    "\n",
    "sizeTads = dfTads.shape\n",
    "print(f\"Size of TADS db after filtering: {sizeTads[0]}, {sizeTads[1]}\")\n",
    "\n",
    "dfTadsSorted = sort_and_shift_columns(dfTads)\n",
    "\n",
    "tadsSortedAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "dfTadsSorted.to_excel(tadsSortedAddr, index=False)\n",
    "\n",
    "# dfTadsLatest = filter_tlines_by_latest_reported_year(dfTadsSorted)\n",
    "dfTadsLatest = get_latest_entries(dfTadsSorted)\n",
    "\n",
    "sizeTadsLatest = dfTadsLatest.shape\n",
    "\n",
    "print(f\"Size of TADS db after filtering for only latest reported year: {sizeTadsLatest[0]}, {sizeTadsLatest[1]}\")\n",
    "\n",
    "tadsLatestAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "dfTadsLatest.to_excel(tadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2aeef4-4be9-481c-8323-ee9bff5505d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = get_matched_entries(dfVeloSorted, dfTadsLatest)\n",
    "matchAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Matched.xlsx\")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     60847\n",
       "28739     22650\n",
       "184865     2486\n",
       "118743    55397\n",
       "118743    69508\n",
       "          ...  \n",
       "300894    55407\n",
       "292165    60900\n",
       "300914    60900\n",
       "184890     2431\n",
       "300927     2430\n",
       "Name: Rec_ID, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['Rec_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .conda (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e423bd83-e281-4d2a-a781-1c34bdb7a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e2d6fd-6def-4e34-af24-bd49bd1559f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # pylint: disable=undefined-variable line-too-long invalid-name\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ed2854-8303-415b-929d-777bc210d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TADS db before filtering: 301152, 47\n",
      "There are 304 unique companies owning tlines in the entire TADS database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-081c3e414d19>:3: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfTads0 = pd.read_csv(tadsFileAddr)\n"
     ]
    }
   ],
   "source": [
    "tadsFileAddr = os.path.join(rawDataFolder, \"TADS 2024 AC Inventory.csv\")\n",
    "dfTads0 = pd.read_csv(tadsFileAddr)\n",
    "sizeTads0 = dfTads0.shape\n",
    "print(f\"Size of TADS db before filtering: {sizeTads0[0]}, {sizeTads0[1]}\")\n",
    "companyNamesTads0 = set(dfTads0.CompanyName)\n",
    "numCompaniesTads0 = len(companyNamesTads0)\n",
    "print(f\"There are {numCompaniesTads0} unique companies owning tlines in the entire TADS database.\")\n",
    "# display(dftads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761a9eb3-a3ce-4b16-b5dc-4a9376d0b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\tlines-near-chicago-ohare-raw.xlsx\n",
      "Size of velocity suite db before any filtering: 524, 21\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "veloFileAddr = os.path.join(rawDataFolder, \"tlines-near-chicago-ohare-raw.xlsx\") # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f93b78-749d-4baa-b80c-3ba1be6fa2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': 459, 21\n",
      "There are 6 named companies owning the tlines near chicago-ohare\n",
      "Their names are:\n",
      "{'American Transmission Co LLC', 'Undetermined Company', 'Northern Municipal Power Agency', 'AmerenIP', 'Northern Indiana Public Service Co LLC', 'Commonwealth Edison Co'}\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcdac220-3759-42ea-aa68-5d5bedb7da68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's see how many tlines are owned by these 6 companies in the entire TADS database:\n",
      "But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\n",
      "{'Northern Indiana Public Service Company [BA', 'American Transmission Company', 'Ameren Services Company', 'Commonwealth Edison Company'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now let's see how many tlines are owned by these {numCompaniesVelo} \"       \"companies in the entire TADS database:\")\n",
    "\n",
    "print(\"\"f\"But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\")\n",
    "\n",
    "companyNamesVelo2Tads = companyNamesVelo.copy()  # Create a copy to avoid modifying the original\n",
    "\n",
    "# Replace the element using the 'discard' method (more efficient for sets)\n",
    "companyNamesVelo2Tads.discard(\"Commonwealth Edison Co\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "companyNamesVelo2Tads.discard(\"AmerenIP\")\n",
    "companyNamesVelo2Tads.add(\"Ameren Services Company\")\n",
    "companyNamesVelo2Tads.discard(\"American Transmission Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"American Transmission Company\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Indiana Public Service Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Municipal Power Agency\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Undetermined Company\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "print(companyNamesVelo2Tads)\n",
    "\n",
    "dfVeloSorted = sort_and_shift_columns_dfVelo(dfVelo)\n",
    "\n",
    "veloSortedAddr = os.path.join(processedDataFolder, \"dfVelo-Chicago-Ohare-Sorted.xlsx\")\n",
    "dfVeloSorted.to_excel(veloSortedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc8f320-599c-4ad9-8ac5-8d7bb8a20967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'600-799 kV', '200-299 kV', '300-399 kV', '100-199 kV'}\n",
      "Size of TADS db after filtering: 16052, 47\n",
      "Size of TADS db after filtering for only latest reported year: 1705, 47\n"
     ]
    }
   ],
   "source": [
    "dfTads = dfTads0.copy()\n",
    "dfTads = dfTads[dfTads['CompanyName'].isin(companyNamesVelo2Tads)]\n",
    "voltageClassesTads0 = set(dfTads['VoltageClassCodeName'])\n",
    "print(voltageClassesTads0)\n",
    "voltageClassesAllowedTads = voltageClassesTads0.copy()\n",
    "voltageClassesAllowedTads.discard(\"0-99 kV\")\n",
    "\n",
    "dfTads = dfTads[dfTads['VoltageClassCodeName'].isin(voltageClassesAllowedTads)]\n",
    "\n",
    "sizeTads = dfTads.shape\n",
    "print(f\"Size of TADS db after filtering: {sizeTads[0]}, {sizeTads[1]}\")\n",
    "\n",
    "dfTadsSorted = sort_and_shift_columns(dfTads)\n",
    "\n",
    "tadsSortedAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "dfTadsSorted.to_excel(tadsSortedAddr, index=False)\n",
    "\n",
    "# dfTadsLatest = filter_tlines_by_latest_reported_year(dfTadsSorted)\n",
    "dfTadsLatest = get_latest_entries(dfTadsSorted)\n",
    "\n",
    "sizeTadsLatest = dfTadsLatest.shape\n",
    "\n",
    "print(f\"Size of TADS db after filtering for only latest reported year: {sizeTadsLatest[0]}, {sizeTadsLatest[1]}\")\n",
    "\n",
    "tadsLatestAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "dfTadsLatest.to_excel(tadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0185951-357e-4f22-9b12-f9a600a13ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = get_matched_entries(dfVeloSorted, dfTadsLatest)\n",
    "matchAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Matched.xlsx\")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     60847\n",
       "28739     22650\n",
       "184865     2486\n",
       "118743    55397\n",
       "118743    69508\n",
       "          ...  \n",
       "300894    55407\n",
       "292165    60900\n",
       "300914    60900\n",
       "184890     2431\n",
       "300927     2430\n",
       "Name: Rec_ID, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['Rec_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     NaN\n",
       "28739     NaN\n",
       "184865    NaN\n",
       "118743    NaN\n",
       "118743    NaN\n",
       "         ... \n",
       "300894    NaN\n",
       "292165    NaN\n",
       "300914    NaN\n",
       "184890    NaN\n",
       "300927    NaN\n",
       "Name: RetirementDate, Length: 127, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch[\"RetirementDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     Northern Indiana Public Service Company [BA\n",
       "28739     Northern Indiana Public Service Company [BA\n",
       "184865                    Commonwealth Edison Company\n",
       "118743                    Commonwealth Edison Company\n",
       "118743                    Commonwealth Edison Company\n",
       "                             ...                     \n",
       "300894                    Commonwealth Edison Company\n",
       "292165                    Commonwealth Edison Company\n",
       "300914                    Commonwealth Edison Company\n",
       "184890                    Commonwealth Edison Company\n",
       "300927                    Commonwealth Edison Company\n",
       "Name: CompanyName, Length: 127, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['CompanyName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     RFC\n",
       "28739     RFC\n",
       "184865    RFC\n",
       "118743    RFC\n",
       "118743    RFC\n",
       "         ... \n",
       "300894    RFC\n",
       "292165    RFC\n",
       "300914    RFC\n",
       "184890    RFC\n",
       "300927    RFC\n",
       "Name: RegionCode, Length: 127, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['RegionCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729                 Aetna\n",
       "28739                 Aetna\n",
       "184865         Libertyville\n",
       "118743    Electric Junction\n",
       "118743    Electric Junction\n",
       "                ...        \n",
       "300894                 Zion\n",
       "292165             Waukegan\n",
       "300914                 Zion\n",
       "184890         Libertyville\n",
       "300927                 Zion\n",
       "Name: FromBus, Length: 127, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['FromBus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729            Lake George\n",
       "28739                 Miller\n",
       "184865             Aptakisic\n",
       "118743                Aurora\n",
       "118743                Aurora\n",
       "                 ...        \n",
       "300894            Northbrook\n",
       "292165                  Zion\n",
       "300914              Waukegan\n",
       "184890    Zion Energy Center\n",
       "300927    Zion Energy Center\n",
       "Name: ToBus, Length: 127, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['ToBus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     NaN\n",
       "28739     NaN\n",
       "184865    NaN\n",
       "118743    NaN\n",
       "118743    NaN\n",
       "         ... \n",
       "300894    NaN\n",
       "292165    NaN\n",
       "300914    NaN\n",
       "184890    NaN\n",
       "300927    NaN\n",
       "Name: TertiaryBus, Length: 127, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch['TertiaryBus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e055d2a4-a2c6-492e-a4ae-18afc469588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing only specific columns.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with 'ElementIdentifierName' values)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - 'RegionCode'\n",
    "            - 'FromBus'\n",
    "            - 'ToBus'\n",
    "            - 'TertiaryBus'\n",
    "            - 'Miles'\n",
    "            - 'BESExemptedFlag'\n",
    "            - 'NumberOfTerminals'\n",
    "            - 'CircuitTypeCode'\n",
    "            - 'VoltageClassCodeName'\n",
    "            - 'ParentCode'\n",
    "            - 'ConductorsPerPhaseCode'\n",
    "            - 'OverheadGroundWireCode'\n",
    "            - 'InsulatorTypeCode'\n",
    "            - 'CableTypeCode'\n",
    "            - 'StructureMaterialCode'\n",
    "            - 'StructureTypeCode'\n",
    "            - 'CircuitsPerStructureCode'\n",
    "            - 'TerrainCode'\n",
    "            - 'ElevationCode'\n",
    "            - 'InServiceDate'\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Fill the 'combo' column with 'ElementIdentifierName' values\n",
    "    df_reduced[\"combo\"] = df_reduced[\"ElementIdentifierName\"]\n",
    "\n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-2a46a48da432>:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced[\"ElementIdentifierName\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>CircuitTypeCode</th>\n",
       "      <th>...</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "      <td>138054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "      <td>138102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>15410</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "      <td>15410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "      <td>11119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "      <td>11119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>15423</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2431</td>\n",
       "      <td>15423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ElementIdentifierName                                  CompanyName  \\\n",
       "28729                 138054  Northern Indiana Public Service Company [BA   \n",
       "28739                 138102  Northern Indiana Public Service Company [BA   \n",
       "184865                 15410                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "...                      ...                                          ...   \n",
       "300894                  2218                  Commonwealth Edison Company   \n",
       "292165                  1609                  Commonwealth Edison Company   \n",
       "300914                  2218                  Commonwealth Edison Company   \n",
       "184890                 15423                  Commonwealth Edison Company   \n",
       "300927                  2223                  Commonwealth Edison Company   \n",
       "\n",
       "       RegionCode            FromBus               ToBus TertiaryBus   Miles  \\\n",
       "28729         RFC              Aetna         Lake George         NaN   4.900   \n",
       "28739         RFC              Aetna              Miller         NaN   0.500   \n",
       "184865        RFC       Libertyville           Aptakisic         NaN  10.133   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "...           ...                ...                 ...         ...     ...   \n",
       "300894        RFC               Zion          Northbrook         NaN  26.210   \n",
       "292165        RFC           Waukegan                Zion         NaN  12.275   \n",
       "300914        RFC               Zion            Waukegan         NaN   5.283   \n",
       "184890        RFC       Libertyville  Zion Energy Center         NaN  12.300   \n",
       "300927        RFC               Zion  Zion Energy Center         NaN   5.982   \n",
       "\n",
       "        BESExemptedFlag  NumberOfTerminals    CircuitTypeCode  ...  \\\n",
       "28729               0.0                2.0  ACO - AC Overhead  ...   \n",
       "28739               0.0                2.0  ACO - AC Overhead  ...   \n",
       "184865              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "300894              0.0                2.0  ACO - AC Overhead  ...   \n",
       "292165              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300914              NaN                2.0  ACO - AC Overhead  ...   \n",
       "184890              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300927              NaN                2.0  ACO - AC Overhead  ...   \n",
       "\n",
       "       CableTypeCode StructureMaterialCode  StructureTypeCode  \\\n",
       "28729            NaN                   NaN                NaN   \n",
       "28739            NaN                   NaN                NaN   \n",
       "184865           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "...              ...                   ...                ...   \n",
       "300894           NaN                   NaN                NaN   \n",
       "292165           NaN                   NaN                NaN   \n",
       "300914           NaN                   NaN                NaN   \n",
       "184890           NaN                   NaN                NaN   \n",
       "300927           NaN                   NaN                NaN   \n",
       "\n",
       "        CircuitsPerStructureCode  TerrainCode  ElevationCode  InServiceDate  \\\n",
       "28729                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "28739                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "184865                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "...                          ...          ...            ...            ...   \n",
       "300894                       NaN          NaN            NaN    1/1/13 0:00   \n",
       "292165                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300914                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "184890                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300927                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "\n",
       "        RetirementDate  Rec_ID   combo  \n",
       "28729              NaN   60847  138054  \n",
       "28739              NaN   22650  138102  \n",
       "184865             NaN    2486   15410  \n",
       "118743             NaN   55397   11119  \n",
       "118743             NaN   69508   11119  \n",
       "...                ...     ...     ...  \n",
       "300894             NaN   55407    2218  \n",
       "292165             NaN   60900    1609  \n",
       "300914             NaN   60900    2218  \n",
       "184890             NaN    2431   15423  \n",
       "300927             NaN    2430    2223  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1557eb06-8700-49ea-9bd1-8f2d97d6c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-a030858b3d99>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>CircuitTypeCode</th>\n",
       "      <th>...</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "      <td>ACO - AC Overhead - Aetna - Lake George - 138054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "      <td>ACO - AC Overhead - Aetna - Miller - 138102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>15410</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "      <td>ACO - AC Overhead - Libertyville - Aptakisic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "      <td>ACO - AC Overhead - Zion - Northbrook - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "      <td>ACO - AC Overhead - Waukegan - Zion - 1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "      <td>ACO - AC Overhead - Zion - Waukegan - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>15423</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2431</td>\n",
       "      <td>ACO - AC Overhead - Libertyville - Zion Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "      <td>ACO - AC Overhead - Zion - Zion Energy Center ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ElementIdentifierName                                  CompanyName  \\\n",
       "28729                 138054  Northern Indiana Public Service Company [BA   \n",
       "28739                 138102  Northern Indiana Public Service Company [BA   \n",
       "184865                 15410                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "...                      ...                                          ...   \n",
       "300894                  2218                  Commonwealth Edison Company   \n",
       "292165                  1609                  Commonwealth Edison Company   \n",
       "300914                  2218                  Commonwealth Edison Company   \n",
       "184890                 15423                  Commonwealth Edison Company   \n",
       "300927                  2223                  Commonwealth Edison Company   \n",
       "\n",
       "       RegionCode            FromBus               ToBus TertiaryBus   Miles  \\\n",
       "28729         RFC              Aetna         Lake George         NaN   4.900   \n",
       "28739         RFC              Aetna              Miller         NaN   0.500   \n",
       "184865        RFC       Libertyville           Aptakisic         NaN  10.133   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "...           ...                ...                 ...         ...     ...   \n",
       "300894        RFC               Zion          Northbrook         NaN  26.210   \n",
       "292165        RFC           Waukegan                Zion         NaN  12.275   \n",
       "300914        RFC               Zion            Waukegan         NaN   5.283   \n",
       "184890        RFC       Libertyville  Zion Energy Center         NaN  12.300   \n",
       "300927        RFC               Zion  Zion Energy Center         NaN   5.982   \n",
       "\n",
       "        BESExemptedFlag  NumberOfTerminals    CircuitTypeCode  ...  \\\n",
       "28729               0.0                2.0  ACO - AC Overhead  ...   \n",
       "28739               0.0                2.0  ACO - AC Overhead  ...   \n",
       "184865              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "300894              0.0                2.0  ACO - AC Overhead  ...   \n",
       "292165              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300914              NaN                2.0  ACO - AC Overhead  ...   \n",
       "184890              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300927              NaN                2.0  ACO - AC Overhead  ...   \n",
       "\n",
       "       CableTypeCode StructureMaterialCode  StructureTypeCode  \\\n",
       "28729            NaN                   NaN                NaN   \n",
       "28739            NaN                   NaN                NaN   \n",
       "184865           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "...              ...                   ...                ...   \n",
       "300894           NaN                   NaN                NaN   \n",
       "292165           NaN                   NaN                NaN   \n",
       "300914           NaN                   NaN                NaN   \n",
       "184890           NaN                   NaN                NaN   \n",
       "300927           NaN                   NaN                NaN   \n",
       "\n",
       "        CircuitsPerStructureCode  TerrainCode  ElevationCode  InServiceDate  \\\n",
       "28729                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "28739                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "184865                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "...                          ...          ...            ...            ...   \n",
       "300894                       NaN          NaN            NaN    1/1/13 0:00   \n",
       "292165                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300914                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "184890                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300927                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "\n",
       "        RetirementDate  Rec_ID  \\\n",
       "28729              NaN   60847   \n",
       "28739              NaN   22650   \n",
       "184865             NaN    2486   \n",
       "118743             NaN   55397   \n",
       "118743             NaN   69508   \n",
       "...                ...     ...   \n",
       "300894             NaN   55407   \n",
       "292165             NaN   60900   \n",
       "300914             NaN   60900   \n",
       "184890             NaN    2431   \n",
       "300927             NaN    2430   \n",
       "\n",
       "                                                    combo  \n",
       "28729    ACO - AC Overhead - Aetna - Lake George - 138054  \n",
       "28739         ACO - AC Overhead - Aetna - Miller - 138102  \n",
       "184865  ACO - AC Overhead - Libertyville - Aptakisic -...  \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...  \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...  \n",
       "...                                                   ...  \n",
       "300894       ACO - AC Overhead - Zion - Northbrook - 2218  \n",
       "292165         ACO - AC Overhead - Waukegan - Zion - 1609  \n",
       "300914         ACO - AC Overhead - Zion - Waukegan - 2218  \n",
       "184890  ACO - AC Overhead - Libertyville - Zion Energy...  \n",
       "300927  ACO - AC Overhead - Zion - Zion Energy Center ...  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a69793-3322-4e24-a3e0-4353f5c6108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    df_reduced = df_reduced[[\"combo\"] + list(df_reduced.filter(like='^((?!combo).)*$'))]\n",
    "\n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-d9f3a6cae046>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Lake George - 138054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Miller - 138102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Aptakisic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO - AC Overhead - Zion - Northbrook - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>ACO - AC Overhead - Waukegan - Zion - 1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO - AC Overhead - Zion - Waukegan - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Zion Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO - AC Overhead - Zion - Zion Energy Center ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    combo\n",
       "28729    ACO - AC Overhead - Aetna - Lake George - 138054\n",
       "28739         ACO - AC Overhead - Aetna - Miller - 138102\n",
       "184865  ACO - AC Overhead - Libertyville - Aptakisic -...\n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...\n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...\n",
       "...                                                   ...\n",
       "300894       ACO - AC Overhead - Zion - Northbrook - 2218\n",
       "292165         ACO - AC Overhead - Waukegan - Zion - 1609\n",
       "300914         ACO - AC Overhead - Zion - Waukegan - 2218\n",
       "184890  ACO - AC Overhead - Libertyville - Zion Energy...\n",
       "300927  ACO - AC Overhead - Zion - Zion Energy Center ...\n",
       "\n",
       "[127 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a8caf52-06de-459d-a47e-eee6ef0b7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    df_reduced = df_reduced[[\"combo\"] + list(df_reduced.filter(like='^((?!combo).)*$'))]\n",
    "\n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-63e873415df9>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Lake George - 138054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Miller - 138102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Aptakisic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO - AC Overhead - Zion - Northbrook - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>ACO - AC Overhead - Waukegan - Zion - 1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO - AC Overhead - Zion - Waukegan - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Zion Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO - AC Overhead - Zion - Zion Energy Center ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    combo\n",
       "28729    ACO - AC Overhead - Aetna - Lake George - 138054\n",
       "28739         ACO - AC Overhead - Aetna - Miller - 138102\n",
       "184865  ACO - AC Overhead - Libertyville - Aptakisic -...\n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...\n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...\n",
       "...                                                   ...\n",
       "300894       ACO - AC Overhead - Zion - Northbrook - 2218\n",
       "292165         ACO - AC Overhead - Waukegan - Zion - 1609\n",
       "300914         ACO - AC Overhead - Zion - Waukegan - 2218\n",
       "184890  ACO - AC Overhead - Libertyville - Zion Energy...\n",
       "300927  ACO - AC Overhead - Zion - Zion Energy Center ...\n",
       "\n",
       "[127 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ecd9ae-07b7-4d40-b364-8319d28054d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    df_reduced.insert(0, \"combo\", df_reduced.pop(\"combo\"))\n",
    "\n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-102b1a8fcd19>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    }
   ],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfMatch1 \u001b[39m=\u001b[39m copy(dfMatch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "dfMatch1 = copy(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch1 = dfMatch.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.copy of                   FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfMatch1[\u001b[39m'\u001b[39;49m\u001b[39mRec_ID\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dfMatch1['Rec_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-4ca358aa3b3b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    class(dfMatch1)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class(dfMatch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfMatch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch1 = dfMatch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'combo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combo'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfMatch1\u001b[39m.\u001b[39;49mpop(\u001b[39m'\u001b[39;49m\u001b[39mcombo\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:5806\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m   5766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5767\u001b[0m \u001b[39m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5768\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5804\u001b[0m \u001b[39m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5805\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpop(item\u001b[39m=\u001b[39;49mitem)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:946\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m Any:\n\u001b[1;32m--> 946\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[item]\n\u001b[0;32m    947\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[0;32m    949\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4091\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combo'"
     ]
    }
   ],
   "source": [
    "dfMatch1.pop('combo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'combo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combo'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfMatch1\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcombo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:5806\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m   5766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5767\u001b[0m \u001b[39m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5768\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5804\u001b[0m \u001b[39m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5805\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpop(item\u001b[39m=\u001b[39;49mitem)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:946\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m Any:\n\u001b[1;32m--> 946\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[item]\n\u001b[0;32m    947\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[0;32m    949\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4091\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combo'"
     ]
    }
   ],
   "source": [
    "dfMatch1.pop(\"combo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729     60847\n",
       "28739     22650\n",
       "184865     2486\n",
       "118743    55397\n",
       "118743    69508\n",
       "          ...  \n",
       "300894    55407\n",
       "292165    60900\n",
       "300914    60900\n",
       "184890     2431\n",
       "300927     2430\n",
       "Name: Rec_ID, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch1.pop('Rec_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>CreationDT</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>59:52.2</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>59:52.2</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>14:43.7</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... CreationDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...    59:52.2   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...    59:52.2   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "...                                    ...        ...  ...        ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    14:43.7   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...    33:22.9   \n",
       "\n",
       "       ExtractionDT UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk  \\\n",
       "28729       05:07.9  00:01.0        NaN         01:21.7  636757   1   \n",
       "28739       05:07.9  00:01.0        NaN         01:21.7  642142   1   \n",
       "184865      05:07.9  00:01.0        NaN         01:21.7  650912   1   \n",
       "118743      05:07.9  00:01.0        NaN         01:21.7  625367   1   \n",
       "118743      05:07.9  00:01.0        NaN         01:21.7  625367   1   \n",
       "...             ...      ...        ...             ...     ...  ..   \n",
       "300894      10:05.5  08:34.2        NaN         00:00.9  216720   1   \n",
       "292165      05:07.9  00:01.0        NaN         01:21.7  650849   1   \n",
       "300914      05:07.9  00:01.0        NaN         01:21.7  625328   1   \n",
       "184890      05:07.9  00:01.0        NaN         01:21.7  625419   1   \n",
       "300927      05:07.9  00:01.0        NaN         01:21.7  625330   1   \n",
       "\n",
       "                      Slicer                             AliasID  IsCurrent  \n",
       "28729   9259 | 113936 | 2024  0x10ED02D26825C003EE3B8BB374B3D856          1  \n",
       "28739   9259 | 113983 | 2024  0xBB81DBE68DB618667B9650E57C7267EA          1  \n",
       "184865  9400 | 118818 | 2024  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1  \n",
       "118743  9402 | 119072 | 2024  0x2A3F37E31771BB4D9468566640B78822          1  \n",
       "118743  9402 | 119072 | 2024  0x2A3F37E31771BB4D9468566640B78822          1  \n",
       "...                      ...                                 ...        ...  \n",
       "300894   5803 | 31789 | 2014  0xD7BAD6B5D071292FD40F898CABBC9677          1  \n",
       "292165  9400 | 118840 | 2024  0x128D3A78E37B1B206191C78D9B5D7C4C          1  \n",
       "300914  9402 | 119042 | 2024  0xD7BAD6B5D071292FD40F898CABBC9677          1  \n",
       "184890  9402 | 119100 | 2024  0xC81DBDBE35DD273C67BADAA182719325          1  \n",
       "300927  9402 | 119044 | 2024  0xC21A84D1CF465517E3067BE5D830BD02          1  \n",
       "\n",
       "[127 rows x 47 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch1 = dfMatch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dfMatch1.pop('Rec_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "insert() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfMatch1\u001b[39m.\u001b[39;49minsert(\u001b[39m0\u001b[39;49m, col)\n",
      "\u001b[1;31mTypeError\u001b[0m: insert() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": [
    "dfMatch1.insert(0, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch1.insert(0, 'Rec_ID', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>...</th>\n",
       "      <th>CreationDT</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>60847</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>...</td>\n",
       "      <td>59:52.2</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>22650</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>...</td>\n",
       "      <td>59:52.2</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>2486</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>55397</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>69508</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>55407</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>14:43.7</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>60900</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>60900</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>2431</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>2430</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>...</td>\n",
       "      <td>33:22.9</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rec_ID            FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729    60847              Aetna         Lake George              2024   \n",
       "28739    22650              Aetna              Miller              2024   \n",
       "184865    2486       Libertyville           Aptakisic              2024   \n",
       "118743   55397  Electric Junction              Aurora              2024   \n",
       "118743   69508  Electric Junction              Aurora              2024   \n",
       "...        ...                ...                 ...               ...   \n",
       "300894   55407               Zion          Northbrook              2014   \n",
       "292165   60900           Waukegan                Zion              2024   \n",
       "300914   60900               Zion            Waukegan              2024   \n",
       "184890    2431       Libertyville  Zion Energy Center              2024   \n",
       "300927    2430               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID  ... CreationDT ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03  ...    59:52.2      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03  ...    59:52.2      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "...                                    ...  ...        ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    14:43.7      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB  ...    33:22.9      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1  \n",
       "...                                    ...        ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "038ea105-b768-4a67-9f8f-718d8097a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    # df_reduced.insert(0, \"combo\", df_reduced.pop(\"combo\"))\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "    col = df_reduced_copy.pop('combo')\n",
    "    df_reduced_copy.insert(0, 'combo', col)\n",
    "    \n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50d2eb5b-b78f-42fd-85c0-6e3fd1bea711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    # df_reduced.insert(0, \"combo\", df_reduced.pop(\"combo\"))\n",
    "    # df_reduced_copy = df_reduced.copy()\n",
    "    col = df_reduced.pop('combo')\n",
    "    df_reduced.insert(0, 'combo', col)\n",
    "    \n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-00852321955d>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    }
   ],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bbb31ed-69bb-4f3d-abdd-2a6c0cbf0340",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-a9d8df8d1dd5>, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[48], line 62\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_reduced.iloc(:, 0) = col\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    # df_reduced.insert(0, \"combo\", df_reduced.pop(\"combo\"))\n",
    "    # df_reduced_copy = df_reduced.copy()\n",
    "    col = df_reduced.pop('combo')\n",
    "    df_reduced.iloc(:, 0) = col\n",
    "    \n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ` padnas.iloc` not found.\n"
     ]
    }
   ],
   "source": [
    "? padnas.iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type help() for interactive help, or help(object) for help about object."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m help(pandas\u001b[39m.\u001b[39miloc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "help(pandas.iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iloc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m help(iloc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iloc' is not defined"
     ]
    }
   ],
   "source": [
    "help(iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "112eaa21-8fa2-4096-b1a4-a027a730e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    # df_reduced.insert(0, \"combo\", df_reduced.pop(\"combo\"))\n",
    "    # df_reduced_copy = df_reduced.copy()\n",
    "    col = df_reduced.pop('combo')\n",
    "    df_reduced.iloc[:, 0] = col\n",
    "    \n",
    "    return df_reduced\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-7d6d3a22360e>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    }
   ],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1034691e-90a9-4854-97dc-20b828f841aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Reorder columns with 'combo' as the first column\n",
    "    # df_reduced.insert(0, \"combo\", df_reduced.pop(\"combo\"))\n",
    "    # df_reduced_copy = df_reduced.copy()\n",
    "    col = df_reduced.pop('combo')\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "    df_reduced_copy.iloc[:, 0] = col\n",
    "    \n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-a6d738c5abc1>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced[\"combo\"] = df_reduced.apply(\n"
     ]
    }
   ],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9852d82a-5f0b-4494-a5ea-2b99d8461a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # col = df_reduced_copy.pop('combo')\n",
    "    # df_reduced_copy = df_reduced.copy()\n",
    "    # df_reduced_copy.iloc[:, 0] = col\n",
    "    \n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>CircuitTypeCode</th>\n",
       "      <th>...</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "      <td>ACO - AC Overhead - Aetna - Lake George - 138054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "      <td>ACO - AC Overhead - Aetna - Miller - 138102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>15410</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "      <td>ACO - AC Overhead - Libertyville - Aptakisic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "      <td>ACO - AC Overhead - Zion - Northbrook - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "      <td>ACO - AC Overhead - Waukegan - Zion - 1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "      <td>ACO - AC Overhead - Zion - Waukegan - 2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>15423</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2431</td>\n",
       "      <td>ACO - AC Overhead - Libertyville - Zion Energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "      <td>ACO - AC Overhead - Zion - Zion Energy Center ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ElementIdentifierName                                  CompanyName  \\\n",
       "28729                 138054  Northern Indiana Public Service Company [BA   \n",
       "28739                 138102  Northern Indiana Public Service Company [BA   \n",
       "184865                 15410                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "...                      ...                                          ...   \n",
       "300894                  2218                  Commonwealth Edison Company   \n",
       "292165                  1609                  Commonwealth Edison Company   \n",
       "300914                  2218                  Commonwealth Edison Company   \n",
       "184890                 15423                  Commonwealth Edison Company   \n",
       "300927                  2223                  Commonwealth Edison Company   \n",
       "\n",
       "       RegionCode            FromBus               ToBus TertiaryBus   Miles  \\\n",
       "28729         RFC              Aetna         Lake George         NaN   4.900   \n",
       "28739         RFC              Aetna              Miller         NaN   0.500   \n",
       "184865        RFC       Libertyville           Aptakisic         NaN  10.133   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "...           ...                ...                 ...         ...     ...   \n",
       "300894        RFC               Zion          Northbrook         NaN  26.210   \n",
       "292165        RFC           Waukegan                Zion         NaN  12.275   \n",
       "300914        RFC               Zion            Waukegan         NaN   5.283   \n",
       "184890        RFC       Libertyville  Zion Energy Center         NaN  12.300   \n",
       "300927        RFC               Zion  Zion Energy Center         NaN   5.982   \n",
       "\n",
       "        BESExemptedFlag  NumberOfTerminals    CircuitTypeCode  ...  \\\n",
       "28729               0.0                2.0  ACO - AC Overhead  ...   \n",
       "28739               0.0                2.0  ACO - AC Overhead  ...   \n",
       "184865              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "300894              0.0                2.0  ACO - AC Overhead  ...   \n",
       "292165              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300914              NaN                2.0  ACO - AC Overhead  ...   \n",
       "184890              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300927              NaN                2.0  ACO - AC Overhead  ...   \n",
       "\n",
       "       CableTypeCode StructureMaterialCode  StructureTypeCode  \\\n",
       "28729            NaN                   NaN                NaN   \n",
       "28739            NaN                   NaN                NaN   \n",
       "184865           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "...              ...                   ...                ...   \n",
       "300894           NaN                   NaN                NaN   \n",
       "292165           NaN                   NaN                NaN   \n",
       "300914           NaN                   NaN                NaN   \n",
       "184890           NaN                   NaN                NaN   \n",
       "300927           NaN                   NaN                NaN   \n",
       "\n",
       "        CircuitsPerStructureCode  TerrainCode  ElevationCode  InServiceDate  \\\n",
       "28729                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "28739                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "184865                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "...                          ...          ...            ...            ...   \n",
       "300894                       NaN          NaN            NaN    1/1/13 0:00   \n",
       "292165                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300914                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "184890                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300927                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "\n",
       "        RetirementDate  Rec_ID  \\\n",
       "28729              NaN   60847   \n",
       "28739              NaN   22650   \n",
       "184865             NaN    2486   \n",
       "118743             NaN   55397   \n",
       "118743             NaN   69508   \n",
       "...                ...     ...   \n",
       "300894             NaN   55407   \n",
       "292165             NaN   60900   \n",
       "300914             NaN   60900   \n",
       "184890             NaN    2431   \n",
       "300927             NaN    2430   \n",
       "\n",
       "                                                    combo  \n",
       "28729    ACO - AC Overhead - Aetna - Lake George - 138054  \n",
       "28739         ACO - AC Overhead - Aetna - Miller - 138102  \n",
       "184865  ACO - AC Overhead - Libertyville - Aptakisic -...  \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...  \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...  \n",
       "...                                                   ...  \n",
       "300894       ACO - AC Overhead - Zion - Northbrook - 2218  \n",
       "292165         ACO - AC Overhead - Waukegan - Zion - 1609  \n",
       "300914         ACO - AC Overhead - Zion - Waukegan - 2218  \n",
       "184890  ACO - AC Overhead - Libertyville - Zion Energy...  \n",
       "300927  ACO - AC Overhead - Zion - Zion Energy Center ...  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f114729-19f6-4ccb-92d0-c5a018376083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns and a dynamic 'combo' column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName)\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns)\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the new DataFrame with desired columns\n",
    "    df_reduced = dfMatch[\n",
    "        [\n",
    "            \"ElementIdentifierName\",\n",
    "            \"CompanyName\",\n",
    "            \"RegionCode\",\n",
    "            \"FromBus\",\n",
    "            \"ToBus\",\n",
    "            \"TertiaryBus\",\n",
    "            \"Miles\",\n",
    "            \"BESExemptedFlag\",\n",
    "            \"NumberOfTerminals\",\n",
    "            \"CircuitTypeCode\",\n",
    "            \"VoltageClassCodeName\",\n",
    "            \"ParentCode\",\n",
    "            \"ConductorsPerPhaseCode\",\n",
    "            \"OverheadGroundWireCode\",\n",
    "            \"InsulatorTypeCode\",\n",
    "            \"CableTypeCode\",\n",
    "            \"StructureMaterialCode\",\n",
    "            \"StructureTypeCode\",\n",
    "            \"CircuitsPerStructureCode\",\n",
    "            \"TerrainCode\",\n",
    "            \"ElevationCode\",\n",
    "            \"InServiceDate\",\n",
    "            \"RetirementDate\",\n",
    "            \"Rec_ID\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    col = df_reduced_copy.pop('combo')\n",
    "    # df_reduced_copy = df_reduced.copy()\n",
    "    df_reduced_copy.iloc[:, 0] = col\n",
    "    \n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>CircuitTypeCode</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Lake George - 138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Miller - 138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Aptakisic -...</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO - AC Overhead - Zion - Northbrook - 2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>ACO - AC Overhead - Waukegan - Zion - 1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO - AC Overhead - Zion - Waukegan - 2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Zion Energy...</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO - AC Overhead - Zion - Zion Energy Center ...</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACO - AC Overhead</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ElementIdentifierName  \\\n",
       "28729    ACO - AC Overhead - Aetna - Lake George - 138054   \n",
       "28739         ACO - AC Overhead - Aetna - Miller - 138102   \n",
       "184865  ACO - AC Overhead - Libertyville - Aptakisic -...   \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...   \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...   \n",
       "...                                                   ...   \n",
       "300894       ACO - AC Overhead - Zion - Northbrook - 2218   \n",
       "292165         ACO - AC Overhead - Waukegan - Zion - 1609   \n",
       "300914         ACO - AC Overhead - Zion - Waukegan - 2218   \n",
       "184890  ACO - AC Overhead - Libertyville - Zion Energy...   \n",
       "300927  ACO - AC Overhead - Zion - Zion Energy Center ...   \n",
       "\n",
       "                                        CompanyName RegionCode  \\\n",
       "28729   Northern Indiana Public Service Company [BA        RFC   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC   \n",
       "184865                  Commonwealth Edison Company        RFC   \n",
       "118743                  Commonwealth Edison Company        RFC   \n",
       "118743                  Commonwealth Edison Company        RFC   \n",
       "...                                             ...        ...   \n",
       "300894                  Commonwealth Edison Company        RFC   \n",
       "292165                  Commonwealth Edison Company        RFC   \n",
       "300914                  Commonwealth Edison Company        RFC   \n",
       "184890                  Commonwealth Edison Company        RFC   \n",
       "300927                  Commonwealth Edison Company        RFC   \n",
       "\n",
       "                  FromBus               ToBus TertiaryBus   Miles  \\\n",
       "28729               Aetna         Lake George         NaN   4.900   \n",
       "28739               Aetna              Miller         NaN   0.500   \n",
       "184865       Libertyville           Aptakisic         NaN  10.133   \n",
       "118743  Electric Junction              Aurora         NaN   1.433   \n",
       "118743  Electric Junction              Aurora         NaN   1.433   \n",
       "...                   ...                 ...         ...     ...   \n",
       "300894               Zion          Northbrook         NaN  26.210   \n",
       "292165           Waukegan                Zion         NaN  12.275   \n",
       "300914               Zion            Waukegan         NaN   5.283   \n",
       "184890       Libertyville  Zion Energy Center         NaN  12.300   \n",
       "300927               Zion  Zion Energy Center         NaN   5.982   \n",
       "\n",
       "        BESExemptedFlag  NumberOfTerminals    CircuitTypeCode  ...  \\\n",
       "28729               0.0                2.0  ACO - AC Overhead  ...   \n",
       "28739               0.0                2.0  ACO - AC Overhead  ...   \n",
       "184865              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "118743              NaN                2.0  ACO - AC Overhead  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "300894              0.0                2.0  ACO - AC Overhead  ...   \n",
       "292165              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300914              NaN                2.0  ACO - AC Overhead  ...   \n",
       "184890              NaN                2.0  ACO - AC Overhead  ...   \n",
       "300927              NaN                2.0  ACO - AC Overhead  ...   \n",
       "\n",
       "       InsulatorTypeCode CableTypeCode  StructureMaterialCode  \\\n",
       "28729                NaN           NaN                    NaN   \n",
       "28739                NaN           NaN                    NaN   \n",
       "184865               NaN           NaN                    NaN   \n",
       "118743               NaN           NaN                    NaN   \n",
       "118743               NaN           NaN                    NaN   \n",
       "...                  ...           ...                    ...   \n",
       "300894               NaN           NaN                    NaN   \n",
       "292165               NaN           NaN                    NaN   \n",
       "300914               NaN           NaN                    NaN   \n",
       "184890               NaN           NaN                    NaN   \n",
       "300927               NaN           NaN                    NaN   \n",
       "\n",
       "        StructureTypeCode  CircuitsPerStructureCode  TerrainCode  \\\n",
       "28729                 NaN                       NaN          NaN   \n",
       "28739                 NaN                       NaN          NaN   \n",
       "184865                NaN                       NaN          NaN   \n",
       "118743                NaN                       NaN          NaN   \n",
       "118743                NaN                       NaN          NaN   \n",
       "...                   ...                       ...          ...   \n",
       "300894                NaN                       NaN          NaN   \n",
       "292165                NaN                       NaN          NaN   \n",
       "300914                NaN                       NaN          NaN   \n",
       "184890                NaN                       NaN          NaN   \n",
       "300927                NaN                       NaN          NaN   \n",
       "\n",
       "        ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28729             NaN    1/1/15 0:00             NaN   60847  \n",
       "28739             NaN    1/1/15 0:00             NaN   22650  \n",
       "184865            NaN    1/1/15 0:00             NaN    2486  \n",
       "118743            NaN    1/1/15 0:00             NaN   55397  \n",
       "118743            NaN    1/1/15 0:00             NaN   69508  \n",
       "...               ...            ...             ...     ...  \n",
       "300894            NaN    1/1/13 0:00             NaN   55407  \n",
       "292165            NaN    1/1/15 0:00             NaN   60900  \n",
       "300914            NaN    1/1/15 0:00             NaN   60900  \n",
       "184890            NaN    1/1/15 0:00             NaN    2431  \n",
       "300927            NaN    1/1/15 0:00             NaN    2430  \n",
       "\n",
       "[127 rows x 24 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4b84f5d-a9e8-4805-801e-f217e25c7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Lake George - 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO - AC Overhead - Aetna - Miller - 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Aptakisic -...</td>\n",
       "      <td>15410</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO - AC Overhead - Electric Junction - Aurora...</td>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO - AC Overhead - Zion - Northbrook - 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>ACO - AC Overhead - Waukegan - Zion - 1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO - AC Overhead - Zion - Waukegan - 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>ACO - AC Overhead - Libertyville - Zion Energy...</td>\n",
       "      <td>15423</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO - AC Overhead - Zion - Zion Energy Center ...</td>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    combo  \\\n",
       "28729    ACO - AC Overhead - Aetna - Lake George - 138054   \n",
       "28739         ACO - AC Overhead - Aetna - Miller - 138102   \n",
       "184865  ACO - AC Overhead - Libertyville - Aptakisic -...   \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...   \n",
       "118743  ACO - AC Overhead - Electric Junction - Aurora...   \n",
       "...                                                   ...   \n",
       "300894       ACO - AC Overhead - Zion - Northbrook - 2218   \n",
       "292165         ACO - AC Overhead - Waukegan - Zion - 1609   \n",
       "300914         ACO - AC Overhead - Zion - Waukegan - 2218   \n",
       "184890  ACO - AC Overhead - Libertyville - Zion Energy...   \n",
       "300927  ACO - AC Overhead - Zion - Zion Energy Center ...   \n",
       "\n",
       "       ElementIdentifierName                                  CompanyName  \\\n",
       "28729                 138054  Northern Indiana Public Service Company [BA   \n",
       "28739                 138102  Northern Indiana Public Service Company [BA   \n",
       "184865                 15410                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "118743                 11119                  Commonwealth Edison Company   \n",
       "...                      ...                                          ...   \n",
       "300894                  2218                  Commonwealth Edison Company   \n",
       "292165                  1609                  Commonwealth Edison Company   \n",
       "300914                  2218                  Commonwealth Edison Company   \n",
       "184890                 15423                  Commonwealth Edison Company   \n",
       "300927                  2223                  Commonwealth Edison Company   \n",
       "\n",
       "       RegionCode            FromBus               ToBus TertiaryBus   Miles  \\\n",
       "28729         RFC              Aetna         Lake George         NaN   4.900   \n",
       "28739         RFC              Aetna              Miller         NaN   0.500   \n",
       "184865        RFC       Libertyville           Aptakisic         NaN  10.133   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "118743        RFC  Electric Junction              Aurora         NaN   1.433   \n",
       "...           ...                ...                 ...         ...     ...   \n",
       "300894        RFC               Zion          Northbrook         NaN  26.210   \n",
       "292165        RFC           Waukegan                Zion         NaN  12.275   \n",
       "300914        RFC               Zion            Waukegan         NaN   5.283   \n",
       "184890        RFC       Libertyville  Zion Energy Center         NaN  12.300   \n",
       "300927        RFC               Zion  Zion Energy Center         NaN   5.982   \n",
       "\n",
       "        BESExemptedFlag  NumberOfTerminals  ... InsulatorTypeCode  \\\n",
       "28729               0.0                2.0  ...               NaN   \n",
       "28739               0.0                2.0  ...               NaN   \n",
       "184865              NaN                2.0  ...               NaN   \n",
       "118743              NaN                2.0  ...               NaN   \n",
       "118743              NaN                2.0  ...               NaN   \n",
       "...                 ...                ...  ...               ...   \n",
       "300894              0.0                2.0  ...               NaN   \n",
       "292165              NaN                2.0  ...               NaN   \n",
       "300914              NaN                2.0  ...               NaN   \n",
       "184890              NaN                2.0  ...               NaN   \n",
       "300927              NaN                2.0  ...               NaN   \n",
       "\n",
       "       CableTypeCode StructureMaterialCode  StructureTypeCode  \\\n",
       "28729            NaN                   NaN                NaN   \n",
       "28739            NaN                   NaN                NaN   \n",
       "184865           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "...              ...                   ...                ...   \n",
       "300894           NaN                   NaN                NaN   \n",
       "292165           NaN                   NaN                NaN   \n",
       "300914           NaN                   NaN                NaN   \n",
       "184890           NaN                   NaN                NaN   \n",
       "300927           NaN                   NaN                NaN   \n",
       "\n",
       "        CircuitsPerStructureCode  TerrainCode  ElevationCode  InServiceDate  \\\n",
       "28729                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "28739                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "184865                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "...                          ...          ...            ...            ...   \n",
       "300894                       NaN          NaN            NaN    1/1/13 0:00   \n",
       "292165                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300914                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "184890                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300927                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "\n",
       "        RetirementDate  Rec_ID  \n",
       "28729              NaN   60847  \n",
       "28739              NaN   22650  \n",
       "184865             NaN    2486  \n",
       "118743             NaN   55397  \n",
       "118743             NaN   69508  \n",
       "...                ...     ...  \n",
       "300894             NaN   55407  \n",
       "292165             NaN   60900  \n",
       "300914             NaN   60900  \n",
       "184890             NaN    2431  \n",
       "300927             NaN    2430  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "156dcf82-7e2f-435f-8130-0f88e6446d9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_reduced_df' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhousekeeping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     filter_tlines_by_latest_reported_year,  \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     get_latest_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     get_matched_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_reduced_df, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     sort_and_shift_columns, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sort_and_shift_columns_dfVelo, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_reduced_df' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a90094a-4828-43bf-9e60-43c1d0d7c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c51175a2-1757-4038-8f9c-610d9e26d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8ca439a-9700-488f-bb16-9c69ade85621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "036d1082-089c-489d-844c-768912ab8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .conda (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e69f35-560a-4983-86f9-5c7ce2e8ae03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhousekeeping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     filter_tlines_by_latest_reported_year,  \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     get_latest_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     get_matched_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_reduced_df, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     sort_and_shift_columns, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sort_and_shift_columns_dfVelo, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da19533f-39ca-4a5a-abdc-f308fa660a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1abbb6-28df-4ee5-ba5c-b680b2639d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6051000-c1af-463d-bebd-65e8fbe53c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597bdc04-b00b-4656-88f1-009c151d8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d16887-97dc-42de-92d2-bfbddfb3aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727528d4-9c5c-4430-8a1a-48c6c9fd8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "#     matched_indices = []\n",
    "\n",
    "#     # Iterate through both DataFrames\n",
    "#     for i in range(len(dfVeloSorted)):\n",
    "#         from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "#             dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "#         )\n",
    "#         for j in range(len(dfTadsLatest)):\n",
    "#             from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "#                 dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "#             )\n",
    "\n",
    "#             if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "#                 from_sub == to_bus and to_sub == from_bus\n",
    "#             ):\n",
    "#                 matched_indices.append(j)\n",
    "\n",
    "#     dfTadsMatched = dfTadsLatest.iloc[matched_indices].copy()\n",
    "\n",
    "#     return dfTadsMatched\n",
    "\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5be6eaf-c887-49a4-a048-4baefdd1256f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhousekeeping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     \u001b[39m# filter_tlines_by_latest_reported_year,  # Forward Declaration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     get_latest_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     get_matched_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_reduced_df, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     sort_and_shift_columns, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sort_and_shift_columns_dfVelo, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237d4128-c26f-4e41-963e-434b0b912caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c17bfc2c-8d75-4ee5-977b-fefe2316cf04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhousekeeping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     \u001b[39m# filter_tlines_by_latest_reported_year,  # Forward Declaration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     get_latest_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     get_matched_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_reduced_df, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     sort_and_shift_columns, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sort_and_shift_columns_dfVelo, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22852bc-b1ff-4763-af3f-18655f4184f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3279b4e2-b07c-4b9b-86b3-b9044f7f12be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhousekeeping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     \u001b[39m# filter_tlines_by_latest_reported_year,  # Forward Declaration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     get_latest_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     get_matched_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_reduced_df, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     sort_and_shift_columns, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sort_and_shift_columns_dfVelo, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffed5ca5-0f2f-4dff-962f-bba9b797f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Create a dynamic combo option string\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49f5b33-ed76-49b2-bd0b-0c2e6122de36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhousekeeping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     \u001b[39m# filter_tlines_by_latest_reported_year,  # Forward Declaration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     get_latest_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     get_matched_entries, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     get_reduced_df, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     sort_and_shift_columns, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     sort_and_shift_columns_dfVelo, \u001b[39m# Forward Declaration\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_matched_entries' from 'src.housekeeping' (c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .conda (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5e6028-c435-4f58-bdea-d8a0c60d9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1ce70c-7018-4a48-ae83-2b20b5943cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # pylint: disable=undefined-variable line-too-long invalid-name\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec65556-1462-4bb5-86f7-95e915284012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5775086d-692f-48ea-8764-237ddd7fc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f86ce5-aa4d-4167-84e4-a992ad9c6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbc4732-98ae-4dc8-ad41-3556fc892c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # pylint: disable=undefined-variable line-too-long invalid-name\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80079f51-f95b-4e15-b251-4b01c808a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-081c3e414d19>:3: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfTads0 = pd.read_csv(tadsFileAddr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TADS db before filtering: 301152, 47\n",
      "There are 304 unique companies owning tlines in the entire TADS database.\n"
     ]
    }
   ],
   "source": [
    "tadsFileAddr = os.path.join(rawDataFolder, \"TADS 2024 AC Inventory.csv\")\n",
    "dfTads0 = pd.read_csv(tadsFileAddr)\n",
    "sizeTads0 = dfTads0.shape\n",
    "print(f\"Size of TADS db before filtering: {sizeTads0[0]}, {sizeTads0[1]}\")\n",
    "companyNamesTads0 = set(dfTads0.CompanyName)\n",
    "numCompaniesTads0 = len(companyNamesTads0)\n",
    "print(f\"There are {numCompaniesTads0} unique companies owning tlines in the entire TADS database.\")\n",
    "# display(dftads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b456bf-c73b-484b-8fff-37f790130b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\tlines-near-chicago-ohare-raw.xlsx\n",
      "Size of velocity suite db before any filtering: 524, 21\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "veloFileAddr = os.path.join(rawDataFolder, \"tlines-near-chicago-ohare-raw.xlsx\") # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c6d2a0-069a-4312-8b99-1d142ef1da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': 459, 21\n",
      "There are 6 named companies owning the tlines near chicago-ohare\n",
      "Their names are:\n",
      "{'AmerenIP', 'Undetermined Company', 'Commonwealth Edison Co', 'Northern Municipal Power Agency', 'Northern Indiana Public Service Co LLC', 'American Transmission Co LLC'}\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2213ede-32bc-47e4-8563-902e4b3fbf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's see how many tlines are owned by these 6 companies in the entire TADS database:\n",
      "But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\n",
      "{'American Transmission Company', 'Commonwealth Edison Company', 'Northern Indiana Public Service Company [BA', 'Ameren Services Company'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now let's see how many tlines are owned by these {numCompaniesVelo} \"       \"companies in the entire TADS database:\")\n",
    "\n",
    "print(\"\"f\"But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\")\n",
    "\n",
    "companyNamesVelo2Tads = companyNamesVelo.copy()  # Create a copy to avoid modifying the original\n",
    "\n",
    "# Replace the element using the 'discard' method (more efficient for sets)\n",
    "companyNamesVelo2Tads.discard(\"Commonwealth Edison Co\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "companyNamesVelo2Tads.discard(\"AmerenIP\")\n",
    "companyNamesVelo2Tads.add(\"Ameren Services Company\")\n",
    "companyNamesVelo2Tads.discard(\"American Transmission Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"American Transmission Company\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Indiana Public Service Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Municipal Power Agency\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Undetermined Company\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "print(companyNamesVelo2Tads)\n",
    "\n",
    "dfVeloSorted = sort_and_shift_columns_dfVelo(dfVelo)\n",
    "\n",
    "veloSortedAddr = os.path.join(processedDataFolder, \"dfVelo-Chicago-Ohare-Sorted.xlsx\")\n",
    "dfVeloSorted.to_excel(veloSortedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98301bbf-c125-4b18-83c4-7c1d44bcaa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100-199 kV', '600-799 kV', '200-299 kV', '300-399 kV'}\n",
      "Size of TADS db after filtering: 16052, 47\n",
      "Size of TADS db after filtering for only latest reported year: 1705, 47\n"
     ]
    }
   ],
   "source": [
    "dfTads = dfTads0.copy()\n",
    "dfTads = dfTads[dfTads['CompanyName'].isin(companyNamesVelo2Tads)]\n",
    "voltageClassesTads0 = set(dfTads['VoltageClassCodeName'])\n",
    "print(voltageClassesTads0)\n",
    "voltageClassesAllowedTads = voltageClassesTads0.copy()\n",
    "voltageClassesAllowedTads.discard(\"0-99 kV\")\n",
    "\n",
    "dfTads = dfTads[dfTads['VoltageClassCodeName'].isin(voltageClassesAllowedTads)]\n",
    "\n",
    "sizeTads = dfTads.shape\n",
    "print(f\"Size of TADS db after filtering: {sizeTads[0]}, {sizeTads[1]}\")\n",
    "\n",
    "dfTadsSorted = sort_and_shift_columns(dfTads)\n",
    "\n",
    "tadsSortedAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "dfTadsSorted.to_excel(tadsSortedAddr, index=False)\n",
    "\n",
    "# dfTadsLatest = filter_tlines_by_latest_reported_year(dfTadsSorted)\n",
    "dfTadsLatest = get_latest_entries(dfTadsSorted)\n",
    "\n",
    "sizeTadsLatest = dfTadsLatest.shape\n",
    "\n",
    "print(f\"Size of TADS db after filtering for only latest reported year: {sizeTadsLatest[0]}, {sizeTadsLatest[1]}\")\n",
    "\n",
    "tadsLatestAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "dfTadsLatest.to_excel(tadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2b2c044-178e-47ac-939b-4ff93bb94d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = get_matched_entries(dfVeloSorted, dfTadsLatest)\n",
    "matchAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Matched.xlsx\")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebceee68-3bd1-4366-9cb5-67f627b22a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df7a012-a456-4a79-b63d-89f8c74f9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c859b9-05bf-4132-adbe-2d552ce6158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = get_matched_entries(dfVeloSorted, dfTadsLatest)\n",
    "matchAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Matched.xlsx\")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bfb3a92-a958-44fe-b8a3-0a35152e7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d57599d-7d79-48eb-b87e-7f4b80b90941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Create a dynamic combo option string using the first word\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729                  ACO - Aetna - Lake George - 138054\n",
       "28739                       ACO - Aetna - Miller - 138102\n",
       "184865             ACO - Libertyville - Aptakisic - 15410\n",
       "118743           ACO - Electric Junction - Aurora - 11119\n",
       "118743           ACO - Electric Junction - Aurora - 11119\n",
       "                               ...                       \n",
       "300894                     ACO - Zion - Northbrook - 2218\n",
       "292165                       ACO - Waukegan - Zion - 1609\n",
       "300914                       ACO - Zion - Waukegan - 2218\n",
       "184890    ACO - Libertyville - Zion Energy Center - 15423\n",
       "300927             ACO - Zion - Zion Energy Center - 2223\n",
       "Name: combo, Length: 127, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatchReduced['combo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e96eebd2-9121-45da-a139-dafb49e1b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe03bd2d-9df2-4b7d-92d7-27752db059d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\processedData/chicago-ohare-lines.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m dfMatchReduced \u001b[39m=\u001b[39m get_reduced_df(dfMatch)\n\u001b[0;32m      3\u001b[0m matchReducedAddr \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(processedDataFolder, \u001b[39m\"\u001b[39m\u001b[39mchicago-ohare-lines.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m dfMatchReduced\u001b[39m.\u001b[39;49mto_excel(matchReducedAddr, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:2414\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2401\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2403\u001b[0m formatter \u001b[39m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2404\u001b[0m     df,\n\u001b[0;32m   2405\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2412\u001b[0m     inf_rep\u001b[39m=\u001b[39minf_rep,\n\u001b[0;32m   2413\u001b[0m )\n\u001b[1;32m-> 2414\u001b[0m formatter\u001b[39m.\u001b[39;49mwrite(\n\u001b[0;32m   2415\u001b[0m     excel_writer,\n\u001b[0;32m   2416\u001b[0m     sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m   2417\u001b[0m     startrow\u001b[39m=\u001b[39;49mstartrow,\n\u001b[0;32m   2418\u001b[0m     startcol\u001b[39m=\u001b[39;49mstartcol,\n\u001b[0;32m   2419\u001b[0m     freeze_panes\u001b[39m=\u001b[39;49mfreeze_panes,\n\u001b[0;32m   2420\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m   2421\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2422\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m   2423\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[39m=\u001b[39m ExcelWriter(\n\u001b[0;32m    944\u001b[0m         writer,\n\u001b[0;32m    945\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    946\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    947\u001b[0m         engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    948\u001b[0m     )\n\u001b[0;32m    949\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworkbook\u001b[39;00m \u001b[39mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[39m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     62\u001b[0m     path,\n\u001b[0;32m     63\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m     64\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m     65\u001b[0m     if_sheet_exists\u001b[39m=\u001b[39;49mif_sheet_exists,\n\u001b[0;32m     66\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[39m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode:  \u001b[39m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles \u001b[39m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[39mbytes\u001b[39m], path), compression\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1247\u001b[0m         path, mode, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[0;32m   1249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cur_sheet \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[39mif\u001b[39;00m date_format \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\processedData/chicago-ohare-lines.xlsx'"
     ]
    }
   ],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7bae3c5-4d55-450a-9293-4f9cec3a6e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb90ddf-99f9-43ad-991d-1f32cf3a0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Create a dynamic combo option string using the first word\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} - {row['FromBus']} - {row['ToBus']} - {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\") # no longer needed\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2bab56d-d0b4-4138-bdaa-66d12aac8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccfea26e-8cce-4e1e-8c0f-4396d5fdd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus, ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Create a dynamic combo option string using the first word\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['FromBus']}-{row['ToBus']}-{row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\") # no longer needed\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")  # Remove 'combo' column and store it\n",
    "    df_reduced_copy.insert(\n",
    "        loc=0, column=\"combo\", value=col\n",
    "    )  # Insert 'combo' as the first column\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c6dcb2-662e-4bc9-9df8-0b0d0d46ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d5d365d-c77c-48e2-b96c-27a4ff4a917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # pylint: disable=undefined-variable line-too-long invalid-name\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b4723ed-0218-4202-a538-035b5de1e1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-081c3e414d19>:3: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfTads0 = pd.read_csv(tadsFileAddr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TADS db before filtering: 301152, 47\n",
      "There are 304 unique companies owning tlines in the entire TADS database.\n"
     ]
    }
   ],
   "source": [
    "tadsFileAddr = os.path.join(rawDataFolder, \"TADS 2024 AC Inventory.csv\")\n",
    "dfTads0 = pd.read_csv(tadsFileAddr)\n",
    "sizeTads0 = dfTads0.shape\n",
    "print(f\"Size of TADS db before filtering: {sizeTads0[0]}, {sizeTads0[1]}\")\n",
    "companyNamesTads0 = set(dfTads0.CompanyName)\n",
    "numCompaniesTads0 = len(companyNamesTads0)\n",
    "print(f\"There are {numCompaniesTads0} unique companies owning tlines in the entire TADS database.\")\n",
    "# display(dftads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ced5833-0548-4e6b-9926-d5398314ab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\tlines-near-chicago-ohare-raw.xlsx\n",
      "Size of velocity suite db before any filtering: 524, 21\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "veloFileAddr = os.path.join(rawDataFolder, \"tlines-near-chicago-ohare-raw.xlsx\") # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe7fee9-f2ce-4228-ae26-dba9ea230542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': 459, 21\n",
      "There are 6 named companies owning the tlines near chicago-ohare\n",
      "Their names are:\n",
      "{'AmerenIP', 'Undetermined Company', 'Commonwealth Edison Co', 'Northern Municipal Power Agency', 'Northern Indiana Public Service Co LLC', 'American Transmission Co LLC'}\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "953f064f-0ef6-4538-9264-b125f957a518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's see how many tlines are owned by these 6 companies in the entire TADS database:\n",
      "But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\n",
      "{'American Transmission Company', 'Commonwealth Edison Company', 'Northern Indiana Public Service Company [BA', 'Ameren Services Company'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now let's see how many tlines are owned by these {numCompaniesVelo} \"       \"companies in the entire TADS database:\")\n",
    "\n",
    "print(\"\"f\"But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\")\n",
    "\n",
    "companyNamesVelo2Tads = companyNamesVelo.copy()  # Create a copy to avoid modifying the original\n",
    "\n",
    "# Replace the element using the 'discard' method (more efficient for sets)\n",
    "companyNamesVelo2Tads.discard(\"Commonwealth Edison Co\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "companyNamesVelo2Tads.discard(\"AmerenIP\")\n",
    "companyNamesVelo2Tads.add(\"Ameren Services Company\")\n",
    "companyNamesVelo2Tads.discard(\"American Transmission Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"American Transmission Company\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Indiana Public Service Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Municipal Power Agency\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Undetermined Company\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "print(companyNamesVelo2Tads)\n",
    "\n",
    "dfVeloSorted = sort_and_shift_columns_dfVelo(dfVelo)\n",
    "\n",
    "veloSortedAddr = os.path.join(processedDataFolder, \"dfVelo-Chicago-Ohare-Sorted.xlsx\")\n",
    "dfVeloSorted.to_excel(veloSortedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7d1d1fe-fc1d-43b8-8b15-c0aff19690ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100-199 kV', '600-799 kV', '200-299 kV', '300-399 kV'}\n",
      "Size of TADS db after filtering: 16052, 47\n",
      "Size of TADS db after filtering for only latest reported year: 1705, 47\n"
     ]
    }
   ],
   "source": [
    "dfTads = dfTads0.copy()\n",
    "dfTads = dfTads[dfTads['CompanyName'].isin(companyNamesVelo2Tads)]\n",
    "voltageClassesTads0 = set(dfTads['VoltageClassCodeName'])\n",
    "print(voltageClassesTads0)\n",
    "voltageClassesAllowedTads = voltageClassesTads0.copy()\n",
    "voltageClassesAllowedTads.discard(\"0-99 kV\")\n",
    "\n",
    "dfTads = dfTads[dfTads['VoltageClassCodeName'].isin(voltageClassesAllowedTads)]\n",
    "\n",
    "sizeTads = dfTads.shape\n",
    "print(f\"Size of TADS db after filtering: {sizeTads[0]}, {sizeTads[1]}\")\n",
    "\n",
    "dfTadsSorted = sort_and_shift_columns(dfTads)\n",
    "\n",
    "tadsSortedAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "dfTadsSorted.to_excel(tadsSortedAddr, index=False)\n",
    "\n",
    "# dfTadsLatest = filter_tlines_by_latest_reported_year(dfTadsSorted)\n",
    "dfTadsLatest = get_latest_entries(dfTadsSorted)\n",
    "\n",
    "sizeTadsLatest = dfTadsLatest.shape\n",
    "\n",
    "print(f\"Size of TADS db after filtering for only latest reported year: {sizeTadsLatest[0]}, {sizeTadsLatest[1]}\")\n",
    "\n",
    "tadsLatestAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "dfTadsLatest.to_excel(tadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00cba00b-969e-4f8c-8edb-646717617659",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = get_matched_entries(dfVeloSorted, dfTadsLatest)\n",
    "matchAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Matched.xlsx\")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f0c070-f4d1-49ee-8d9f-dbc8ea9c56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "078ce076-9d98-45a6-b2cc-83b74920c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>ACO Aptakisic-Libertyville 15410</td>\n",
       "      <td>15410</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO Aurora-Electric Junction 11119</td>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO Aurora-Electric Junction 11119</td>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO Northbrook-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>ACO Waukegan-Zion 1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO Waukegan-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>ACO Libertyville-Zion Energy Center 15423</td>\n",
       "      <td>15423</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO Zion-Zion Energy Center 2223</td>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            combo ElementIdentifierName  \\\n",
       "28729                ACO Aetna-Lake George 138054                138054   \n",
       "28739                     ACO Aetna-Miller 138102                138102   \n",
       "184865           ACO Aptakisic-Libertyville 15410                 15410   \n",
       "118743         ACO Aurora-Electric Junction 11119                 11119   \n",
       "118743         ACO Aurora-Electric Junction 11119                 11119   \n",
       "...                                           ...                   ...   \n",
       "300894                   ACO Northbrook-Zion 2218                  2218   \n",
       "292165                     ACO Waukegan-Zion 1609                  1609   \n",
       "300914                     ACO Waukegan-Zion 2218                  2218   \n",
       "184890  ACO Libertyville-Zion Energy Center 15423                 15423   \n",
       "300927           ACO Zion-Zion Energy Center 2223                  2223   \n",
       "\n",
       "                                        CompanyName RegionCode  \\\n",
       "28729   Northern Indiana Public Service Company [BA        RFC   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC   \n",
       "184865                  Commonwealth Edison Company        RFC   \n",
       "118743                  Commonwealth Edison Company        RFC   \n",
       "118743                  Commonwealth Edison Company        RFC   \n",
       "...                                             ...        ...   \n",
       "300894                  Commonwealth Edison Company        RFC   \n",
       "292165                  Commonwealth Edison Company        RFC   \n",
       "300914                  Commonwealth Edison Company        RFC   \n",
       "184890                  Commonwealth Edison Company        RFC   \n",
       "300927                  Commonwealth Edison Company        RFC   \n",
       "\n",
       "                  FromBus               ToBus TertiaryBus   Miles  \\\n",
       "28729               Aetna         Lake George         NaN   4.900   \n",
       "28739               Aetna              Miller         NaN   0.500   \n",
       "184865       Libertyville           Aptakisic         NaN  10.133   \n",
       "118743  Electric Junction              Aurora         NaN   1.433   \n",
       "118743  Electric Junction              Aurora         NaN   1.433   \n",
       "...                   ...                 ...         ...     ...   \n",
       "300894               Zion          Northbrook         NaN  26.210   \n",
       "292165           Waukegan                Zion         NaN  12.275   \n",
       "300914               Zion            Waukegan         NaN   5.283   \n",
       "184890       Libertyville  Zion Energy Center         NaN  12.300   \n",
       "300927               Zion  Zion Energy Center         NaN   5.982   \n",
       "\n",
       "        BESExemptedFlag  NumberOfTerminals  ... InsulatorTypeCode  \\\n",
       "28729               0.0                2.0  ...               NaN   \n",
       "28739               0.0                2.0  ...               NaN   \n",
       "184865              NaN                2.0  ...               NaN   \n",
       "118743              NaN                2.0  ...               NaN   \n",
       "118743              NaN                2.0  ...               NaN   \n",
       "...                 ...                ...  ...               ...   \n",
       "300894              0.0                2.0  ...               NaN   \n",
       "292165              NaN                2.0  ...               NaN   \n",
       "300914              NaN                2.0  ...               NaN   \n",
       "184890              NaN                2.0  ...               NaN   \n",
       "300927              NaN                2.0  ...               NaN   \n",
       "\n",
       "       CableTypeCode StructureMaterialCode  StructureTypeCode  \\\n",
       "28729            NaN                   NaN                NaN   \n",
       "28739            NaN                   NaN                NaN   \n",
       "184865           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "118743           NaN                   NaN                NaN   \n",
       "...              ...                   ...                ...   \n",
       "300894           NaN                   NaN                NaN   \n",
       "292165           NaN                   NaN                NaN   \n",
       "300914           NaN                   NaN                NaN   \n",
       "184890           NaN                   NaN                NaN   \n",
       "300927           NaN                   NaN                NaN   \n",
       "\n",
       "        CircuitsPerStructureCode  TerrainCode  ElevationCode  InServiceDate  \\\n",
       "28729                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "28739                        NaN          NaN            NaN    1/1/15 0:00   \n",
       "184865                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "118743                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "...                          ...          ...            ...            ...   \n",
       "300894                       NaN          NaN            NaN    1/1/13 0:00   \n",
       "292165                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300914                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "184890                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "300927                       NaN          NaN            NaN    1/1/15 0:00   \n",
       "\n",
       "        RetirementDate  Rec_ID  \n",
       "28729              NaN   60847  \n",
       "28739              NaN   22650  \n",
       "184865             NaN    2486  \n",
       "118743             NaN   55397  \n",
       "118743             NaN   69508  \n",
       "...                ...     ...  \n",
       "300894             NaN   55407  \n",
       "292165             NaN   60900  \n",
       "300914             NaN   60900  \n",
       "184890             NaN    2431  \n",
       "300927             NaN    2430  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatchReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4d43c0f-7373-406d-9624-bed6eafe0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9adc9eac-6e46-475b-ae66-d296fabbc378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "154e8f45-aebb-4ab1-9f7e-640368a536d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8523241-c462-4c88-b68e-352ba300b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "280465f3-11ad-46df-b25a-2bb4cb2dbf9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_excel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_py.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m dfMatchReduced \u001b[39m=\u001b[39m get_reduced_df(dfMatch)\n\u001b[0;32m      3\u001b[0m matchReducedAddr \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(processedDataFolder, \u001b[39m\"\u001b[39m\u001b[39mchicago-ohare-lines.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m dfMatchReduced\u001b[39m.\u001b[39;49mto_excel(matchReducedAddr, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_excel'"
     ]
    }
   ],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2544d98b-b97d-4a4b-8a30-8d762fcba2ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-9969bc970303>, line 220)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[43], line 220\u001b[1;36m\u001b[0m\n\u001b[1;33m    ``\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "``\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d23d87be-9390-4331-bb91-72aef734d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m size(dfMatchReduced)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'size' is not defined"
     ]
    }
   ],
   "source": [
    "size(dfMatchReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfMatchReduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .conda (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6299fdd-f322-463b-9e00-44df30fd9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837908ca-28bd-4c4c-ab4f-4ebe72383288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfMatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y \u001b[39m=\u001b[39m get_reduced_df(dfMatch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfMatch' is not defined"
     ]
    }
   ],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafd49ab-9b3b-48c1-aa26-08c29eaa13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3939d2a-5d1a-428f-9948-62eed3b049a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # pylint: disable=undefined-variable line-too-long invalid-name\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16f1564-2509-4fce-90f1-6b2a78e46736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TADS db before filtering: 301152, 47\n",
      "There are 304 unique companies owning tlines in the entire TADS database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-081c3e414d19>:3: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfTads0 = pd.read_csv(tadsFileAddr)\n"
     ]
    }
   ],
   "source": [
    "tadsFileAddr = os.path.join(rawDataFolder, \"TADS 2024 AC Inventory.csv\")\n",
    "dfTads0 = pd.read_csv(tadsFileAddr)\n",
    "sizeTads0 = dfTads0.shape\n",
    "print(f\"Size of TADS db before filtering: {sizeTads0[0]}, {sizeTads0[1]}\")\n",
    "companyNamesTads0 = set(dfTads0.CompanyName)\n",
    "numCompaniesTads0 = len(companyNamesTads0)\n",
    "print(f\"There are {numCompaniesTads0} unique companies owning tlines in the entire TADS database.\")\n",
    "# display(dftads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809242bd-056c-4181-8268-9ea382ad2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\tlines-near-chicago-ohare-raw.xlsx\n",
      "Size of velocity suite db before any filtering: 524, 21\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "veloFileAddr = os.path.join(rawDataFolder, \"tlines-near-chicago-ohare-raw.xlsx\") # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a42bbbc-ed69-40d5-a67b-b31e2268c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': 459, 21\n",
      "There are 6 named companies owning the tlines near chicago-ohare\n",
      "Their names are:\n",
      "{'Undetermined Company', 'American Transmission Co LLC', 'AmerenIP', 'Commonwealth Edison Co', 'Northern Indiana Public Service Co LLC', 'Northern Municipal Power Agency'}\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91357517-dd3d-4a90-9fd8-b939917f3acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's see how many tlines are owned by these 6 companies in the entire TADS database:\n",
      "But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\n",
      "{'Northern Indiana Public Service Company [BA', 'American Transmission Company', 'Ameren Services Company', 'Commonwealth Edison Company'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now let's see how many tlines are owned by these {numCompaniesVelo} \"       \"companies in the entire TADS database:\")\n",
    "\n",
    "print(\"\"f\"But first I'll need to rename some companies in vs db to match with the exact strings of the TADS db.\")\n",
    "\n",
    "companyNamesVelo2Tads = companyNamesVelo.copy()  # Create a copy to avoid modifying the original\n",
    "\n",
    "# Replace the element using the 'discard' method (more efficient for sets)\n",
    "companyNamesVelo2Tads.discard(\"Commonwealth Edison Co\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "companyNamesVelo2Tads.discard(\"AmerenIP\")\n",
    "companyNamesVelo2Tads.add(\"Ameren Services Company\")\n",
    "companyNamesVelo2Tads.discard(\"American Transmission Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"American Transmission Company\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Indiana Public Service Co LLC\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Northern Municipal Power Agency\")\n",
    "companyNamesVelo2Tads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "companyNamesVelo2Tads.discard(\"Undetermined Company\")\n",
    "companyNamesVelo2Tads.add(\"Commonwealth Edison Company\")\n",
    "print(companyNamesVelo2Tads)\n",
    "\n",
    "dfVeloSorted = sort_and_shift_columns_dfVelo(dfVelo)\n",
    "\n",
    "veloSortedAddr = os.path.join(processedDataFolder, \"dfVelo-Chicago-Ohare-Sorted.xlsx\")\n",
    "dfVeloSorted.to_excel(veloSortedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bddbf27b-7bba-4c1a-897e-c38005569dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'600-799 kV', '300-399 kV', '200-299 kV', '100-199 kV'}\n",
      "Size of TADS db after filtering: 16052, 47\n",
      "Size of TADS db after filtering for only latest reported year: 1705, 47\n"
     ]
    }
   ],
   "source": [
    "dfTads = dfTads0.copy()\n",
    "dfTads = dfTads[dfTads['CompanyName'].isin(companyNamesVelo2Tads)]\n",
    "voltageClassesTads0 = set(dfTads['VoltageClassCodeName'])\n",
    "print(voltageClassesTads0)\n",
    "voltageClassesAllowedTads = voltageClassesTads0.copy()\n",
    "voltageClassesAllowedTads.discard(\"0-99 kV\")\n",
    "\n",
    "dfTads = dfTads[dfTads['VoltageClassCodeName'].isin(voltageClassesAllowedTads)]\n",
    "\n",
    "sizeTads = dfTads.shape\n",
    "print(f\"Size of TADS db after filtering: {sizeTads[0]}, {sizeTads[1]}\")\n",
    "\n",
    "dfTadsSorted = sort_and_shift_columns(dfTads)\n",
    "\n",
    "tadsSortedAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "dfTadsSorted.to_excel(tadsSortedAddr, index=False)\n",
    "\n",
    "# dfTadsLatest = filter_tlines_by_latest_reported_year(dfTadsSorted)\n",
    "dfTadsLatest = get_latest_entries(dfTadsSorted)\n",
    "\n",
    "sizeTadsLatest = dfTadsLatest.shape\n",
    "\n",
    "print(f\"Size of TADS db after filtering for only latest reported year: {sizeTadsLatest[0]}, {sizeTadsLatest[1]}\")\n",
    "\n",
    "tadsLatestAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "dfTadsLatest.to_excel(tadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6325409-20a9-455d-86d5-490435f6fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = get_matched_entries(dfVeloSorted, dfTadsLatest)\n",
    "matchAddr = os.path.join(processedDataFolder, \"dfTads-Chicago-Ohare-Matched.xlsx\")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6345c992-3121-40ea-be32-5591a77df0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28715</th>\n",
       "      <td>ACO Aetna-Dune Acres 138006</td>\n",
       "      <td>138006</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>ACO Arcadian-Zion 2222</td>\n",
       "      <td>2222</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Arcadian</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>12/30/22 0:00</td>\n",
       "      <td>52054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300876</th>\n",
       "      <td>ACO Lakeview-Zion 28201</td>\n",
       "      <td>28201</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Lakeview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300888</th>\n",
       "      <td>ACO Libertyville-Zion 2224</td>\n",
       "      <td>2224</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO Northbrook-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO Waukegan-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO Zion-Zion Energy Center 2223</td>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   combo ElementIdentifierName  \\\n",
       "28715        ACO Aetna-Dune Acres 138006                138006   \n",
       "28729       ACO Aetna-Lake George 138054                138054   \n",
       "28739            ACO Aetna-Miller 138102                138102   \n",
       "28739            ACO Aetna-Miller 138102                138102   \n",
       "11121             ACO Arcadian-Zion 2222                  2222   \n",
       "...                                  ...                   ...   \n",
       "300876           ACO Lakeview-Zion 28201                 28201   \n",
       "300888        ACO Libertyville-Zion 2224                  2224   \n",
       "300894          ACO Northbrook-Zion 2218                  2218   \n",
       "300914            ACO Waukegan-Zion 2218                  2218   \n",
       "300927  ACO Zion-Zion Energy Center 2223                  2223   \n",
       "\n",
       "                                        CompanyName RegionCode   FromBus  \\\n",
       "28715   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28729   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "11121                 American Transmission Company        MRO  Arcadian   \n",
       "...                                             ...        ...       ...   \n",
       "300876                  Commonwealth Edison Company        RFC      Zion   \n",
       "300888                  Commonwealth Edison Company        RFC      Zion   \n",
       "300894                  Commonwealth Edison Company        RFC      Zion   \n",
       "300914                  Commonwealth Edison Company        RFC      Zion   \n",
       "300927                  Commonwealth Edison Company        RFC      Zion   \n",
       "\n",
       "                     ToBus TertiaryBus   Miles  BESExemptedFlag  \\\n",
       "28715           Dune Acres         NaN  11.700              0.0   \n",
       "28729          Lake George         NaN   4.900              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "11121                 Zion         NaN  53.100              NaN   \n",
       "...                    ...         ...     ...              ...   \n",
       "300876            Lakeview         NaN   5.070              0.0   \n",
       "300888        Libertyville         NaN  18.502              NaN   \n",
       "300894          Northbrook         NaN  26.210              0.0   \n",
       "300914            Waukegan         NaN   5.283              NaN   \n",
       "300927  Zion Energy Center         NaN   5.982              NaN   \n",
       "\n",
       "        NumberOfTerminals  ... InsulatorTypeCode CableTypeCode  \\\n",
       "28715                 2.0  ...               NaN           NaN   \n",
       "28729                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "11121                 2.0  ...               NaN           NaN   \n",
       "...                   ...  ...               ...           ...   \n",
       "300876                2.0  ...               NaN           NaN   \n",
       "300888                2.0  ...               NaN           NaN   \n",
       "300894                2.0  ...               NaN           NaN   \n",
       "300914                2.0  ...               NaN           NaN   \n",
       "300927                2.0  ...               NaN           NaN   \n",
       "\n",
       "       StructureMaterialCode  StructureTypeCode  CircuitsPerStructureCode  \\\n",
       "28715                    NaN                NaN                       NaN   \n",
       "28729                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "11121                    NaN                NaN                       NaN   \n",
       "...                      ...                ...                       ...   \n",
       "300876                   NaN                NaN                       NaN   \n",
       "300888                   NaN                NaN                       NaN   \n",
       "300894                   NaN                NaN                       NaN   \n",
       "300914                   NaN                NaN                       NaN   \n",
       "300927                   NaN                NaN                       NaN   \n",
       "\n",
       "        TerrainCode  ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28715           NaN            NaN    1/1/15 0:00             NaN   50026  \n",
       "28729           NaN            NaN    1/1/15 0:00             NaN   60847  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   22650  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   70313  \n",
       "11121           NaN            NaN    1/1/15 0:00   12/30/22 0:00   52054  \n",
       "...             ...            ...            ...             ...     ...  \n",
       "300876          NaN            NaN    1/1/13 0:00             NaN   60901  \n",
       "300888          NaN            NaN    1/1/15 0:00             NaN   62352  \n",
       "300894          NaN            NaN    1/1/13 0:00             NaN   55407  \n",
       "300914          NaN            NaN    1/1/15 0:00             NaN   60900  \n",
       "300927          NaN            NaN    1/1/15 0:00             NaN    2430  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatchReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d72c08-464e-484d-a015-8f5a7c4984d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-14-1da1f8e398d6>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 78\u001b[1;36m\u001b[0m\n\u001b[1;33m    lambda row: f\"{row['Circuit\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "  \"\"\"\n",
    "  This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "  with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "  Args:\n",
    "      dfMatch: The input pandas DataFrame.\n",
    "\n",
    "  Returns:\n",
    "      A new DataFrame containing the following columns:\n",
    "          - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "          - 'ElementIdentifierName'\n",
    "          - 'CompanyName'\n",
    "          - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "          - 'RetirementDate' (added)\n",
    "          - 'Rec_ID' (added)\n",
    "  \"\"\"\n",
    "\n",
    "  # Select desired columns from the input DataFrame\n",
    "  desired_cols = [\n",
    "      \"ElementIdentifierName\",\n",
    "      \"CompanyName\",\n",
    "      \"RegionCode\",\n",
    "      \"FromBus\",\n",
    "      \"ToBus\",\n",
    "      \"TertiaryBus\",\n",
    "      \"Miles\",\n",
    "      \"BESExemptedFlag\",\n",
    "      \"NumberOfTerminals\",\n",
    "      \"CircuitTypeCode\",\n",
    "      \"VoltageClassCodeName\",\n",
    "      \"ParentCode\",\n",
    "      \"ConductorsPerPhaseCode\",\n",
    "      \"OverheadGroundWireCode\",\n",
    "      \"InsulatorTypeCode\",\n",
    "      \"CableTypeCode\",\n",
    "      \"StructureMaterialCode\",\n",
    "      \"StructureTypeCode\",\n",
    "      \"CircuitsPerStructureCode\",\n",
    "      \"TerrainCode\",\n",
    "      \"ElevationCode\",\n",
    "      \"InServiceDate\",\n",
    "      \"RetirementDate\",\n",
    "      \"Rec_ID\",\n",
    "  ]\n",
    "\n",
    "  df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "  # Create a copy of the DataFrame to avoid modifying the original\n",
    "  df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "  # Check for Empty Strings (Optional)\n",
    "  if df_reduced_copy['FromBus'].notna().all() and df_reduced_copy['ToBus'].notna().all():\n",
    "      pass  # No empty strings, proceed\n",
    "  else:\n",
    "      # Replace empty strings with a consistent value (e.g., 'NA')\n",
    "      df_reduced_copy['FromBus'] = df_reduced_copy['FromBus'].fillna('NA')\n",
    "      df_reduced_copy['ToBus'] = df_reduced_copy['ToBus'].fillna('NA')\n",
    "\n",
    "  # Extract the first word from CircuitTypeCode\n",
    "  df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "  # Print intermediate sorted values (for debugging)\n",
    "  print(df_reduced_copy[['FromBus', 'ToBus']].apply(lambda x: \"-\".join(sorted(x)), axis=1).head())\n",
    "\n",
    "  # Temporary column to store the sorted Bus combination\n",
    "  df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "      lambda x: \"-\".join(sorted(x)), axis=1\n",
    "  )\n",
    "\n",
    "  # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "  df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "      lambda row: f\"{row['Circuit\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0932ab78-9295-4224-ae2a-61d3c9b5d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Check for Empty Strings (Optional)\n",
    "    if df_reduced_copy['FromBus'].notna().all() and df_reduced_copy['ToBus'].notna().all():\n",
    "        pass  # No empty strings, proceed\n",
    "    else:\n",
    "        # Replace empty strings with a consistent value (e.g., 'NA')\n",
    "        df_reduced_copy['FromBus'] = df_reduced_copy['FromBus'].fillna('NA')\n",
    "        df_reduced_copy['ToBus'] = df_reduced_copy['ToBus'].fillna('NA')\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Print intermediate sorted values (for debugging)\n",
    "    print(df_reduced_copy[['FromBus', 'ToBus']].apply(lambda x: \"-\".join(sorted(x)), axis=1).head())\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28729            Aetna-Lake George\n",
      "28739                 Aetna-Miller\n",
      "184865      Aptakisic-Libertyville\n",
      "118743    Aurora-Electric Junction\n",
      "118743    Aurora-Electric Junction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fa3575-0c7d-4534-ac62-8e5600757390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Check for Empty Strings (Optional)\n",
    "    if df_reduced_copy['FromBus'].notna().all() and df_reduced_copy['ToBus'].notna().all():\n",
    "        pass  # No empty strings, proceed\n",
    "    else:\n",
    "        # Replace empty strings with a consistent value (e.g., 'NA')\n",
    "        df_reduced_copy['FromBus'] = df_reduced_copy['FromBus'].fillna('NA')\n",
    "        df_reduced_copy['ToBus'] = df_reduced_copy['ToBus'].fillna('NA')\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Print intermediate sorted values (for debugging)\n",
    "    print(df_reduced_copy[['FromBus', 'ToBus']].apply(lambda x: \"-\".join(sorted(x)), axis=1).head())\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729               Aetna         Lake George              2024   \n",
       "28739               Aetna              Miller              2024   \n",
       "184865       Libertyville           Aptakisic              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "118743  Electric Junction              Aurora              2024   \n",
       "...                   ...                 ...               ...   \n",
       "300894               Zion          Northbrook              2014   \n",
       "292165           Waukegan                Zion              2024   \n",
       "300914               Zion            Waukegan              2024   \n",
       "184890       Libertyville  Zion Energy Center              2024   \n",
       "300927               Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28729            Aetna-Lake George\n",
      "28739                 Aetna-Miller\n",
      "184865      Aptakisic-Libertyville\n",
      "118743    Aurora-Electric Junction\n",
      "118743    Aurora-Electric Junction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85baaa3d-9e59-46b1-82a0-5df208a8ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Check for Empty Strings (Optional)\n",
    "    if df_reduced_copy['FromBus'].notna().all() and df_reduced_copy['ToBus'].notna().all():\n",
    "        pass  # No empty strings, proceed\n",
    "    else:\n",
    "        # Replace empty strings with a consistent value (e.g., 'NA')\n",
    "        df_reduced_copy['FromBus'] = df_reduced_copy['FromBus'].fillna('NA')\n",
    "        df_reduced_copy['ToBus'] = df_reduced_copy['ToBus'].fillna('NA')\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Print intermediate sorted values (for debugging)\n",
    "    print(df_reduced_copy[['FromBus', 'ToBus']].apply(lambda x: \"-\".join(sorted(x)), axis=1).head())\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28729            Aetna-Lake George\n",
      "28739                 Aetna-Miller\n",
      "184865      Aptakisic-Libertyville\n",
      "118743    Aurora-Electric Junction\n",
      "118743    Aurora-Electric Junction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1826c5d-8954-4f34-8783-725a83161c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus (ensures FromBus < ToBus)\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Create a dynamic combo option string (no need for separate sorting)\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode']} {row['FromBus']}-{row['ToBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28715</th>\n",
       "      <td>ACO - AC Overhead Aetna-Dune Acres 138006</td>\n",
       "      <td>138006</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO - AC Overhead Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO - AC Overhead Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO - AC Overhead Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>ACO - AC Overhead Arcadian-Zion 2222</td>\n",
       "      <td>2222</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Arcadian</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>12/30/22 0:00</td>\n",
       "      <td>52054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300876</th>\n",
       "      <td>ACO - AC Overhead Zion-Lakeview 28201</td>\n",
       "      <td>28201</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Lakeview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300888</th>\n",
       "      <td>ACO - AC Overhead Zion-Libertyville 2224</td>\n",
       "      <td>2224</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO - AC Overhead Zion-Northbrook 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO - AC Overhead Zion-Waukegan 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO - AC Overhead Zion-Zion Energy Center 2223</td>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 combo ElementIdentifierName  \\\n",
       "28715        ACO - AC Overhead Aetna-Dune Acres 138006                138006   \n",
       "28729       ACO - AC Overhead Aetna-Lake George 138054                138054   \n",
       "28739            ACO - AC Overhead Aetna-Miller 138102                138102   \n",
       "28739            ACO - AC Overhead Aetna-Miller 138102                138102   \n",
       "11121             ACO - AC Overhead Arcadian-Zion 2222                  2222   \n",
       "...                                                ...                   ...   \n",
       "300876           ACO - AC Overhead Zion-Lakeview 28201                 28201   \n",
       "300888        ACO - AC Overhead Zion-Libertyville 2224                  2224   \n",
       "300894          ACO - AC Overhead Zion-Northbrook 2218                  2218   \n",
       "300914            ACO - AC Overhead Zion-Waukegan 2218                  2218   \n",
       "300927  ACO - AC Overhead Zion-Zion Energy Center 2223                  2223   \n",
       "\n",
       "                                        CompanyName RegionCode   FromBus  \\\n",
       "28715   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28729   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "11121                 American Transmission Company        MRO  Arcadian   \n",
       "...                                             ...        ...       ...   \n",
       "300876                  Commonwealth Edison Company        RFC      Zion   \n",
       "300888                  Commonwealth Edison Company        RFC      Zion   \n",
       "300894                  Commonwealth Edison Company        RFC      Zion   \n",
       "300914                  Commonwealth Edison Company        RFC      Zion   \n",
       "300927                  Commonwealth Edison Company        RFC      Zion   \n",
       "\n",
       "                     ToBus TertiaryBus   Miles  BESExemptedFlag  \\\n",
       "28715           Dune Acres         NaN  11.700              0.0   \n",
       "28729          Lake George         NaN   4.900              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "11121                 Zion         NaN  53.100              NaN   \n",
       "...                    ...         ...     ...              ...   \n",
       "300876            Lakeview         NaN   5.070              0.0   \n",
       "300888        Libertyville         NaN  18.502              NaN   \n",
       "300894          Northbrook         NaN  26.210              0.0   \n",
       "300914            Waukegan         NaN   5.283              NaN   \n",
       "300927  Zion Energy Center         NaN   5.982              NaN   \n",
       "\n",
       "        NumberOfTerminals  ... InsulatorTypeCode CableTypeCode  \\\n",
       "28715                 2.0  ...               NaN           NaN   \n",
       "28729                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "11121                 2.0  ...               NaN           NaN   \n",
       "...                   ...  ...               ...           ...   \n",
       "300876                2.0  ...               NaN           NaN   \n",
       "300888                2.0  ...               NaN           NaN   \n",
       "300894                2.0  ...               NaN           NaN   \n",
       "300914                2.0  ...               NaN           NaN   \n",
       "300927                2.0  ...               NaN           NaN   \n",
       "\n",
       "       StructureMaterialCode  StructureTypeCode  CircuitsPerStructureCode  \\\n",
       "28715                    NaN                NaN                       NaN   \n",
       "28729                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "11121                    NaN                NaN                       NaN   \n",
       "...                      ...                ...                       ...   \n",
       "300876                   NaN                NaN                       NaN   \n",
       "300888                   NaN                NaN                       NaN   \n",
       "300894                   NaN                NaN                       NaN   \n",
       "300914                   NaN                NaN                       NaN   \n",
       "300927                   NaN                NaN                       NaN   \n",
       "\n",
       "        TerrainCode  ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28715           NaN            NaN    1/1/15 0:00             NaN   50026  \n",
       "28729           NaN            NaN    1/1/15 0:00             NaN   60847  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   22650  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   70313  \n",
       "11121           NaN            NaN    1/1/15 0:00   12/30/22 0:00   52054  \n",
       "...             ...            ...            ...             ...     ...  \n",
       "300876          NaN            NaN    1/1/13 0:00             NaN   60901  \n",
       "300888          NaN            NaN    1/1/15 0:00             NaN   62352  \n",
       "300894          NaN            NaN    1/1/13 0:00             NaN   55407  \n",
       "300914          NaN            NaN    1/1/15 0:00             NaN   60900  \n",
       "300927          NaN            NaN    1/1/15 0:00             NaN    2430  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c719330f-c37e-4d3e-b0dc-2505f8e75c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Check for Empty Strings (Optional)\n",
    "    if df_reduced_copy['FromBus'].notna().all() and df_reduced_copy['ToBus'].notna().all():\n",
    "        pass  # No empty strings, proceed\n",
    "    else:\n",
    "        # Replace empty strings with a consistent value (e.g., 'NA')\n",
    "        df_reduced_copy['FromBus'] = df_reduced_copy['FromBus'].fillna('NA')\n",
    "        df_reduced_copy['ToBus'] = df_reduced_copy['ToBus'].fillna('NA')\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Print intermediate sorted values (for debugging)\n",
    "    print(df_reduced_copy[['FromBus', 'ToBus']].apply(lambda x: \"-\".join(sorted(x)), axis=1).head())\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28729            Aetna-Lake George\n",
      "28739                 Aetna-Miller\n",
      "184865      Aptakisic-Libertyville\n",
      "118743    Aurora-Electric Junction\n",
      "118743    Aurora-Electric Junction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abaa86fa-fb3f-4908-96d6-03fa75751951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Check for Empty Strings (Optional)\n",
    "    if df_reduced_copy['FromBus'].notna().all() and df_reduced_copy['ToBus'].notna().all():\n",
    "        pass  # No empty strings, proceed\n",
    "    else:\n",
    "        # Replace empty strings with a consistent value (e.g., 'NA')\n",
    "        df_reduced_copy['FromBus'] = df_reduced_copy['FromBus'].fillna('NA')\n",
    "        df_reduced_copy['ToBus'] = df_reduced_copy['ToBus'].fillna('NA')\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "\n",
    "    # Print intermediate sorted values (for debugging)\n",
    "    print(df_reduced_copy[['FromBus', 'ToBus']].apply(lambda x: \"-\".join(sorted(x)), axis=1).head())\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28729            Aetna-Lake George\n",
      "28739                 Aetna-Miller\n",
      "184865      Aptakisic-Libertyville\n",
      "118743    Aurora-Electric Junction\n",
      "118743    Aurora-Electric Junction\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2caee2ac-62d0-4816-a2fd-4e674a6581e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "def rearrange_buses(df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame (df) and returns a new DataFrame with 'FromBus'\n",
    "    lexicographically smaller than 'ToBus'.\n",
    "\n",
    "    Args:\n",
    "        df: The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with 'FromBus' always preceding 'ToBus'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_rearranged = df.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "    return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28715</th>\n",
       "      <td>ACO Aetna-Dune Acres 138006</td>\n",
       "      <td>138006</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>ACO Arcadian-Zion 2222</td>\n",
       "      <td>2222</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Arcadian</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>12/30/22 0:00</td>\n",
       "      <td>52054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300876</th>\n",
       "      <td>ACO Lakeview-Zion 28201</td>\n",
       "      <td>28201</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Lakeview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300888</th>\n",
       "      <td>ACO Libertyville-Zion 2224</td>\n",
       "      <td>2224</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>ACO Northbrook-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO Waukegan-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO Zion-Zion Energy Center 2223</td>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   combo ElementIdentifierName  \\\n",
       "28715        ACO Aetna-Dune Acres 138006                138006   \n",
       "28729       ACO Aetna-Lake George 138054                138054   \n",
       "28739            ACO Aetna-Miller 138102                138102   \n",
       "28739            ACO Aetna-Miller 138102                138102   \n",
       "11121             ACO Arcadian-Zion 2222                  2222   \n",
       "...                                  ...                   ...   \n",
       "300876           ACO Lakeview-Zion 28201                 28201   \n",
       "300888        ACO Libertyville-Zion 2224                  2224   \n",
       "300894          ACO Northbrook-Zion 2218                  2218   \n",
       "300914            ACO Waukegan-Zion 2218                  2218   \n",
       "300927  ACO Zion-Zion Energy Center 2223                  2223   \n",
       "\n",
       "                                        CompanyName RegionCode   FromBus  \\\n",
       "28715   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28729   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC     Aetna   \n",
       "11121                 American Transmission Company        MRO  Arcadian   \n",
       "...                                             ...        ...       ...   \n",
       "300876                  Commonwealth Edison Company        RFC      Zion   \n",
       "300888                  Commonwealth Edison Company        RFC      Zion   \n",
       "300894                  Commonwealth Edison Company        RFC      Zion   \n",
       "300914                  Commonwealth Edison Company        RFC      Zion   \n",
       "300927                  Commonwealth Edison Company        RFC      Zion   \n",
       "\n",
       "                     ToBus TertiaryBus   Miles  BESExemptedFlag  \\\n",
       "28715           Dune Acres         NaN  11.700              0.0   \n",
       "28729          Lake George         NaN   4.900              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "11121                 Zion         NaN  53.100              NaN   \n",
       "...                    ...         ...     ...              ...   \n",
       "300876            Lakeview         NaN   5.070              0.0   \n",
       "300888        Libertyville         NaN  18.502              NaN   \n",
       "300894          Northbrook         NaN  26.210              0.0   \n",
       "300914            Waukegan         NaN   5.283              NaN   \n",
       "300927  Zion Energy Center         NaN   5.982              NaN   \n",
       "\n",
       "        NumberOfTerminals  ... InsulatorTypeCode CableTypeCode  \\\n",
       "28715                 2.0  ...               NaN           NaN   \n",
       "28729                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "11121                 2.0  ...               NaN           NaN   \n",
       "...                   ...  ...               ...           ...   \n",
       "300876                2.0  ...               NaN           NaN   \n",
       "300888                2.0  ...               NaN           NaN   \n",
       "300894                2.0  ...               NaN           NaN   \n",
       "300914                2.0  ...               NaN           NaN   \n",
       "300927                2.0  ...               NaN           NaN   \n",
       "\n",
       "       StructureMaterialCode  StructureTypeCode  CircuitsPerStructureCode  \\\n",
       "28715                    NaN                NaN                       NaN   \n",
       "28729                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "11121                    NaN                NaN                       NaN   \n",
       "...                      ...                ...                       ...   \n",
       "300876                   NaN                NaN                       NaN   \n",
       "300888                   NaN                NaN                       NaN   \n",
       "300894                   NaN                NaN                       NaN   \n",
       "300914                   NaN                NaN                       NaN   \n",
       "300927                   NaN                NaN                       NaN   \n",
       "\n",
       "        TerrainCode  ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28715           NaN            NaN    1/1/15 0:00             NaN   50026  \n",
       "28729           NaN            NaN    1/1/15 0:00             NaN   60847  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   22650  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   70313  \n",
       "11121           NaN            NaN    1/1/15 0:00   12/30/22 0:00   52054  \n",
       "...             ...            ...            ...             ...     ...  \n",
       "300876          NaN            NaN    1/1/13 0:00             NaN   60901  \n",
       "300888          NaN            NaN    1/1/15 0:00             NaN   62352  \n",
       "300894          NaN            NaN    1/1/13 0:00             NaN   55407  \n",
       "300914          NaN            NaN    1/1/15 0:00             NaN   60900  \n",
       "300927          NaN            NaN    1/1/15 0:00             NaN    2430  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>ACO Arcadian-Zion 2222</td>\n",
       "      <td>2222</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Arcadian</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>12/30/22 0:00</td>\n",
       "      <td>52054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41495</th>\n",
       "      <td>ACO Babcock-Lake George 345003</td>\n",
       "      <td>345003</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Babcock</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41979</th>\n",
       "      <td>ACO Albers-Bain 63143</td>\n",
       "      <td>63143</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Bain</td>\n",
       "      <td>Albers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41989</th>\n",
       "      <td>ACO Bain-Kenosha 63151</td>\n",
       "      <td>63151</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Bain</td>\n",
       "      <td>Kenosha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47634</th>\n",
       "      <td>ACO Bedford Park-Hayford 11521</td>\n",
       "      <td>11521</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bedford Park</td>\n",
       "      <td>Hayford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55732</th>\n",
       "      <td>ACO Bloom-Burnham 17908</td>\n",
       "      <td>17908</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55742</th>\n",
       "      <td>ACO Bloom-Davis Creek 17907</td>\n",
       "      <td>17907</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>Davis Creek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68623</th>\n",
       "      <td>ACO Blue Island-Burnham 17701</td>\n",
       "      <td>17701</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>Blue Island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68643</th>\n",
       "      <td>ACO Burnham-Calumet 17723</td>\n",
       "      <td>17723</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>Calumet</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>21.084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68666</th>\n",
       "      <td>ACO Burnham-Davis Creek 17704</td>\n",
       "      <td>17704</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>Davis Creek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68691</th>\n",
       "      <td>ACO Burnham-Tower Automotive 17715</td>\n",
       "      <td>17715</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>Tower Automotive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68710</th>\n",
       "      <td>ACO Burnham-Wildwood 17713</td>\n",
       "      <td>17713</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>Wildwood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68830</th>\n",
       "      <td>ACO Burns Ditch-Midwest Steel 138037</td>\n",
       "      <td>138037</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Burns Ditch</td>\n",
       "      <td>Midwest Steel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81804</th>\n",
       "      <td>ACO Cherry Valley-Glidden 15627</td>\n",
       "      <td>15627</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Cherry Valley</td>\n",
       "      <td>Glidden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81836</th>\n",
       "      <td>ACO Cherry Valley-Silver Lake 15616</td>\n",
       "      <td>15616</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Cherry Valley</td>\n",
       "      <td>Silver Lake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82532</th>\n",
       "      <td>ACO Bloom-Chicago Heights 7305</td>\n",
       "      <td>7305</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Chicago Heights</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      combo ElementIdentifierName  \\\n",
       "28729          ACO Aetna-Lake George 138054                138054   \n",
       "28739               ACO Aetna-Miller 138102                138102   \n",
       "28739               ACO Aetna-Miller 138102                138102   \n",
       "11121                ACO Arcadian-Zion 2222                  2222   \n",
       "41495        ACO Babcock-Lake George 345003                345003   \n",
       "41979                 ACO Albers-Bain 63143                 63143   \n",
       "41989                ACO Bain-Kenosha 63151                 63151   \n",
       "47634        ACO Bedford Park-Hayford 11521                 11521   \n",
       "55732               ACO Bloom-Burnham 17908                 17908   \n",
       "55742           ACO Bloom-Davis Creek 17907                 17907   \n",
       "68623         ACO Blue Island-Burnham 17701                 17701   \n",
       "68643             ACO Burnham-Calumet 17723                 17723   \n",
       "68666         ACO Burnham-Davis Creek 17704                 17704   \n",
       "68691    ACO Burnham-Tower Automotive 17715                 17715   \n",
       "68710            ACO Burnham-Wildwood 17713                 17713   \n",
       "68830  ACO Burns Ditch-Midwest Steel 138037                138037   \n",
       "81804       ACO Cherry Valley-Glidden 15627                 15627   \n",
       "81836   ACO Cherry Valley-Silver Lake 15616                 15616   \n",
       "82532        ACO Bloom-Chicago Heights 7305                  7305   \n",
       "\n",
       "                                       CompanyName RegionCode  \\\n",
       "28729  Northern Indiana Public Service Company [BA        RFC   \n",
       "28739  Northern Indiana Public Service Company [BA        RFC   \n",
       "28739  Northern Indiana Public Service Company [BA        RFC   \n",
       "11121                American Transmission Company        MRO   \n",
       "41495  Northern Indiana Public Service Company [BA        RFC   \n",
       "41979                American Transmission Company        MRO   \n",
       "41989                American Transmission Company        MRO   \n",
       "47634                  Commonwealth Edison Company        RFC   \n",
       "55732                  Commonwealth Edison Company        RFC   \n",
       "55742                  Commonwealth Edison Company        RFC   \n",
       "68623                  Commonwealth Edison Company        RFC   \n",
       "68643                  Commonwealth Edison Company        RFC   \n",
       "68666                  Commonwealth Edison Company        RFC   \n",
       "68691                  Commonwealth Edison Company        RFC   \n",
       "68710                  Commonwealth Edison Company        RFC   \n",
       "68830  Northern Indiana Public Service Company [BA        RFC   \n",
       "81804                  Commonwealth Edison Company        RFC   \n",
       "81836                  Commonwealth Edison Company        RFC   \n",
       "82532                  Commonwealth Edison Company        RFC   \n",
       "\n",
       "               FromBus             ToBus TertiaryBus   Miles  BESExemptedFlag  \\\n",
       "28729            Aetna       Lake George         NaN   4.900              0.0   \n",
       "28739            Aetna            Miller         NaN   0.500              0.0   \n",
       "28739            Aetna            Miller         NaN   0.500              0.0   \n",
       "11121         Arcadian              Zion         NaN  53.100              NaN   \n",
       "41495          Babcock       Lake George         NaN  12.000              0.0   \n",
       "41979             Bain            Albers         NaN   4.790              NaN   \n",
       "41989             Bain           Kenosha         NaN   1.650              NaN   \n",
       "47634     Bedford Park           Hayford         NaN   5.650              0.0   \n",
       "55732            Bloom           Burnham         NaN  12.420              NaN   \n",
       "55742            Bloom       Davis Creek         NaN  37.505              NaN   \n",
       "68623          Burnham       Blue Island         NaN   8.380              0.0   \n",
       "68643          Burnham           Calumet      Taylor  21.084              NaN   \n",
       "68666          Burnham       Davis Creek         NaN  49.910              NaN   \n",
       "68691          Burnham  Tower Automotive         NaN   2.710              NaN   \n",
       "68710          Burnham          Wildwood         NaN   5.452              NaN   \n",
       "68830      Burns Ditch     Midwest Steel         NaN   0.800              0.0   \n",
       "81804    Cherry Valley           Glidden         NaN  29.114              NaN   \n",
       "81836    Cherry Valley       Silver Lake         NaN  40.548              NaN   \n",
       "82532  Chicago Heights             Bloom         NaN   2.493              NaN   \n",
       "\n",
       "       NumberOfTerminals  ... InsulatorTypeCode CableTypeCode  \\\n",
       "28729                2.0  ...               NaN           NaN   \n",
       "28739                2.0  ...               NaN           NaN   \n",
       "28739                2.0  ...               NaN           NaN   \n",
       "11121                2.0  ...               NaN           NaN   \n",
       "41495                2.0  ...               NaN           NaN   \n",
       "41979                2.0  ...               NaN           NaN   \n",
       "41989                2.0  ...               NaN           NaN   \n",
       "47634                2.0  ...               NaN           NaN   \n",
       "55732                2.0  ...               NaN           NaN   \n",
       "55742                2.0  ...               NaN           NaN   \n",
       "68623                2.0  ...               NaN           NaN   \n",
       "68643                3.0  ...               NaN           NaN   \n",
       "68666                2.0  ...               NaN           NaN   \n",
       "68691                2.0  ...               NaN           NaN   \n",
       "68710                2.0  ...               NaN           NaN   \n",
       "68830                2.0  ...               NaN           NaN   \n",
       "81804                2.0  ...               NaN           NaN   \n",
       "81836                2.0  ...               NaN           NaN   \n",
       "82532                2.0  ...               NaN           NaN   \n",
       "\n",
       "      StructureMaterialCode  StructureTypeCode  CircuitsPerStructureCode  \\\n",
       "28729                   NaN                NaN                       NaN   \n",
       "28739                   NaN                NaN                       NaN   \n",
       "28739                   NaN                NaN                       NaN   \n",
       "11121                   NaN                NaN                       NaN   \n",
       "41495                   NaN                NaN                       NaN   \n",
       "41979                   NaN                NaN                       NaN   \n",
       "41989                   NaN                NaN                       NaN   \n",
       "47634                   NaN                NaN                       NaN   \n",
       "55732                   NaN                NaN                       NaN   \n",
       "55742                   NaN                NaN                       NaN   \n",
       "68623                   NaN                NaN                       NaN   \n",
       "68643                   NaN                NaN                       NaN   \n",
       "68666                   NaN                NaN                       NaN   \n",
       "68691                   NaN                NaN                       NaN   \n",
       "68710                   NaN                NaN                       NaN   \n",
       "68830                   NaN                NaN                       NaN   \n",
       "81804                   NaN                NaN                       NaN   \n",
       "81836                   NaN                NaN                       NaN   \n",
       "82532                   NaN                NaN                       NaN   \n",
       "\n",
       "       TerrainCode  ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28729          NaN            NaN    1/1/15 0:00             NaN   60847  \n",
       "28739          NaN            NaN    1/1/15 0:00             NaN   22650  \n",
       "28739          NaN            NaN    1/1/15 0:00             NaN   70313  \n",
       "11121          NaN            NaN    1/1/15 0:00   12/30/22 0:00   52054  \n",
       "41495          NaN            NaN    1/1/13 0:00             NaN   55461  \n",
       "41979          NaN            NaN    1/1/15 0:00             NaN   71534  \n",
       "41989          NaN            NaN    1/1/15 0:00             NaN    7127  \n",
       "47634          NaN            NaN    1/1/13 0:00             NaN    2593  \n",
       "55732          NaN            NaN    1/1/15 0:00             NaN    2798  \n",
       "55742          NaN            NaN    1/1/15 0:00             NaN    2792  \n",
       "68623          NaN            NaN    1/1/13 0:00             NaN   55442  \n",
       "68643          NaN            NaN    1/1/15 0:00             NaN   61331  \n",
       "68666          NaN            NaN    1/1/15 0:00             NaN   60822  \n",
       "68691          NaN            NaN    1/1/15 0:00             NaN   62360  \n",
       "68710          NaN            NaN    1/1/15 0:00             NaN    2577  \n",
       "68830          NaN            NaN    1/1/15 0:00             NaN   69257  \n",
       "81804          NaN            NaN    1/1/15 0:00             NaN    2683  \n",
       "81836          NaN            NaN    1/1/15 0:00             NaN   52310  \n",
       "82532          NaN            NaN    1/1/15 0:00             NaN   61854  \n",
       "\n",
       "[19 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01950028-ac94-480c-8f22-fcb4f51a3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "\n",
    "def rearrangeColumns(df, col_x, col_y):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (df), column names (col_x, col_y),\n",
    "    and exchanges the values in those columns if val_x is bigger than val_y for each row.\n",
    "\n",
    "    Args:\n",
    "        df: The input pandas DataFrame.\n",
    "        col_x: The name of the first column.\n",
    "        col_y: The name of the second column.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with columns x and y potentially exchanged based on the condition.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply a lambda function to compare and potentially swap values\n",
    "    df_copy[[col_x, col_y]] = df_copy[[col_x, col_y]].where(\n",
    "        df_copy[col_x] <= df_copy[col_y], [df_copy[col_y], df_copy[col_x]]\n",
    "    )\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f173b35c-4212-4a89-a582-57b0aeec0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "\n",
    "def rearrangeColumns(df, col_x='FromBus', col_y='ToBus'):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (df), column names (col_x, col_y),\n",
    "    and exchanges the values in those columns if val_x is bigger than val_y for each row.\n",
    "\n",
    "    Args:\n",
    "        df: The input pandas DataFrame.\n",
    "        col_x: The name of the first column.\n",
    "        col_y: The name of the second column.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with columns x and y potentially exchanged based on the condition.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply a lambda function to compare and potentially swap values\n",
    "    df_copy[[col_x, col_y]] = df_copy[[col_x, col_y]].where(\n",
    "        df_copy[col_x] <= df_copy[col_y], [df_copy[col_y], df_copy[col_x]]\n",
    "    )\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (127,2) (127,2) (2,127) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rearrangeColumns(dfMatch)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py:243\u001b[0m\n\u001b[0;32m    240\u001b[0m df_copy \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    242\u001b[0m \u001b[39m# Apply a lambda function to compare and potentially swap values\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m df_copy[[col_x, col_y]] \u001b[39m=\u001b[39m df_copy[[col_x, col_y]]\u001b[39m.\u001b[39;49mwhere(\n\u001b[0;32m    244\u001b[0m     df_copy[col_x] \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m df_copy[col_y], [df_copy[col_y], df_copy[col_x]]\n\u001b[0;32m    245\u001b[0m )\n\u001b[0;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m df_copy\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:10981\u001b[0m, in \u001b[0;36mNDFrame.where\u001b[1;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[0;32m  10974\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m  10975\u001b[0m                 _chained_assignment_warning_method_msg,\n\u001b[0;32m  10976\u001b[0m                 \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m  10977\u001b[0m                 stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m  10978\u001b[0m             )\n\u001b[0;32m  10980\u001b[0m other \u001b[39m=\u001b[39m common\u001b[39m.\u001b[39mapply_if_callable(other, \u001b[39mself\u001b[39m)\n\u001b[1;32m> 10981\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_where(cond, other, inplace, axis, level)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:10756\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[1;34m(self, cond, other, inplace, axis, level, warn)\u001b[0m\n\u001b[0;32m  10753\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(result)\n\u001b[0;32m  10755\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m> 10756\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mwhere(\n\u001b[0;32m  10757\u001b[0m         other\u001b[39m=\u001b[39;49mother,\n\u001b[0;32m  10758\u001b[0m         cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m  10759\u001b[0m         align\u001b[39m=\u001b[39;49malign,\n\u001b[0;32m  10760\u001b[0m     )\n\u001b[0;32m  10761\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[0;32m  10762\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\internals\\base.py:204\u001b[0m, in \u001b[0;36mDataManager.where\u001b[1;34m(self, other, cond, align)\u001b[0m\n\u001b[0;32m    201\u001b[0m     align_keys \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    202\u001b[0m     other \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_with_block(\n\u001b[0;32m    205\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mwhere\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    206\u001b[0m     align_keys\u001b[39m=\u001b[39;49malign_keys,\n\u001b[0;32m    207\u001b[0m     other\u001b[39m=\u001b[39;49mother,\n\u001b[0;32m    208\u001b[0m     cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m    209\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    210\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1634\u001b[0m, in \u001b[0;36mBlock.where\u001b[1;34m(self, other, cond, _downcast, using_cow)\u001b[0m\n\u001b[0;32m   1629\u001b[0m             other \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(other)\u001b[39m.\u001b[39mreshape(values\u001b[39m.\u001b[39mshape)\n\u001b[0;32m   1630\u001b[0m             \u001b[39m# If lengths don't match (or len(other)==1), we will raise\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m             \u001b[39m#  inside expressions.where, see test_series_where\u001b[39;00m\n\u001b[0;32m   1632\u001b[0m \n\u001b[0;32m   1633\u001b[0m         \u001b[39m# Note: expressions.where may upcast.\u001b[39;00m\n\u001b[1;32m-> 1634\u001b[0m         result \u001b[39m=\u001b[39m expressions\u001b[39m.\u001b[39;49mwhere(\u001b[39m~\u001b[39;49micond, values, other)\n\u001b[0;32m   1635\u001b[0m         \u001b[39m# The np_can_hold_element check _should_ ensure that we always\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m         \u001b[39m#  have result.dtype == self.dtype here.\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:259\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(cond, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[39mEvaluate the where condition cond on a and b.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39m    Whether to try to use numexpr.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39massert\u001b[39;00m _where \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[39mreturn\u001b[39;00m _where(cond, a, b) \u001b[39mif\u001b[39;00m use_numexpr \u001b[39melse\u001b[39;00m _where_standard(cond, a, b)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:189\u001b[0m, in \u001b[0;36m_where_numexpr\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    182\u001b[0m     result \u001b[39m=\u001b[39m ne\u001b[39m.\u001b[39mevaluate(\n\u001b[0;32m    183\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhere(cond_value, a_value, b_value)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m         local_dict\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcond_value\u001b[39m\u001b[39m\"\u001b[39m: cond, \u001b[39m\"\u001b[39m\u001b[39ma_value\u001b[39m\u001b[39m\"\u001b[39m: a, \u001b[39m\"\u001b[39m\u001b[39mb_value\u001b[39m\u001b[39m\"\u001b[39m: b},\n\u001b[0;32m    185\u001b[0m         casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msafe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     result \u001b[39m=\u001b[39m _where_standard(cond, a, b)\n\u001b[0;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:174\u001b[0m, in \u001b[0;36m_where_standard\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_where_standard\u001b[39m(cond, a, b):\n\u001b[0;32m    173\u001b[0m     \u001b[39m# Caller is responsible for extracting ndarray if necessary\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mwhere(cond, a, b)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (127,2) (127,2) (2,127) "
     ]
    }
   ],
   "source": [
    "rearrangeColumns(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0abbf8ef-714b-4bb8-9a44-49915bef2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "\n",
    "def rearrangeColumns(df, col_x='FromBus', col_y='ToBus'):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (df), column names (col_x, col_y),\n",
    "    and exchanges the values in those columns if val_x is bigger than val_y for each row,\n",
    "    while keeping other columns unchanged.\n",
    "\n",
    "    Args:\n",
    "        df: The input pandas DataFrame.\n",
    "        col_x: The name of the first column.\n",
    "        col_y: The name of the second column.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with columns x and y potentially exchanged based on the condition.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Select the columns to potentially exchange and other columns\n",
    "    cols_to_exchange = [col_x, col_y]\n",
    "    other_cols = list(set(df_copy.columns) - set(cols_to_exchange))\n",
    "\n",
    "    # Apply a lambda function to compare and potentially swap values\n",
    "    df_copy[cols_to_exchange] = df_copy[cols_to_exchange].where(\n",
    "        df_copy[col_x] <= df_copy[col_y], [df_copy[col_y], df_copy[col_x]]\n",
    "    )\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (127,2) (127,2) (2,127) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rearrangeColumns(dfMatch)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\src\\housekeeping.py:248\u001b[0m\n\u001b[0;32m    245\u001b[0m other_cols \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(df_copy\u001b[39m.\u001b[39mcolumns) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(cols_to_exchange))\n\u001b[0;32m    247\u001b[0m \u001b[39m# Apply a lambda function to compare and potentially swap values\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m df_copy[cols_to_exchange] \u001b[39m=\u001b[39m df_copy[cols_to_exchange]\u001b[39m.\u001b[39;49mwhere(\n\u001b[0;32m    249\u001b[0m     df_copy[col_x] \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m df_copy[col_y], [df_copy[col_y], df_copy[col_x]]\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m df_copy\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:10981\u001b[0m, in \u001b[0;36mNDFrame.where\u001b[1;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[0;32m  10974\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m  10975\u001b[0m                 _chained_assignment_warning_method_msg,\n\u001b[0;32m  10976\u001b[0m                 \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m  10977\u001b[0m                 stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m  10978\u001b[0m             )\n\u001b[0;32m  10980\u001b[0m other \u001b[39m=\u001b[39m common\u001b[39m.\u001b[39mapply_if_callable(other, \u001b[39mself\u001b[39m)\n\u001b[1;32m> 10981\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_where(cond, other, inplace, axis, level)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\generic.py:10756\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[1;34m(self, cond, other, inplace, axis, level, warn)\u001b[0m\n\u001b[0;32m  10753\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(result)\n\u001b[0;32m  10755\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m> 10756\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mwhere(\n\u001b[0;32m  10757\u001b[0m         other\u001b[39m=\u001b[39;49mother,\n\u001b[0;32m  10758\u001b[0m         cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m  10759\u001b[0m         align\u001b[39m=\u001b[39;49malign,\n\u001b[0;32m  10760\u001b[0m     )\n\u001b[0;32m  10761\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[0;32m  10762\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\internals\\base.py:204\u001b[0m, in \u001b[0;36mDataManager.where\u001b[1;34m(self, other, cond, align)\u001b[0m\n\u001b[0;32m    201\u001b[0m     align_keys \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    202\u001b[0m     other \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_with_block(\n\u001b[0;32m    205\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mwhere\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    206\u001b[0m     align_keys\u001b[39m=\u001b[39;49malign_keys,\n\u001b[0;32m    207\u001b[0m     other\u001b[39m=\u001b[39;49mother,\n\u001b[0;32m    208\u001b[0m     cond\u001b[39m=\u001b[39;49mcond,\n\u001b[0;32m    209\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    210\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1634\u001b[0m, in \u001b[0;36mBlock.where\u001b[1;34m(self, other, cond, _downcast, using_cow)\u001b[0m\n\u001b[0;32m   1629\u001b[0m             other \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(other)\u001b[39m.\u001b[39mreshape(values\u001b[39m.\u001b[39mshape)\n\u001b[0;32m   1630\u001b[0m             \u001b[39m# If lengths don't match (or len(other)==1), we will raise\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m             \u001b[39m#  inside expressions.where, see test_series_where\u001b[39;00m\n\u001b[0;32m   1632\u001b[0m \n\u001b[0;32m   1633\u001b[0m         \u001b[39m# Note: expressions.where may upcast.\u001b[39;00m\n\u001b[1;32m-> 1634\u001b[0m         result \u001b[39m=\u001b[39m expressions\u001b[39m.\u001b[39;49mwhere(\u001b[39m~\u001b[39;49micond, values, other)\n\u001b[0;32m   1635\u001b[0m         \u001b[39m# The np_can_hold_element check _should_ ensure that we always\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m         \u001b[39m#  have result.dtype == self.dtype here.\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:259\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(cond, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[39mEvaluate the where condition cond on a and b.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39m    Whether to try to use numexpr.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39massert\u001b[39;00m _where \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[39mreturn\u001b[39;00m _where(cond, a, b) \u001b[39mif\u001b[39;00m use_numexpr \u001b[39melse\u001b[39;00m _where_standard(cond, a, b)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:189\u001b[0m, in \u001b[0;36m_where_numexpr\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    182\u001b[0m     result \u001b[39m=\u001b[39m ne\u001b[39m.\u001b[39mevaluate(\n\u001b[0;32m    183\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhere(cond_value, a_value, b_value)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m         local_dict\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcond_value\u001b[39m\u001b[39m\"\u001b[39m: cond, \u001b[39m\"\u001b[39m\u001b[39ma_value\u001b[39m\u001b[39m\"\u001b[39m: a, \u001b[39m\"\u001b[39m\u001b[39mb_value\u001b[39m\u001b[39m\"\u001b[39m: b},\n\u001b[0;32m    185\u001b[0m         casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msafe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     result \u001b[39m=\u001b[39m _where_standard(cond, a, b)\n\u001b[0;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:174\u001b[0m, in \u001b[0;36m_where_standard\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_where_standard\u001b[39m(cond, a, b):\n\u001b[0;32m    173\u001b[0m     \u001b[39m# Caller is responsible for extracting ndarray if necessary\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mwhere(cond, a, b)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (127,2) (127,2) (2,127) "
     ]
    }
   ],
   "source": [
    "rearrangeColumns(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a94e56c7-af7d-43c8-916f-0d485fb90ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "\n",
    "def rearrangeColumns(df, col1=\"FromBus\", col2=\"ToBus\"):\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Iterate through each row and swap col1 and col2 if necessary\n",
    "    for index, row in df.iterrows():\n",
    "        value1 = str(row[col1])\n",
    "        value2 = str(row[col2])\n",
    "\n",
    "        if value1 > value2:\n",
    "            df.at[index, col1] = value2\n",
    "            df.at[index, col2] = value1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>ReportingYearNbr</th>\n",
       "      <th>InventoryDataDetailID</th>\n",
       "      <th>InventoryDataID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CompanyCode</th>\n",
       "      <th>NERCID</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>UpdateDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>Slicer</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>2024</td>\n",
       "      <td>113936</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>636757</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113936 | 2024</td>\n",
       "      <td>0x10ED02D26825C003EE3B8BB374B3D856</td>\n",
       "      <td>1</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>2024</td>\n",
       "      <td>113983</td>\n",
       "      <td>9259</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>NCR02611 | RFC</td>\n",
       "      <td>NCR02611</td>\n",
       "      <td>0x294791EC91004582F3E1DB12ADA4BB03</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>642142</td>\n",
       "      <td>1</td>\n",
       "      <td>9259 | 113983 | 2024</td>\n",
       "      <td>0xBB81DBE68DB618667B9650E57C7267EA</td>\n",
       "      <td>1</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>2024</td>\n",
       "      <td>118818</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650912</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118818 | 2024</td>\n",
       "      <td>0xAF15167B2979EF5C2EDF9A7BA84F1C01</td>\n",
       "      <td>1</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>2024</td>\n",
       "      <td>119072</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625367</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119072 | 2024</td>\n",
       "      <td>0x2A3F37E31771BB4D9468566640B78822</td>\n",
       "      <td>1</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300894</th>\n",
       "      <td>Northbrook</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2014</td>\n",
       "      <td>31789</td>\n",
       "      <td>5803</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>10:05.5</td>\n",
       "      <td>08:34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00.9</td>\n",
       "      <td>216720</td>\n",
       "      <td>1</td>\n",
       "      <td>5803 | 31789 | 2014</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>118840</td>\n",
       "      <td>9400</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>650849</td>\n",
       "      <td>1</td>\n",
       "      <td>9400 | 118840 | 2024</td>\n",
       "      <td>0x128D3A78E37B1B206191C78D9B5D7C4C</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>2024</td>\n",
       "      <td>119042</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625328</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119042 | 2024</td>\n",
       "      <td>0xD7BAD6B5D071292FD40F898CABBC9677</td>\n",
       "      <td>1</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184890</th>\n",
       "      <td>Libertyville</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119100</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625419</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119100 | 2024</td>\n",
       "      <td>0xC81DBDBE35DD273C67BADAA182719325</td>\n",
       "      <td>1</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>2024</td>\n",
       "      <td>119044</td>\n",
       "      <td>9402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>NCR08013 | RFC | RFC - PJM</td>\n",
       "      <td>NCR08013</td>\n",
       "      <td>0xCC2BCCB6A749329A905A8A66AA5A99DB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>...</td>\n",
       "      <td>05:07.9</td>\n",
       "      <td>00:01.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01:21.7</td>\n",
       "      <td>625330</td>\n",
       "      <td>1</td>\n",
       "      <td>9402 | 119044 | 2024</td>\n",
       "      <td>0xC21A84D1CF465517E3067BE5D830BD02</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FromBus               ToBus  ReportingYearNbr  \\\n",
       "28729          Aetna         Lake George              2024   \n",
       "28739          Aetna              Miller              2024   \n",
       "184865     Aptakisic        Libertyville              2024   \n",
       "118743        Aurora   Electric Junction              2024   \n",
       "118743        Aurora   Electric Junction              2024   \n",
       "...              ...                 ...               ...   \n",
       "300894    Northbrook                Zion              2014   \n",
       "292165      Waukegan                Zion              2024   \n",
       "300914      Waukegan                Zion              2024   \n",
       "184890  Libertyville  Zion Energy Center              2024   \n",
       "300927          Zion  Zion Energy Center              2024   \n",
       "\n",
       "        InventoryDataDetailID  InventoryDataID  \\\n",
       "28729                  113936             9259   \n",
       "28739                  113983             9259   \n",
       "184865                 118818             9400   \n",
       "118743                 119072             9402   \n",
       "118743                 119072             9402   \n",
       "...                       ...              ...   \n",
       "300894                  31789             5803   \n",
       "292165                 118840             9400   \n",
       "300914                 119042             9402   \n",
       "184890                 119100             9402   \n",
       "300927                 119044             9402   \n",
       "\n",
       "                                        CompanyName  \\\n",
       "28729   Northern Indiana Public Service Company [BA   \n",
       "28739   Northern Indiana Public Service Company [BA   \n",
       "184865                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "118743                  Commonwealth Edison Company   \n",
       "...                                             ...   \n",
       "300894                  Commonwealth Edison Company   \n",
       "292165                  Commonwealth Edison Company   \n",
       "300914                  Commonwealth Edison Company   \n",
       "184890                  Commonwealth Edison Company   \n",
       "300927                  Commonwealth Edison Company   \n",
       "\n",
       "                       CompanyCode    NERCID  \\\n",
       "28729               NCR02611 | RFC  NCR02611   \n",
       "28739               NCR02611 | RFC  NCR02611   \n",
       "184865  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "118743  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "...                            ...       ...   \n",
       "300894  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "292165  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300914  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "184890  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "300927  NCR08013 | RFC | RFC - PJM  NCR08013   \n",
       "\n",
       "                            NERCID_AliasID RegionCode  ... ExtractionDT  \\\n",
       "28729   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "28739   0x294791EC91004582F3E1DB12ADA4BB03        RFC  ...      05:07.9   \n",
       "184865  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "118743  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "...                                    ...        ...  ...          ...   \n",
       "300894  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      10:05.5   \n",
       "292165  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300914  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "184890  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "300927  0xCC2BCCB6A749329A905A8A66AA5A99DB        RFC  ...      05:07.9   \n",
       "\n",
       "       UpdateDT DeletionDT NERC_DataPullDT   ID_SK Rnk                Slicer  \\\n",
       "28729   00:01.0        NaN         01:21.7  636757   1  9259 | 113936 | 2024   \n",
       "28739   00:01.0        NaN         01:21.7  642142   1  9259 | 113983 | 2024   \n",
       "184865  00:01.0        NaN         01:21.7  650912   1  9400 | 118818 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "118743  00:01.0        NaN         01:21.7  625367   1  9402 | 119072 | 2024   \n",
       "...         ...        ...             ...     ...  ..                   ...   \n",
       "300894  08:34.2        NaN         00:00.9  216720   1   5803 | 31789 | 2014   \n",
       "292165  00:01.0        NaN         01:21.7  650849   1  9400 | 118840 | 2024   \n",
       "300914  00:01.0        NaN         01:21.7  625328   1  9402 | 119042 | 2024   \n",
       "184890  00:01.0        NaN         01:21.7  625419   1  9402 | 119100 | 2024   \n",
       "300927  00:01.0        NaN         01:21.7  625330   1  9402 | 119044 | 2024   \n",
       "\n",
       "                                   AliasID  IsCurrent  Rec_ID  \n",
       "28729   0x10ED02D26825C003EE3B8BB374B3D856          1   60847  \n",
       "28739   0xBB81DBE68DB618667B9650E57C7267EA          1   22650  \n",
       "184865  0xAF15167B2979EF5C2EDF9A7BA84F1C01          1    2486  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   55397  \n",
       "118743  0x2A3F37E31771BB4D9468566640B78822          1   69508  \n",
       "...                                    ...        ...     ...  \n",
       "300894  0xD7BAD6B5D071292FD40F898CABBC9677          1   55407  \n",
       "292165  0x128D3A78E37B1B206191C78D9B5D7C4C          1   60900  \n",
       "300914  0xD7BAD6B5D071292FD40F898CABBC9677          1   60900  \n",
       "184890  0xC81DBDBE35DD273C67BADAA182719325          1    2431  \n",
       "300927  0xC21A84D1CF465517E3067BE5D830BD02          1    2430  \n",
       "\n",
       "[127 rows x 48 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrangeColumns(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2628eae-103d-4a53-a68b-354727aaaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def get_reduced_df(dfMatch):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame (dfMatch) and returns a new DataFrame containing specific columns\n",
    "    with a dynamic 'combo' column as the first column, with FromBus always preceding ToBus and sorted.\n",
    "\n",
    "    Args:\n",
    "        dfMatch: The input pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the following columns:\n",
    "            - 'combo' (filled with a string combining CircuitTypeCode, FromBus-ToBus, and ElementIdentifierName) - This column becomes the first column in the output.\n",
    "            - 'ElementIdentifierName'\n",
    "            - 'CompanyName'\n",
    "            - ... (other desired columns) - Include any other columns you want in the output DataFrame.\n",
    "            - 'RetirementDate' (added)\n",
    "            - 'Rec_ID' (added)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select desired columns from the input DataFrame\n",
    "    desired_cols = [\n",
    "        \"ElementIdentifierName\",\n",
    "        \"CompanyName\",\n",
    "        \"RegionCode\",\n",
    "        \"FromBus\",\n",
    "        \"ToBus\",\n",
    "        \"TertiaryBus\",\n",
    "        \"Miles\",\n",
    "        \"BESExemptedFlag\",\n",
    "        \"NumberOfTerminals\",\n",
    "        \"CircuitTypeCode\",\n",
    "        \"VoltageClassCodeName\",\n",
    "        \"ParentCode\",\n",
    "        \"ConductorsPerPhaseCode\",\n",
    "        \"OverheadGroundWireCode\",\n",
    "        \"InsulatorTypeCode\",\n",
    "        \"CableTypeCode\",\n",
    "        \"StructureMaterialCode\",\n",
    "        \"StructureTypeCode\",\n",
    "        \"CircuitsPerStructureCode\",\n",
    "        \"TerrainCode\",\n",
    "        \"ElevationCode\",\n",
    "        \"InServiceDate\",\n",
    "        \"RetirementDate\",\n",
    "        \"Rec_ID\",\n",
    "    ]\n",
    "\n",
    "    df_reduced = dfMatch[desired_cols]\n",
    "\n",
    "    df_reduced = rearrangeColumns(df_reduced)\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_reduced_copy = df_reduced.copy()\n",
    "\n",
    "    # Extract the first word from CircuitTypeCode\n",
    "    df_reduced_copy[\"CircuitTypeCode_FirstWord\"] = (\n",
    "        df_reduced_copy[\"CircuitTypeCode\"].str.split().str[0]\n",
    "    )\n",
    "\n",
    "    # Temporary column to store the sorted Bus combination\n",
    "    df_reduced_copy[\"SortedBus\"] = df_reduced_copy[[\"FromBus\", \"ToBus\"]].apply(\n",
    "        lambda x: \"-\".join(sorted(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # Create a dynamic combo option string using the first word and sorted FromBus-ToBus\n",
    "    df_reduced_copy[\"combo\"] = df_reduced_copy.apply(\n",
    "        lambda row: f\"{row['CircuitTypeCode_FirstWord']} {row['SortedBus']} {row['ElementIdentifierName']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df_reduced_copy.pop(\"CircuitTypeCode_FirstWord\")  # No longer needed\n",
    "    df_reduced_copy.pop(\"SortedBus\")  # No longer needed\n",
    "\n",
    "    # Sort the DataFrame by FromBus and ToBus\n",
    "    df_reduced_copy = df_reduced_copy.sort_values(by=[\"FromBus\", \"ToBus\"])\n",
    "\n",
    "    # Make 'combo' the first column\n",
    "    col = df_reduced_copy.pop(\"combo\")\n",
    "    df_reduced_copy.insert(loc=0, column=\"combo\", value=col)\n",
    "\n",
    "    return df_reduced_copy\n",
    "\n",
    "\n",
    "def filter_tlines_by_latest_reported_year(df):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to include only the first row for each unique combination of 'FromBus' and 'ToBus' columns,\n",
    "    assuming 'FromBus', 'ToBus', and 'ReportingYearNbr' are already sorted in descending order by 'ReportingYearNbr'.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr' (sorted by 'ReportingYearNbr' descending).\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame containing the first row for each unique combination of 'FromBus' and 'ToBus' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables to track current and previous values\n",
    "    current_frombus = None\n",
    "    current_tobus = None\n",
    "    filtered_df = pd.DataFrame(\n",
    "        columns=df.columns\n",
    "    )  # Create empty DataFrame to store filtered rows\n",
    "\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        frombus, tobus, _ = row[\"FromBus\"], row[\"ToBus\"], row[\"ReportingYearNbr\"]\n",
    "\n",
    "        # Check if new unique combination of 'FromBus' and 'ToBus' is encountered\n",
    "        if (current_frombus != frombus) or (current_tobus != tobus):\n",
    "            # Add previous row (if it exists) to the filtered DataFrame\n",
    "            if current_frombus is not None and current_tobus is not None:\n",
    "                try:\n",
    "                    # Attempt to add the previous row using loc\n",
    "                    filtered_df = pd.concat(\n",
    "                        [filtered_df, df.loc[(current_frombus, current_tobus)]],\n",
    "                        ignore_index=True,\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    # Handle potential KeyError (e.g., missing value in previous combination)\n",
    "                    # You can choose a strategy like logging the error or skipping the row\n",
    "                    print(\n",
    "                        f\"KeyError encountered for ({current_frombus}, {current_tobus}). Skipping row.\"\n",
    "                    )\n",
    "\n",
    "            # Update current values\n",
    "            current_frombus = frombus\n",
    "            current_tobus = tobus\n",
    "\n",
    "        # Always append the current row (might be the first or subsequent for the same 'FromBus' and 'ToBus')\n",
    "        filtered_df = pd.concat([filtered_df, row], ignore_index=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_latest_entries(dfTadsSorted):\n",
    "    # Drop duplicates, keeping the first occurrence\n",
    "    dfTadsLatest = dfTadsSorted.drop_duplicates(\n",
    "        subset=[\"FromBus\", \"ToBus\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    return dfTadsLatest\n",
    "\n",
    "def sort_and_shift_columns(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'FromBus', 'ToBus', 'ReportingYearNbr' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'FromBus', 'ToBus', and 'ReportingYearNbr'.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus', 'ReportingYearNbr'\n",
    "        with those three columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"FromBus\", \"ToBus\", \"ReportingYearNbr\"], ascending=[True, True, False]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"] + [\n",
    "        col\n",
    "        for col in sorted_df.columns\n",
    "        if col not in [\"FromBus\", \"ToBus\", \"ReportingYearNbr\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def sort_and_shift_columns_dfVelo(df):\n",
    "    \"\"\"\n",
    "    Sorts a DataFrame by 'From Sub', 'To Sub' and rearranges those columns to be first.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing columns 'From Sub', 'To Sub' apart from any other columns.\n",
    "\n",
    "    Returns:\n",
    "        A new pandas DataFrame with all columns sorted by 'FromBus', 'ToBus\n",
    "        with those two columns positioned at the beginning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by 'FromBus', 'ToBus', 'ReportingYearNbr' (descending order for ReportingYearNbr)\n",
    "    sorted_df = df.sort_values(\n",
    "        by=[\"From Sub\", \"To Sub\"], ascending=[True, True]\n",
    "    )\n",
    "\n",
    "    # Define desired column order (efficient approach)\n",
    "    desired_column_order = [\"From Sub\", \"To Sub\"] + [\n",
    "        col for col in sorted_df.columns if col not in [\"From Sub\", \"To Sub\"]\n",
    "    ]\n",
    "\n",
    "    # Reorder columns using `.loc` indexing\n",
    "    shifted_df = sorted_df.loc[:, desired_column_order]\n",
    "\n",
    "    return shifted_df\n",
    "\n",
    "def get_matched_entries(dfVeloSorted, dfTadsLatest):\n",
    "    matched_rows = []\n",
    "\n",
    "    # Iterate through both DataFrames\n",
    "    for i in range(len(dfVeloSorted)):\n",
    "        from_sub, to_sub = str(dfVeloSorted.iloc[i][\"From Sub\"]), str(\n",
    "            dfVeloSorted.iloc[i][\"To Sub\"]\n",
    "        )\n",
    "        rec_id = dfVeloSorted.iloc[i][\"Rec_ID\"]\n",
    "        for j in range(len(dfTadsLatest)):\n",
    "            from_bus, to_bus = str(dfTadsLatest.iloc[j][\"FromBus\"]), str(\n",
    "                dfTadsLatest.iloc[j][\"ToBus\"]\n",
    "            )\n",
    "\n",
    "            if (from_sub == from_bus and to_sub == to_bus) or (\n",
    "                from_sub == to_bus and to_sub == from_bus\n",
    "            ):\n",
    "                matched_row = dfTadsLatest.iloc[j].copy()\n",
    "                matched_row[\"Rec_ID\"] = rec_id\n",
    "                matched_rows.append(matched_row)\n",
    "\n",
    "    dfTadsMatched = pd.DataFrame(matched_rows)\n",
    "\n",
    "    return dfTadsMatched\n",
    "\n",
    "\n",
    "def rearrangeColumns(df, col1=\"FromBus\", col2=\"ToBus\"):\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Iterate through each row and swap col1 and col2 if necessary\n",
    "    for index, row in df.iterrows():\n",
    "        value1 = str(row[col1])\n",
    "        value2 = str(row[col2])\n",
    "\n",
    "        if value1 > value2:\n",
    "            df.at[index, col1] = value2\n",
    "            df.at[index, col2] = value1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_reduced_df(dfMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28715</th>\n",
       "      <td>ACO Aetna-Dune Acres 138006</td>\n",
       "      <td>138006</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41979</th>\n",
       "      <td>ACO Albers-Bain 63143</td>\n",
       "      <td>63143</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Albers</td>\n",
       "      <td>Bain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292357</th>\n",
       "      <td>ACO Tollway-Wayne 14402</td>\n",
       "      <td>14402</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Tollway</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286725</th>\n",
       "      <td>ACO University-Washington Park 17404</td>\n",
       "      <td>17404</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>University</td>\n",
       "      <td>Washington Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292165</th>\n",
       "      <td>ACO Waukegan-Zion 1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300914</th>\n",
       "      <td>ACO Waukegan-Zion 2218</td>\n",
       "      <td>2218</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Waukegan</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300927</th>\n",
       "      <td>ACO Zion-Zion Energy Center 2223</td>\n",
       "      <td>2223</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       combo ElementIdentifierName  \\\n",
       "28715            ACO Aetna-Dune Acres 138006                138006   \n",
       "28729           ACO Aetna-Lake George 138054                138054   \n",
       "28739                ACO Aetna-Miller 138102                138102   \n",
       "28739                ACO Aetna-Miller 138102                138102   \n",
       "41979                  ACO Albers-Bain 63143                 63143   \n",
       "...                                      ...                   ...   \n",
       "292357               ACO Tollway-Wayne 14402                 14402   \n",
       "286725  ACO University-Washington Park 17404                 17404   \n",
       "292165                ACO Waukegan-Zion 1609                  1609   \n",
       "300914                ACO Waukegan-Zion 2218                  2218   \n",
       "300927      ACO Zion-Zion Energy Center 2223                  2223   \n",
       "\n",
       "                                        CompanyName RegionCode     FromBus  \\\n",
       "28715   Northern Indiana Public Service Company [BA        RFC       Aetna   \n",
       "28729   Northern Indiana Public Service Company [BA        RFC       Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC       Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC       Aetna   \n",
       "41979                 American Transmission Company        MRO      Albers   \n",
       "...                                             ...        ...         ...   \n",
       "292357                  Commonwealth Edison Company        RFC     Tollway   \n",
       "286725                  Commonwealth Edison Company        RFC  University   \n",
       "292165                  Commonwealth Edison Company        RFC    Waukegan   \n",
       "300914                  Commonwealth Edison Company        RFC    Waukegan   \n",
       "300927                  Commonwealth Edison Company        RFC        Zion   \n",
       "\n",
       "                     ToBus TertiaryBus   Miles  BESExemptedFlag  \\\n",
       "28715           Dune Acres         NaN  11.700              0.0   \n",
       "28729          Lake George         NaN   4.900              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "28739               Miller         NaN   0.500              0.0   \n",
       "41979                 Bain         NaN   4.790              NaN   \n",
       "...                    ...         ...     ...              ...   \n",
       "292357               Wayne         NaN   5.598              NaN   \n",
       "286725     Washington Park         NaN   2.200              NaN   \n",
       "292165                Zion         NaN  12.275              NaN   \n",
       "300914                Zion         NaN   5.283              NaN   \n",
       "300927  Zion Energy Center         NaN   5.982              NaN   \n",
       "\n",
       "        NumberOfTerminals  ... InsulatorTypeCode CableTypeCode  \\\n",
       "28715                 2.0  ...               NaN           NaN   \n",
       "28729                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "41979                 2.0  ...               NaN           NaN   \n",
       "...                   ...  ...               ...           ...   \n",
       "292357                2.0  ...               NaN           NaN   \n",
       "286725                2.0  ...               NaN           NaN   \n",
       "292165                2.0  ...               NaN           NaN   \n",
       "300914                2.0  ...               NaN           NaN   \n",
       "300927                2.0  ...               NaN           NaN   \n",
       "\n",
       "       StructureMaterialCode  StructureTypeCode  CircuitsPerStructureCode  \\\n",
       "28715                    NaN                NaN                       NaN   \n",
       "28729                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "41979                    NaN                NaN                       NaN   \n",
       "...                      ...                ...                       ...   \n",
       "292357                   NaN                NaN                       NaN   \n",
       "286725                   NaN                NaN                       NaN   \n",
       "292165                   NaN                NaN                       NaN   \n",
       "300914                   NaN                NaN                       NaN   \n",
       "300927                   NaN                NaN                       NaN   \n",
       "\n",
       "        TerrainCode  ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28715           NaN            NaN    1/1/15 0:00             NaN   50026  \n",
       "28729           NaN            NaN    1/1/15 0:00             NaN   60847  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   22650  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   70313  \n",
       "41979           NaN            NaN    1/1/15 0:00             NaN   71534  \n",
       "...             ...            ...            ...             ...     ...  \n",
       "292357          NaN            NaN    1/1/15 0:00             NaN   27894  \n",
       "286725          NaN            NaN    1/1/15 0:00             NaN    2559  \n",
       "292165          NaN            NaN    1/1/15 0:00             NaN   60900  \n",
       "300914          NaN            NaN    1/1/15 0:00             NaN   60900  \n",
       "300927          NaN            NaN    1/1/15 0:00             NaN    2430  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>ElementIdentifierName</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>FromBus</th>\n",
       "      <th>ToBus</th>\n",
       "      <th>TertiaryBus</th>\n",
       "      <th>Miles</th>\n",
       "      <th>BESExemptedFlag</th>\n",
       "      <th>NumberOfTerminals</th>\n",
       "      <th>...</th>\n",
       "      <th>InsulatorTypeCode</th>\n",
       "      <th>CableTypeCode</th>\n",
       "      <th>StructureMaterialCode</th>\n",
       "      <th>StructureTypeCode</th>\n",
       "      <th>CircuitsPerStructureCode</th>\n",
       "      <th>TerrainCode</th>\n",
       "      <th>ElevationCode</th>\n",
       "      <th>InServiceDate</th>\n",
       "      <th>RetirementDate</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>ACO Aetna-Lake George 138054</td>\n",
       "      <td>138054</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>ACO Aetna-Miller 138102</td>\n",
       "      <td>138102</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41979</th>\n",
       "      <td>ACO Albers-Bain 63143</td>\n",
       "      <td>63143</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Albers</td>\n",
       "      <td>Bain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173167</th>\n",
       "      <td>ACO Albers-Kenosha 9352</td>\n",
       "      <td>9352</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Albers</td>\n",
       "      <td>Kenosha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184865</th>\n",
       "      <td>ACO Aptakisic-Libertyville 15410</td>\n",
       "      <td>15410</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aptakisic</td>\n",
       "      <td>Libertyville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>ACO Arcadian-Zion 2222</td>\n",
       "      <td>2222</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Arcadian</td>\n",
       "      <td>Zion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>12/30/22 0:00</td>\n",
       "      <td>52054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO Aurora-Electric Junction 11119</td>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118743</th>\n",
       "      <td>ACO Aurora-Electric Junction 11119</td>\n",
       "      <td>11119</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110995</th>\n",
       "      <td>ACO Babcock-Dune Acres 138075</td>\n",
       "      <td>138075</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Babcock</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110995</th>\n",
       "      <td>ACO Babcock-Dune Acres 138075</td>\n",
       "      <td>138075</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Babcock</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41495</th>\n",
       "      <td>ACO Babcock-Lake George 345003</td>\n",
       "      <td>345003</td>\n",
       "      <td>Northern Indiana Public Service Company [BA</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Babcock</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41989</th>\n",
       "      <td>ACO Bain-Kenosha 63151</td>\n",
       "      <td>63151</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Bain</td>\n",
       "      <td>Kenosha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238623</th>\n",
       "      <td>ACO Bain-Pleasant Prairie W-26</td>\n",
       "      <td>W-26</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Bain</td>\n",
       "      <td>Pleasant Prairie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/24 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238623</th>\n",
       "      <td>ACO Bain-Pleasant Prairie W-26</td>\n",
       "      <td>W-26</td>\n",
       "      <td>American Transmission Company</td>\n",
       "      <td>MRO</td>\n",
       "      <td>Bain</td>\n",
       "      <td>Pleasant Prairie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/24 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142823</th>\n",
       "      <td>ACO Bedford Park-Goodings Grove 11607</td>\n",
       "      <td>11607</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bedford Park</td>\n",
       "      <td>Goodings Grove</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47634</th>\n",
       "      <td>ACO Bedford Park-Hayford 11521</td>\n",
       "      <td>11521</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bedford Park</td>\n",
       "      <td>Hayford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/13 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55732</th>\n",
       "      <td>ACO Bloom-Burnham 17908</td>\n",
       "      <td>17908</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82532</th>\n",
       "      <td>ACO Bloom-Chicago Heights 7305</td>\n",
       "      <td>7305</td>\n",
       "      <td>Commonwealth Edison Company</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>Chicago Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/15 0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        combo ElementIdentifierName  \\\n",
       "28729            ACO Aetna-Lake George 138054                138054   \n",
       "28739                 ACO Aetna-Miller 138102                138102   \n",
       "28739                 ACO Aetna-Miller 138102                138102   \n",
       "41979                   ACO Albers-Bain 63143                 63143   \n",
       "173167                ACO Albers-Kenosha 9352                  9352   \n",
       "184865       ACO Aptakisic-Libertyville 15410                 15410   \n",
       "11121                  ACO Arcadian-Zion 2222                  2222   \n",
       "118743     ACO Aurora-Electric Junction 11119                 11119   \n",
       "118743     ACO Aurora-Electric Junction 11119                 11119   \n",
       "110995          ACO Babcock-Dune Acres 138075                138075   \n",
       "110995          ACO Babcock-Dune Acres 138075                138075   \n",
       "41495          ACO Babcock-Lake George 345003                345003   \n",
       "41989                  ACO Bain-Kenosha 63151                 63151   \n",
       "238623         ACO Bain-Pleasant Prairie W-26                  W-26   \n",
       "238623         ACO Bain-Pleasant Prairie W-26                  W-26   \n",
       "142823  ACO Bedford Park-Goodings Grove 11607                 11607   \n",
       "47634          ACO Bedford Park-Hayford 11521                 11521   \n",
       "55732                 ACO Bloom-Burnham 17908                 17908   \n",
       "82532          ACO Bloom-Chicago Heights 7305                  7305   \n",
       "\n",
       "                                        CompanyName RegionCode       FromBus  \\\n",
       "28729   Northern Indiana Public Service Company [BA        RFC         Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC         Aetna   \n",
       "28739   Northern Indiana Public Service Company [BA        RFC         Aetna   \n",
       "41979                 American Transmission Company        MRO        Albers   \n",
       "173167                American Transmission Company        MRO        Albers   \n",
       "184865                  Commonwealth Edison Company        RFC     Aptakisic   \n",
       "11121                 American Transmission Company        MRO      Arcadian   \n",
       "118743                  Commonwealth Edison Company        RFC        Aurora   \n",
       "118743                  Commonwealth Edison Company        RFC        Aurora   \n",
       "110995  Northern Indiana Public Service Company [BA        RFC       Babcock   \n",
       "110995  Northern Indiana Public Service Company [BA        RFC       Babcock   \n",
       "41495   Northern Indiana Public Service Company [BA        RFC       Babcock   \n",
       "41989                 American Transmission Company        MRO          Bain   \n",
       "238623                American Transmission Company        MRO          Bain   \n",
       "238623                American Transmission Company        MRO          Bain   \n",
       "142823                  Commonwealth Edison Company        RFC  Bedford Park   \n",
       "47634                   Commonwealth Edison Company        RFC  Bedford Park   \n",
       "55732                   Commonwealth Edison Company        RFC         Bloom   \n",
       "82532                   Commonwealth Edison Company        RFC         Bloom   \n",
       "\n",
       "                    ToBus TertiaryBus   Miles  BESExemptedFlag  \\\n",
       "28729         Lake George         NaN   4.900              0.0   \n",
       "28739              Miller         NaN   0.500              0.0   \n",
       "28739              Miller         NaN   0.500              0.0   \n",
       "41979                Bain         NaN   4.790              NaN   \n",
       "173167            Kenosha         NaN   3.970              NaN   \n",
       "184865       Libertyville         NaN  10.133              NaN   \n",
       "11121                Zion         NaN  53.100              NaN   \n",
       "118743  Electric Junction         NaN   1.433              NaN   \n",
       "118743  Electric Junction         NaN   1.433              NaN   \n",
       "110995         Dune Acres         NaN   7.700              0.0   \n",
       "110995         Dune Acres         NaN   7.700              0.0   \n",
       "41495         Lake George         NaN  12.000              0.0   \n",
       "41989             Kenosha         NaN   1.650              NaN   \n",
       "238623   Pleasant Prairie         NaN   1.010              NaN   \n",
       "238623   Pleasant Prairie         NaN   1.010              NaN   \n",
       "142823     Goodings Grove         NaN  18.515              NaN   \n",
       "47634             Hayford         NaN   5.650              0.0   \n",
       "55732             Burnham         NaN  12.420              NaN   \n",
       "82532     Chicago Heights         NaN   2.493              NaN   \n",
       "\n",
       "        NumberOfTerminals  ... InsulatorTypeCode CableTypeCode  \\\n",
       "28729                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "28739                 2.0  ...               NaN           NaN   \n",
       "41979                 2.0  ...               NaN           NaN   \n",
       "173167                2.0  ...               NaN           NaN   \n",
       "184865                2.0  ...               NaN           NaN   \n",
       "11121                 2.0  ...               NaN           NaN   \n",
       "118743                2.0  ...               NaN           NaN   \n",
       "118743                2.0  ...               NaN           NaN   \n",
       "110995                2.0  ...               NaN           NaN   \n",
       "110995                2.0  ...               NaN           NaN   \n",
       "41495                 2.0  ...               NaN           NaN   \n",
       "41989                 2.0  ...               NaN           NaN   \n",
       "238623                2.0  ...               NaN           NaN   \n",
       "238623                2.0  ...               NaN           NaN   \n",
       "142823                2.0  ...               NaN           NaN   \n",
       "47634                 2.0  ...               NaN           NaN   \n",
       "55732                 2.0  ...               NaN           NaN   \n",
       "82532                 2.0  ...               NaN           NaN   \n",
       "\n",
       "       StructureMaterialCode  StructureTypeCode  CircuitsPerStructureCode  \\\n",
       "28729                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "28739                    NaN                NaN                       NaN   \n",
       "41979                    NaN                NaN                       NaN   \n",
       "173167                   NaN                NaN                       NaN   \n",
       "184865                   NaN                NaN                       NaN   \n",
       "11121                    NaN                NaN                       NaN   \n",
       "118743                   NaN                NaN                       NaN   \n",
       "118743                   NaN                NaN                       NaN   \n",
       "110995                   NaN                NaN                       NaN   \n",
       "110995                   NaN                NaN                       NaN   \n",
       "41495                    NaN                NaN                       NaN   \n",
       "41989                    NaN                NaN                       NaN   \n",
       "238623                   NaN                NaN                       NaN   \n",
       "238623                   NaN                NaN                       NaN   \n",
       "142823                   NaN                NaN                       NaN   \n",
       "47634                    NaN                NaN                       NaN   \n",
       "55732                    NaN                NaN                       NaN   \n",
       "82532                    NaN                NaN                       NaN   \n",
       "\n",
       "        TerrainCode  ElevationCode  InServiceDate  RetirementDate  Rec_ID  \n",
       "28729           NaN            NaN    1/1/15 0:00             NaN   60847  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   22650  \n",
       "28739           NaN            NaN    1/1/15 0:00             NaN   70313  \n",
       "41979           NaN            NaN    1/1/15 0:00             NaN   71534  \n",
       "173167          NaN            NaN    1/1/15 0:00             NaN   61461  \n",
       "184865          NaN            NaN    1/1/15 0:00             NaN    2486  \n",
       "11121           NaN            NaN    1/1/15 0:00   12/30/22 0:00   52054  \n",
       "118743          NaN            NaN    1/1/15 0:00             NaN   55397  \n",
       "118743          NaN            NaN    1/1/15 0:00             NaN   69508  \n",
       "110995          NaN            NaN    1/1/15 0:00             NaN   22653  \n",
       "110995          NaN            NaN    1/1/15 0:00             NaN   60848  \n",
       "41495           NaN            NaN    1/1/13 0:00             NaN   55461  \n",
       "41989           NaN            NaN    1/1/15 0:00             NaN    7127  \n",
       "238623          NaN            NaN    1/1/24 0:00             NaN   27450  \n",
       "238623          NaN            NaN    1/1/24 0:00             NaN   70900  \n",
       "142823          NaN            NaN    1/1/15 0:00             NaN    2600  \n",
       "47634           NaN            NaN    1/1/13 0:00             NaN    2593  \n",
       "55732           NaN            NaN    1/1/15 0:00             NaN    2798  \n",
       "82532           NaN            NaN    1/1/15 0:00             NaN   61854  \n",
       "\n",
       "[19 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "318810d8-b567-4921-afdf-644fb48a5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchReduced = get_reduced_df(dfMatch)\n",
    "matchReducedAddr = os.path.join(processedDataFolder, \"chicago-ohare-lines.xlsx\")\n",
    "dfMatchReduced.to_excel(matchReducedAddr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Transmission Line Name</th>\n",
       "      <th>Owner2</th>\n",
       "      <th>Voltage kV</th>\n",
       "      <th>Voltage Class kV</th>\n",
       "      <th>Number of Lines</th>\n",
       "      <th>Proposed</th>\n",
       "      <th>Underground</th>\n",
       "      <th>From Sub</th>\n",
       "      <th>To Sub</th>\n",
       "      <th>...</th>\n",
       "      <th>Length mi</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Source</th>\n",
       "      <th>Numeric Voltages</th>\n",
       "      <th>Holding Company Name</th>\n",
       "      <th>Owner2 ID</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>Layer_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ownership Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commonwealth Edison Co</td>\n",
       "      <td>Belvidere to Marengo Tap 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>2</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Belvidere</td>\n",
       "      <td>Marengo Tap</td>\n",
       "      <td>...</td>\n",
       "      <td>12.579538</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>-99</td>\n",
       "      <td>2732</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commonwealth Edison Co</td>\n",
       "      <td>Marengo Tap to Woodstock 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Marengo Tap</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>...</td>\n",
       "      <td>11.489827</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>-99</td>\n",
       "      <td>2737</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commonwealth Edison Co</td>\n",
       "      <td>Marengo Tap to Marengo 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>2</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Marengo Tap</td>\n",
       "      <td>Marengo</td>\n",
       "      <td>...</td>\n",
       "      <td>1.109239</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>-99</td>\n",
       "      <td>55455</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commonwealth Edison Co</td>\n",
       "      <td>McHenry to Crystal Lake 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>2</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>McHenry</td>\n",
       "      <td>Crystal Lake</td>\n",
       "      <td>...</td>\n",
       "      <td>5.882206</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>-99</td>\n",
       "      <td>55456</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Commonwealth Edison Co</td>\n",
       "      <td>Marengo Tap to Pleasant Valley (Indope) 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>2</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Marengo Tap</td>\n",
       "      <td>Pleasant Valley (Indope)</td>\n",
       "      <td>...</td>\n",
       "      <td>10.764849</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>-99</td>\n",
       "      <td>59314</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Northern Indiana Public Service Co LLC</td>\n",
       "      <td>Chicago Avenue to Praxair Inc No 1 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Chicago Avenue</td>\n",
       "      <td>Praxair Inc No 1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.533518</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>NiSource Inc</td>\n",
       "      <td>-99</td>\n",
       "      <td>69262</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Northern Indiana Public Service Co LLC</td>\n",
       "      <td>Dune Acres to Michigan City 345 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Dune Acres</td>\n",
       "      <td>Michigan City</td>\n",
       "      <td>...</td>\n",
       "      <td>11.776760</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>345</td>\n",
       "      <td>NiSource Inc</td>\n",
       "      <td>-99</td>\n",
       "      <td>22656</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Northern Municipal Power Agency</td>\n",
       "      <td>Kenwood to Highland 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Kenwood</td>\n",
       "      <td>Highland</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736390</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Northern Municipal Power Agency</td>\n",
       "      <td>-99</td>\n",
       "      <td>59294</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>Muni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Northern Municipal Power Agency</td>\n",
       "      <td>Highland to Lake George 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Highland</td>\n",
       "      <td>Lake George</td>\n",
       "      <td>...</td>\n",
       "      <td>11.143082</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Northern Municipal Power Agency</td>\n",
       "      <td>-99</td>\n",
       "      <td>22658</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>Muni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Northern Municipal Power Agency</td>\n",
       "      <td>Roxana to Sheffield 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Roxana</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833556</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Northern Municipal Power Agency</td>\n",
       "      <td>-99</td>\n",
       "      <td>50022</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>Muni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company Name  \\\n",
       "1                    Commonwealth Edison Co   \n",
       "2                    Commonwealth Edison Co   \n",
       "3                    Commonwealth Edison Co   \n",
       "4                    Commonwealth Edison Co   \n",
       "5                    Commonwealth Edison Co   \n",
       "..                                      ...   \n",
       "514  Northern Indiana Public Service Co LLC   \n",
       "515  Northern Indiana Public Service Co LLC   \n",
       "516         Northern Municipal Power Agency   \n",
       "517         Northern Municipal Power Agency   \n",
       "518         Northern Municipal Power Agency   \n",
       "\n",
       "                             Transmission Line Name  Owner2  Voltage kV  \\\n",
       "1                   Belvidere to Marengo Tap 138 kV     NaN         138   \n",
       "2                   Marengo Tap to Woodstock 138 kV     NaN         138   \n",
       "3                     Marengo Tap to Marengo 138 kV     NaN         138   \n",
       "4                    McHenry to Crystal Lake 138 kV     NaN         138   \n",
       "5    Marengo Tap to Pleasant Valley (Indope) 138 kV     NaN         138   \n",
       "..                                              ...     ...         ...   \n",
       "514       Chicago Avenue to Praxair Inc No 1 138 kV     NaN         138   \n",
       "515              Dune Acres to Michigan City 345 kV     NaN         345   \n",
       "516                      Kenwood to Highland 138 kV     NaN         138   \n",
       "517                  Highland to Lake George 138 kV     NaN         138   \n",
       "518                      Roxana to Sheffield 138 kV     NaN         138   \n",
       "\n",
       "    Voltage Class kV  Number of Lines    Proposed Underground        From Sub  \\\n",
       "1            100-161                2  In Service           F       Belvidere   \n",
       "2            100-161                1  In Service           F     Marengo Tap   \n",
       "3            100-161                2  In Service           F     Marengo Tap   \n",
       "4            100-161                2  In Service           F         McHenry   \n",
       "5            100-161                2  In Service           F     Marengo Tap   \n",
       "..               ...              ...         ...         ...             ...   \n",
       "514          100-161                1  In Service           F  Chicago Avenue   \n",
       "515              345                1  In Service           F      Dune Acres   \n",
       "516          100-161                1  In Service           F         Kenwood   \n",
       "517          100-161                1  In Service           F        Highland   \n",
       "518          100-161                1  In Service           F          Roxana   \n",
       "\n",
       "                       To Sub  ...  Length mi  Location Code          Source  \\\n",
       "1                 Marengo Tap  ...  12.579538              1  Aerial Imagery   \n",
       "2                   Woodstock  ...  11.489827              1  Aerial Imagery   \n",
       "3                     Marengo  ...   1.109239              1  Aerial Imagery   \n",
       "4                Crystal Lake  ...   5.882206              1  Aerial Imagery   \n",
       "5    Pleasant Valley (Indope)  ...  10.764849              1  Aerial Imagery   \n",
       "..                        ...  ...        ...            ...             ...   \n",
       "514          Praxair Inc No 1  ...   2.533518              1  Aerial Imagery   \n",
       "515             Michigan City  ...  11.776760              1  Aerial Imagery   \n",
       "516                  Highland  ...   1.736390              1  Aerial Imagery   \n",
       "517               Lake George  ...  11.143082              1  Aerial Imagery   \n",
       "518                 Sheffield  ...   4.833556              1  Aerial Imagery   \n",
       "\n",
       "    Numeric Voltages             Holding Company Name Owner2 ID  Rec_ID  \\\n",
       "1            100-161                      Exelon Corp       -99    2732   \n",
       "2            100-161                      Exelon Corp       -99    2737   \n",
       "3            100-161                      Exelon Corp       -99   55455   \n",
       "4            100-161                      Exelon Corp       -99   55456   \n",
       "5            100-161                      Exelon Corp       -99   59314   \n",
       "..               ...                              ...       ...     ...   \n",
       "514          100-161                     NiSource Inc       -99   69262   \n",
       "515              345                     NiSource Inc       -99   22656   \n",
       "516          100-161  Northern Municipal Power Agency       -99   59294   \n",
       "517          100-161  Northern Municipal Power Agency       -99   22658   \n",
       "518          100-161  Northern Municipal Power Agency       -99   50022   \n",
       "\n",
       "     Layer_ID  Type Ownership Type  \n",
       "1          82    AC            IOU  \n",
       "2          82    AC            IOU  \n",
       "3          82    AC            IOU  \n",
       "4          82    AC            IOU  \n",
       "5          82    AC            IOU  \n",
       "..        ...   ...            ...  \n",
       "514        82    AC            IOU  \n",
       "515        82    AC            IOU  \n",
       "516        82    AC           Muni  \n",
       "517        82    AC           Muni  \n",
       "518        82    AC           Muni  \n",
       "\n",
       "[459 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       2732\n",
       "2       2737\n",
       "3      55455\n",
       "4      55456\n",
       "5      59314\n",
       "       ...  \n",
       "514    69262\n",
       "515    22656\n",
       "516    59294\n",
       "517    22658\n",
       "518    50022\n",
       "Name: Rec_ID, Length: 459, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo['Rec_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Transmission Line Name</th>\n",
       "      <th>Owner2</th>\n",
       "      <th>Voltage kV</th>\n",
       "      <th>Voltage Class kV</th>\n",
       "      <th>Number of Lines</th>\n",
       "      <th>Proposed</th>\n",
       "      <th>Underground</th>\n",
       "      <th>From Sub</th>\n",
       "      <th>To Sub</th>\n",
       "      <th>...</th>\n",
       "      <th>Length mi</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Source</th>\n",
       "      <th>Numeric Voltages</th>\n",
       "      <th>Holding Company Name</th>\n",
       "      <th>Owner2 ID</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>Layer_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ownership Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Northern Indiana Public Service Co LLC</td>\n",
       "      <td>Aetna to Miller 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>Miller</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54525</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>NiSource Inc</td>\n",
       "      <td>-99</td>\n",
       "      <td>22650</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company Name  Transmission Line Name  Owner2  \\\n",
       "474  Northern Indiana Public Service Co LLC  Aetna to Miller 138 kV     NaN   \n",
       "\n",
       "     Voltage kV Voltage Class kV  Number of Lines    Proposed Underground  \\\n",
       "474         138          100-161                1  In Service           F   \n",
       "\n",
       "    From Sub  To Sub  ... Length mi  Location Code          Source  \\\n",
       "474    Aetna  Miller  ...   0.54525              1  Aerial Imagery   \n",
       "\n",
       "    Numeric Voltages Holding Company Name Owner2 ID  Rec_ID  Layer_ID  Type  \\\n",
       "474          100-161         NiSource Inc       -99   22650        82    AC   \n",
       "\n",
       "    Ownership Type  \n",
       "474            IOU  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo[dfVelo['Rec_ID'] == 22650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Transmission Line Name</th>\n",
       "      <th>Owner2</th>\n",
       "      <th>Voltage kV</th>\n",
       "      <th>Voltage Class kV</th>\n",
       "      <th>Number of Lines</th>\n",
       "      <th>Proposed</th>\n",
       "      <th>Underground</th>\n",
       "      <th>From Sub</th>\n",
       "      <th>To Sub</th>\n",
       "      <th>...</th>\n",
       "      <th>Length mi</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Source</th>\n",
       "      <th>Numeric Voltages</th>\n",
       "      <th>Holding Company Name</th>\n",
       "      <th>Owner2 ID</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>Layer_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ownership Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Undetermined Company</td>\n",
       "      <td>Miller to Aetna 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Miller</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54393</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-99</td>\n",
       "      <td>70313</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company Name  Transmission Line Name  Owner2  Voltage kV  \\\n",
       "412  Undetermined Company  Miller to Aetna 138 kV     NaN         138   \n",
       "\n",
       "    Voltage Class kV  Number of Lines    Proposed Underground From Sub To Sub  \\\n",
       "412          100-161                1  In Service           F   Miller  Aetna   \n",
       "\n",
       "     ... Length mi  Location Code          Source Numeric Voltages  \\\n",
       "412  ...   0.54393              1  Aerial Imagery          100-161   \n",
       "\n",
       "    Holding Company Name Owner2 ID  Rec_ID  Layer_ID  Type Ownership Type  \n",
       "412              Unknown       -99   70313        82    AC        Unknown  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo[dfVelo['Rec_ID'] == 70313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Transmission Line Name</th>\n",
       "      <th>Owner2</th>\n",
       "      <th>Voltage kV</th>\n",
       "      <th>Voltage Class kV</th>\n",
       "      <th>Number of Lines</th>\n",
       "      <th>Proposed</th>\n",
       "      <th>Underground</th>\n",
       "      <th>From Sub</th>\n",
       "      <th>To Sub</th>\n",
       "      <th>...</th>\n",
       "      <th>Length mi</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Source</th>\n",
       "      <th>Numeric Voltages</th>\n",
       "      <th>Holding Company Name</th>\n",
       "      <th>Owner2 ID</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>Layer_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ownership Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Commonwealth Edison Co</td>\n",
       "      <td>Aurora to Electric Junction 138 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>100-161</td>\n",
       "      <td>2</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25273</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>100-161</td>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>-99</td>\n",
       "      <td>55397</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>IOU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name              Transmission Line Name  Owner2  \\\n",
       "213  Commonwealth Edison Co  Aurora to Electric Junction 138 kV     NaN   \n",
       "\n",
       "     Voltage kV Voltage Class kV  Number of Lines    Proposed Underground  \\\n",
       "213         138          100-161                2  In Service           F   \n",
       "\n",
       "    From Sub             To Sub  ... Length mi  Location Code          Source  \\\n",
       "213   Aurora  Electric Junction  ...   1.25273              1  Aerial Imagery   \n",
       "\n",
       "    Numeric Voltages Holding Company Name Owner2 ID  Rec_ID  Layer_ID  Type  \\\n",
       "213          100-161          Exelon Corp       -99   55397        82    AC   \n",
       "\n",
       "    Ownership Type  \n",
       "213            IOU  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo[dfVelo['Rec_ID'] == 55397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Transmission Line Name</th>\n",
       "      <th>Owner2</th>\n",
       "      <th>Voltage kV</th>\n",
       "      <th>Voltage Class kV</th>\n",
       "      <th>Number of Lines</th>\n",
       "      <th>Proposed</th>\n",
       "      <th>Underground</th>\n",
       "      <th>From Sub</th>\n",
       "      <th>To Sub</th>\n",
       "      <th>...</th>\n",
       "      <th>Length mi</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Source</th>\n",
       "      <th>Numeric Voltages</th>\n",
       "      <th>Holding Company Name</th>\n",
       "      <th>Owner2 ID</th>\n",
       "      <th>Rec_ID</th>\n",
       "      <th>Layer_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Ownership Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Undetermined Company</td>\n",
       "      <td>Aurora to Electric Junction 345 kV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>In Service</td>\n",
       "      <td>F</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Electric Junction</td>\n",
       "      <td>...</td>\n",
       "      <td>1.264928</td>\n",
       "      <td>3</td>\n",
       "      <td>Hitachi Energy</td>\n",
       "      <td>345</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-99</td>\n",
       "      <td>69508</td>\n",
       "      <td>82</td>\n",
       "      <td>AC</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company Name              Transmission Line Name  Owner2  \\\n",
       "219  Undetermined Company  Aurora to Electric Junction 345 kV     NaN   \n",
       "\n",
       "     Voltage kV Voltage Class kV  Number of Lines    Proposed Underground  \\\n",
       "219         345              345                1  In Service           F   \n",
       "\n",
       "    From Sub             To Sub  ... Length mi  Location Code          Source  \\\n",
       "219   Aurora  Electric Junction  ...  1.264928              3  Hitachi Energy   \n",
       "\n",
       "    Numeric Voltages Holding Company Name Owner2 ID  Rec_ID  Layer_ID  Type  \\\n",
       "219              345              Unknown       -99   69508        82    AC   \n",
       "\n",
       "    Ownership Type  \n",
       "219        Unknown  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo[dfVelo['Rec_ID'] == 69508]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28715              ACO Aetna-Dune Acres 138006\n",
       "28729             ACO Aetna-Lake George 138054\n",
       "28739                  ACO Aetna-Miller 138102\n",
       "28739                  ACO Aetna-Miller 138102\n",
       "41979                    ACO Albers-Bain 63143\n",
       "                          ...                 \n",
       "292357                 ACO Tollway-Wayne 14402\n",
       "286725    ACO University-Washington Park 17404\n",
       "292165                  ACO Waukegan-Zion 1609\n",
       "300914                  ACO Waukegan-Zion 2218\n",
       "300927        ACO Zion-Zion Energy Center 2223\n",
       "Name: combo, Length: 127, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMatchReduced['combo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC Clybourn-Crosby 8207',\n",
       " 'ACC Clybourn-Diversey 4013',\n",
       " 'ACC Congress-Medical Center 6701',\n",
       " 'ACC Crosby-Diversey 4018',\n",
       " 'ACC Crosby-Ontario 8211',\n",
       " 'ACC Damen-Evergreen Park 81414',\n",
       " 'ACC Damen-Wallace 11801',\n",
       " 'ACC Dekoven-Madison 3610',\n",
       " 'ACC Des Plaines-Norridge 19801',\n",
       " 'ACC Devon-Northwest 11411',\n",
       " 'ACC Diversey-Northwest 11413',\n",
       " 'ACC Galewood-Natoma 3701',\n",
       " 'ACC Grand-Jefferson 4525',\n",
       " 'ACC Grand-Madison 5810',\n",
       " 'ACC Higgins-Natoma 3706',\n",
       " 'ACC Humboldt Park-Rockwell 5001',\n",
       " 'ACC IC Air Rights-Taylor 15311',\n",
       " 'ACC Jefferson-Taylor 15302',\n",
       " 'ACC Lasalle-Taylor 15316',\n",
       " 'ACC Natoma-Norridge 3707',\n",
       " 'ACC Natoma-Northwest 11412',\n",
       " 'ACC Natoma-Oak Park 3709',\n",
       " 'ACC Northwest-Rosehill 11407',\n",
       " 'ACC Sears-Taylor 15304',\n",
       " 'ACC Taylor-West Loop 15323',\n",
       " 'ACO Aetna-Dune Acres 138006',\n",
       " 'ACO Aetna-Lake George 138054',\n",
       " 'ACO Aetna-Miller 138102',\n",
       " 'ACO Albers-Bain 63143',\n",
       " 'ACO Albers-Kenosha 9352',\n",
       " 'ACO Aptakisic-Libertyville 15410',\n",
       " 'ACO Arcadian-Zion 2222',\n",
       " 'ACO Aurora-Electric Junction 11119',\n",
       " 'ACO Babcock-Dune Acres 138075',\n",
       " 'ACO Babcock-Lake George 345003',\n",
       " 'ACO Bain-Kenosha 63151',\n",
       " 'ACO Bain-Pleasant Prairie W-26',\n",
       " 'ACO Bedford Park-Goodings Grove 11607',\n",
       " 'ACO Bedford Park-Hayford 11521',\n",
       " 'ACO Bloom-Burnham 17908',\n",
       " 'ACO Bloom-Chicago Heights 7305',\n",
       " 'ACO Bloom-Davis Creek 17907',\n",
       " 'ACO Blue Island-Burnham 17701',\n",
       " 'ACO Burnham-Calumet 17723',\n",
       " 'ACO Burnham-Davis Creek 17704',\n",
       " 'ACO Burnham-Munster 345004',\n",
       " 'ACO Burnham-Sheffield 345012',\n",
       " 'ACO Burnham-Tower Automotive 17715',\n",
       " 'ACO Burnham-Wildwood 17713',\n",
       " 'ACO Burns Ditch-Midwest Steel 138037',\n",
       " 'ACO Cherry Valley-Glidden 15627',\n",
       " 'ACO Cherry Valley-Silver Lake 15616',\n",
       " 'ACO Collins-Dresden 2311',\n",
       " 'ACO Collins-Plano 2315',\n",
       " 'ACO Congress-Rockwell 6721',\n",
       " 'ACO Crosby-Grand 5825',\n",
       " 'ACO Crosby-Rockwell 8221',\n",
       " 'ACO Crystal Lake-Silver Lake 13808',\n",
       " 'ACO Davis Creek-Wilmington 8607',\n",
       " 'ACO Devon-Skokie 8803',\n",
       " 'ACO Dresden-Electric Junction 1223',\n",
       " 'ACO Dresden-Elwood 1220',\n",
       " 'ACO Dresden-Mole Creek 1202',\n",
       " 'ACO Electric Junction-Lombard 11120',\n",
       " 'ACO Electric Junction-Naperville 11107',\n",
       " 'ACO Electric Junction-Nelson 15502',\n",
       " 'ACO Electric Junction-North Aurora 11104',\n",
       " 'ACO Electric Junction-Plano 16703',\n",
       " 'ACO Electric Junction-Wayne 11126',\n",
       " 'ACO Elgin-Spaulding 7901',\n",
       " 'ACO Elmhurst-Franklin Park 13503',\n",
       " 'ACO Elmhurst-Lombard 12007',\n",
       " 'ACO Elwood-Goodings Grove 11620',\n",
       " 'ACO Golf Mill-Skokie 8823',\n",
       " 'ACO Goodings Grove-Katydid Road 19601',\n",
       " 'ACO Goodings Grove-Lockport 11604',\n",
       " 'ACO Goodings Grove-Powerton 303',\n",
       " 'ACO Green Acres-Olive 345015',\n",
       " 'ACO Harbor-University 17008',\n",
       " 'ACO Hartsdale-Munster 138023',\n",
       " 'ACO Highland-Kenwood 138099',\n",
       " 'ACO Highland-Lake George 138063',\n",
       " 'ACO Itasca-Lombard 12001',\n",
       " 'ACO Kenosha-Lakeview 9341',\n",
       " 'ACO Kenwood-Munster 138094',\n",
       " 'ACO Lake George-Miller 138022',\n",
       " 'ACO Lake George-Munster 345022',\n",
       " 'ACO Lake George-Taney 138062',\n",
       " 'ACO Lake George-Tower Road 138066',\n",
       " 'ACO Lakeview-Zion 28201',\n",
       " 'ACO Libertyville-Prospect Heights 11723',\n",
       " 'ACO Libertyville-Prospect Heights 15424',\n",
       " 'ACO Libertyville-Silver Lake 13821',\n",
       " 'ACO Libertyville-Tollway 18502',\n",
       " 'ACO Libertyville-Waukegan 1604',\n",
       " 'ACO Libertyville-Zion 15423',\n",
       " 'ACO Libertyville-Zion 2224',\n",
       " 'ACO Libertyville-Zion Energy Center 15423',\n",
       " 'ACO Lisle-Lockport 10802',\n",
       " 'ACO Lisle-Lombard 10321',\n",
       " 'ACO Lockport-Lombard 10807',\n",
       " 'ACO Lockport-McCook 10803',\n",
       " 'ACO Munster-Taney 138095',\n",
       " 'ACO Northbrook-Skokie 8805',\n",
       " 'ACO Northbrook-Zion 2218',\n",
       " 'ACO Racine-Somers 1645',\n",
       " 'ACO Racine-Somers X-124',\n",
       " 'ACO Romeoville-Will County 1803',\n",
       " 'ACO Sandwich-Waterman 11301',\n",
       " 'ACO Sheffield-Wolf Lake 138093',\n",
       " 'ACO Silver Lake-Wayne 14401',\n",
       " 'ACO Spaulding-Wayne 7910',\n",
       " 'ACO Tollway-Wayne 14402',\n",
       " 'ACO University-Washington Park 17404',\n",
       " 'ACO Waukegan-Zion 1609',\n",
       " 'ACO Waukegan-Zion 2218',\n",
       " 'ACO Zion-Zion Energy Center 2223'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dfMatchReduced['combo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method-wrapper '__len__' of set object at 0x0000022E05E0FAC0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dfMatchReduced['combo']).__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m length(\u001b[39mset\u001b[39m(dfMatchReduced[\u001b[39m'\u001b[39m\u001b[39mcombo\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'length' is not defined"
     ]
    }
   ],
   "source": [
    "length(set(dfMatchReduced['combo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m size(\u001b[39mset\u001b[39m(dfMatchReduced[\u001b[39m'\u001b[39m\u001b[39mcombo\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'size' is not defined"
     ]
    }
   ],
   "source": [
    "size(set(dfMatchReduced['combo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mset\u001b[39;49m(dfMatchReduced[\u001b[39m'\u001b[39;49m\u001b[39mcombo\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49msize()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "set(dfMatchReduced['combo']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mset\u001b[39;49m(dfMatchReduced[\u001b[39m'\u001b[39;49m\u001b[39mcombo\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mlength\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'length'"
     ]
    }
   ],
   "source": [
    "set(dfMatchReduced['combo']).length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mset\u001b[39;49m(dfMatchReduced[\u001b[39m'\u001b[39;49m\u001b[39mcombo\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mlength()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'length'"
     ]
    }
   ],
   "source": [
    "set(dfMatchReduced['combo']).length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m length(\u001b[39mset\u001b[39m(dfMatchReduced[\u001b[39m'\u001b[39m\u001b[39mcombo\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'length' is not defined"
     ]
    }
   ],
   "source": [
    "length(set(dfMatchReduced['combo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dfMatchReduced['combo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .conda (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afcff966-0820-4907-b58c-e38a67bc4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e578d71d-a7eb-4472-9489-6dc87744ec56",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-91ab4b7cd46f>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")\n",
    "\n",
    "from src.housekeeping_gads import (\n",
    "    # do nothing lol\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d40d67-04b9-4c93-ab99-3fa3d5f66a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")\n",
    "\n",
    "# from src.housekeeping_gads import (\n",
    "#     # do nothing lol\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0709ce96-ed2c-4ee3-bf4f-fca7e839cd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We seem to be working in a JuPyteR Notebook\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable=undefined-variable line-too-long invalid-name missing-function-docstring f-string-without-interpolation\n",
    "\n",
    "try:\n",
    "    fileAddr = __vsc_ipynb_file__\n",
    "    wd = os.path.dirname(fileAddr)\n",
    "    print(\"We seem to be working in a JuPyteR Notebook\")\n",
    "except ImportError:\n",
    "    wd = os.getcwd()\n",
    "    print(\"We seem to be working in a regular .py file\")\n",
    "\n",
    "\n",
    "rawDataFolder = os.path.join(wd, \"rawData\")\n",
    "processedDataFolder = os.path.join(wd, \"processedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8514a872-f8bc-48df-bf19-595cd1e12901",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\rawData\\\\GADS 2024 AC Inventory.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_gads.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gadsFileAddr \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(rawDataFolder, \u001b[39m\"\u001b[39m\u001b[39mGADS 2024 AC Inventory.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m dfGads0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(gadsFileAddr)\n\u001b[0;32m      4\u001b[0m sizeGads0 \u001b[39m=\u001b[39m dfGads0\u001b[39m.\u001b[39mshape\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of GADS db before filtering: \u001b[39m\u001b[39m{\u001b[39;00msizeGads0[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msizeGads0[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\rawData\\\\GADS 2024 AC Inventory.csv'"
     ]
    }
   ],
   "source": [
    "gadsFileAddr = os.path.join(rawDataFolder, \"GADS 2024 AC Inventory.csv\")\n",
    "dfGads0 = pd.read_csv(gadsFileAddr)\n",
    "sizeGads0 = dfGads0.shape\n",
    "print(f\"Size of GADS db before filtering: {sizeGads0[0]}, {sizeGads0[1]}\")\n",
    "companyNamesGads0 = set(dfGads0.CompanyName)\n",
    "numCompaniesGads0 = len(companyNamesGads0)\n",
    "print(f\"There are {numCompaniesGads0} unique companies owning tlines in the entire GADS database.\")\n",
    "# display(dfgads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ae0502-01e0-4576-bba9-da01ca49884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db before filtering: 11624, 40\n",
      "There are 895 unique companies owning tlines in the entire GADS database.\n"
     ]
    }
   ],
   "source": [
    "gadsFileAddr = os.path.join(rawDataFolder, \"GADS inventory 2024.csv\")\n",
    "dfGads0 = pd.read_csv(gadsFileAddr)\n",
    "sizeGads0 = dfGads0.shape\n",
    "print(f\"Size of GADS db before filtering: {sizeGads0[0]}, {sizeGads0[1]}\")\n",
    "companyNamesGads0 = set(dfGads0.CompanyName)\n",
    "numCompaniesGads0 = len(companyNamesGads0)\n",
    "print(f\"There are {numCompaniesGads0} unique companies owning tlines in the entire GADS database.\")\n",
    "# display(dfgads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8246f34a-ae83-4937-9446-e2f901eb593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db before filtering: 11624, 40\n",
      "There are 895 unique companies owning tlines in the entire GADS database.\n"
     ]
    }
   ],
   "source": [
    "gadsFileAddr = os.path.join(rawDataFolder, \"GADS inventory 2024.csv\")\n",
    "dfGads0 = pd.read_csv(gadsFileAddr)\n",
    "sizeGads0 = dfGads0.shape\n",
    "print(f\"Size of GADS db before filtering: {sizeGads0[0]}, {sizeGads0[1]}\")\n",
    "companyNamesGads0 = set(dfGads0.CompanyName)\n",
    "numCompaniesGads0 = len(companyNamesGads0)\n",
    "print(f\"There are {numCompaniesGads0} unique companies owning tlines in the entire GADS database.\")\n",
    "# display(dfgads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "886ecb37-2ee4-4af7-ad85-4ff5e9cd7ed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-d77c174de64e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    components =\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "components = \n",
    "veloFileAddr = os.path.join(rawDataFolder, \"tlines-near-chicago-ohare-raw.xlsx\") # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8580b4ef-614c-46cd-a051-4cb594427cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\rawData'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_gads.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m veloFileAddr \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(rawDataFolder, ) \u001b[39m# tlines which are <= 50miles from `Chicago/Ohare` weather station\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(veloFileAddr)\n\u001b[1;32m----> 7\u001b[0m dfVelo0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(veloFileAddr, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m sizeVelo0 \u001b[39m=\u001b[39m dfVelo0\u001b[39m.\u001b[39mshape\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of velocity suite db before any filtering: \u001b[39m\u001b[39m{\u001b[39;00msizeVelo0[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msizeVelo0[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[0;32m   1565\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[1;32m-> 1567\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\n\u001b[0;32m   1568\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io,\n\u001b[0;32m   1569\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   1570\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m   1571\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[39mReader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mopenpyxl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 553\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    554\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    556\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    557\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:563\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m IOHandles(\n\u001b[0;32m    560\u001b[0m     handle\u001b[39m=\u001b[39mfilepath_or_buffer, compression\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    561\u001b[0m )\n\u001b[0;32m    562\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workbook_class)):\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m    564\u001b[0m         filepath_or_buffer, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    565\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workbook_class):\n\u001b[0;32m    568\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbook \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\rawData'"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "components = \"genUnits\"\n",
    "filenameVeloGads = location + \"-near-\" + components\n",
    "veloFileAddr = os.path.join(rawDataFolder, ) # tlines which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenameVeloGads = location + \"-near-\" + components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicago-ohare-near-genUnits'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenameVeloGads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992dcd0c-7258-4326-9f39-d0f58c7811d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\chicago-ohare-near-genUnits.xlsx\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\rawData\\\\chicago-ohare-near-genUnits.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_gads.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m veloFileAddr \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(rawDataFolder, filenameVeloGads) \u001b[39m# gen units which are <= 50miles from `Chicago/Ohare` weather station\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(veloFileAddr)\n\u001b[1;32m----> 8\u001b[0m dfVelo0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(veloFileAddr, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m sizeVelo0 \u001b[39m=\u001b[39m dfVelo0\u001b[39m.\u001b[39mshape\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of velocity suite db before any filtering: \u001b[39m\u001b[39m{\u001b[39;00msizeVelo0[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msizeVelo0[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[0;32m   1565\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[1;32m-> 1567\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\n\u001b[0;32m   1568\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io,\n\u001b[0;32m   1569\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   1570\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m   1571\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[39mReader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mopenpyxl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 553\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    554\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    556\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    557\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\excel\\_base.py:563\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m IOHandles(\n\u001b[0;32m    560\u001b[0m     handle\u001b[39m=\u001b[39mfilepath_or_buffer, compression\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    561\u001b[0m )\n\u001b[0;32m    562\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workbook_class)):\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m    564\u001b[0m         filepath_or_buffer, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    565\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workbook_class):\n\u001b[0;32m    568\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbook \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\jhaa\\\\Documents\\\\documents_general\\\\extreme-weather-repo\\\\rawData\\\\chicago-ohare-near-genUnits.xlsx'"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "components = \"genUnits\"\n",
    "ext = \".xlsx\"\n",
    "filenameVeloGads = location + \"-near-\" + components + ext\n",
    "veloFileAddr = os.path.join(rawDataFolder, filenameVeloGads) # gen units which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809df42d-b4ff-440f-849b-f8e43e77e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\rawData\\genUnits-near-chicago-ohare.xlsx\n",
      "Size of velocity suite db before any filtering: 291, 18\n"
     ]
    }
   ],
   "source": [
    "location = \"chicago-ohare\"\n",
    "components = \"genUnits\"\n",
    "ext = \".xlsx\"\n",
    "filenameVeloGads = components + \"-near-\" + location + ext\n",
    "veloFileAddr = os.path.join(rawDataFolder, filenameVeloGads) # gen units which are <= 50miles from `Chicago/Ohare` weather station\n",
    "print(veloFileAddr)\n",
    "dfVelo0 = pd.read_excel(veloFileAddr, engine='openpyxl')\n",
    "sizeVelo0 = dfVelo0.shape\n",
    "print(f\"Size of velocity suite db before any filtering: {sizeVelo0[0]}, {sizeVelo0[1]}\")\n",
    "# dfVelo0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41535d76-9b98-47d7-b8b4-226e9cd78b6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Voltage kV'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Voltage kV'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_gads.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Filter rows with 'Undetermined Company`\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Filter tlines with less than 100kV voltage\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dfVelo \u001b[39m=\u001b[39m dfVelo0\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> 6\u001b[0m dfVelo \u001b[39m=\u001b[39m dfVelo[ dfVelo[\u001b[39m'\u001b[39;49m\u001b[39mVoltage kV\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m100\u001b[39m ]\n\u001b[0;32m      7\u001b[0m \u001b[39m# Filter tlines not currently in service\u001b[39;00m\n\u001b[0;32m      8\u001b[0m dfVelo \u001b[39m=\u001b[39m dfVelo[ dfVelo[\u001b[39m'\u001b[39m\u001b[39mProposed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mIn Service\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4091\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Voltage kV'"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a33d02d0-1dd6-4efa-a90c-3e5d449da27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': 291, 18\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Company Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\main_gads.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m sizeVelo \u001b[39m=\u001b[39m dfVelo\u001b[39m.\u001b[39mshape\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSize of velocity suite db after filtering for Company Names, Voltage [kV] and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mProposed\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00msizeVelo[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msizeVelo[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m companyNamesVelo \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(dfVelo[\u001b[39m'\u001b[39;49m\u001b[39mCompany Name\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     13\u001b[0m numCompaniesVelo \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(companyNamesVelo)\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere are \u001b[39m\u001b[39m{\u001b[39;00mnumCompaniesVelo\u001b[39m}\u001b[39;00m\u001b[39m named companies owning the tlines near \u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4091\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jhaa\\Documents\\documents_general\\extreme-weather-repo\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company Name'"
     ]
    }
   ],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "# dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "# dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "companyNamesVelo = set(dfVelo['Company Name'])\n",
    "numCompaniesVelo = len(companyNamesVelo)\n",
    "print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "print(f\"Their names are:\")\n",
    "print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97e1d69-8e02-4d10-bad4-3dacaf90733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with 'Undetermined Company`\n",
    "# dfVelo = dfVelo0[ dfVelo0['Company Name'] != 'Undetermined Company' ]\n",
    "# Filter tlines with less than 100kV voltage\n",
    "dfVelo = dfVelo0.copy()\n",
    "# dfVelo = dfVelo[ dfVelo['Voltage kV'] >= 100 ]\n",
    "# Filter tlines not currently in service\n",
    "# dfVelo = dfVelo[ dfVelo['Proposed'] == 'In Service']\n",
    "\n",
    "sizeVelo = dfVelo.shape\n",
    "# print(f\"Size of velocity suite db after filtering for Company Names, Voltage [kV] and 'Proposed': {sizeVelo[0]}, {sizeVelo[1]}\")\n",
    "# companyNamesVelo = set(dfVelo['Company Name'])\n",
    "# numCompaniesVelo = len(companyNamesVelo)\n",
    "# print(f\"There are {numCompaniesVelo} named companies owning the tlines near {location}\")\n",
    "# print(f\"Their names are:\")\n",
    "# print(companyNamesVelo)\n",
    "# dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7d3b68e-7cd4-451d-a618-fef4bb055b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Now let's see how many tlines are owned by these {numCompaniesVelo} \"       \"companies in the entire GADS database:\")\n",
    "\n",
    "# print(\"\"f\"But first I'll need to rename some companies in vs db to match with the exact strings of the GADS db.\")\n",
    "\n",
    "# companyNamesVelo2Gads = companyNamesVelo.copy()  # Create a copy to avoid modifying the original\n",
    "\n",
    "# # Replace the element using the 'discard' method (more efficient for sets)\n",
    "# companyNamesVelo2Gads.discard(\"Commonwealth Edison Co\")\n",
    "# companyNamesVelo2Gads.add(\"Commonwealth Edison Company\")\n",
    "# companyNamesVelo2Gads.discard(\"AmerenIP\")\n",
    "# companyNamesVelo2Gads.add(\"Ameren Services Company\")\n",
    "# companyNamesVelo2Gads.discard(\"American Transmission Co LLC\")\n",
    "# companyNamesVelo2Gads.add(\"American Transmission Company\")\n",
    "# companyNamesVelo2Gads.discard(\"Northern Indiana Public Service Co LLC\")\n",
    "# companyNamesVelo2Gads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "# companyNamesVelo2Gads.discard(\"Northern Municipal Power Agency\")\n",
    "# companyNamesVelo2Gads.add(\"Northern Indiana Public Service Company [BA\")\n",
    "# companyNamesVelo2Gads.discard(\"Undetermined Company\")\n",
    "# companyNamesVelo2Gads.add(\"Commonwealth Edison Company\")\n",
    "# print(companyNamesVelo2Gads)\n",
    "\n",
    "# dfVeloSorted = sort_and_shift_columns_dfVelo(dfVelo)\n",
    "dfVeloSorted = dfVelo\n",
    "veloSortedAddr = os.path.join(processedDataFolder, \"dfVelo-\"+components+\"-\"+location+\"-Sorted\"+ext)\n",
    "dfVeloSorted.to_excel(veloSortedAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32aecdc4-90e6-484b-85c3-1da5f1b77616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")\n",
    "\n",
    "from src.housekeeping_gads import (\n",
    "    filter_states # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a862a51a-ab48-4109-8f62-ab7884e3cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db after filtering: 0, 40\n"
     ]
    }
   ],
   "source": [
    "dfGads = dfGads0.copy()\n",
    "# dfGads = dfGads[dfGads['CompanyName'].isin(companyNamesVelo2Gads)]\n",
    "# voltageClassesGads0 = set(dfGads['VoltageClassCodeName'])\n",
    "# print(voltageClassesGads0)\n",
    "# voltageClassesAllowedGads = voltageClassesGads0.copy()\n",
    "# voltageClassesAllowedGads.discard(\"0-99 kV\")\n",
    "\n",
    "# dfGads = dfGads[dfGads['VoltageClassCodeName'].isin(voltageClassesAllowedGads)]\n",
    "dfGads = filter_states(dfGads)\n",
    "sizeGads = dfGads.shape\n",
    "print(f\"Size of GADS db after filtering: {sizeGads[0]}, {sizeGads[1]}\")\n",
    "\n",
    "# dfGadsSorted = sort_and_shift_columns(dfGads)\n",
    "\n",
    "# gadsSortedAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "# dfGadsSorted.to_excel(gadsSortedAddr, index=False)\n",
    "\n",
    "# # dfGadsLatest = filter_tlines_by_latest_reported_year(dfGadsSorted)\n",
    "# dfGadsLatest = get_latest_entries(dfGadsSorted)\n",
    "\n",
    "# sizeGadsLatest = dfGadsLatest.shape\n",
    "\n",
    "# print(f\"Size of GADS db after filtering for only latest reported year: {sizeGadsLatest[0]}, {sizeGadsLatest[1]}\")\n",
    "\n",
    "# gadsLatestAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "# dfGadsLatest.to_excel(gadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f198028d-2520-4414-aacd-bef705ca690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db after filtering: 0, 40\n"
     ]
    }
   ],
   "source": [
    "dfGads = dfGads0.copy()\n",
    "# dfGads = dfGads[dfGads['CompanyName'].isin(companyNamesVelo2Gads)]\n",
    "# voltageClassesGads0 = set(dfGads['VoltageClassCodeName'])\n",
    "# print(voltageClassesGads0)\n",
    "# voltageClassesAllowedGads = voltageClassesGads0.copy()\n",
    "# voltageClassesAllowedGads.discard(\"0-99 kV\")\n",
    "\n",
    "# dfGads = dfGads[dfGads['VoltageClassCodeName'].isin(voltageClassesAllowedGads)]\n",
    "dfGads = filter_states(dfGads)\n",
    "sizeGads = dfGads.shape\n",
    "print(f\"Size of GADS db after filtering: {sizeGads[0]}, {sizeGads[1]}\")\n",
    "\n",
    "# dfGadsSorted = sort_and_shift_columns(dfGads)\n",
    "\n",
    "# gadsSortedAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "# dfGadsSorted.to_excel(gadsSortedAddr, index=False)\n",
    "\n",
    "# # dfGadsLatest = filter_tlines_by_latest_reported_year(dfGadsSorted)\n",
    "# dfGadsLatest = get_latest_entries(dfGadsSorted)\n",
    "\n",
    "# sizeGadsLatest = dfGadsLatest.shape\n",
    "\n",
    "# print(f\"Size of GADS db after filtering for only latest reported year: {sizeGadsLatest[0]}, {sizeGadsLatest[1]}\")\n",
    "\n",
    "# gadsLatestAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "# dfGadsLatest.to_excel(gadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97742a34-ec09-49ff-a60e-7cd144daa40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from src.housekeeping import (\n",
    "    # filter_tlines_by_latest_reported_year,  # Forward Declaration\n",
    "    get_latest_entries, # Forward Declaration\n",
    "    get_matched_entries, # Forward Declaration\n",
    "    get_reduced_df, # Forward Declaration\n",
    "    sort_and_shift_columns, # Forward Declaration\n",
    "    sort_and_shift_columns_dfVelo, # Forward Declaration\n",
    ")\n",
    "\n",
    "from src.housekeeping_gads import (\n",
    "    filter_states # Forward Declaration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83ae6c40-192b-40b8-8668-bf2e1d0dc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db after filtering: 0, 40\n"
     ]
    }
   ],
   "source": [
    "dfGads = dfGads0.copy()\n",
    "# dfGads = dfGads[dfGads['CompanyName'].isin(companyNamesVelo2Gads)]\n",
    "# voltageClassesGads0 = set(dfGads['VoltageClassCodeName'])\n",
    "# print(voltageClassesGads0)\n",
    "# voltageClassesAllowedGads = voltageClassesGads0.copy()\n",
    "# voltageClassesAllowedGads.discard(\"0-99 kV\")\n",
    "\n",
    "# dfGads = dfGads[dfGads['VoltageClassCodeName'].isin(voltageClassesAllowedGads)]\n",
    "dfGads = filter_states(dfGads)\n",
    "sizeGads = dfGads.shape\n",
    "print(f\"Size of GADS db after filtering: {sizeGads[0]}, {sizeGads[1]}\")\n",
    "\n",
    "# dfGadsSorted = sort_and_shift_columns(dfGads)\n",
    "\n",
    "# gadsSortedAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "# dfGadsSorted.to_excel(gadsSortedAddr, index=False)\n",
    "\n",
    "# # dfGadsLatest = filter_tlines_by_latest_reported_year(dfGadsSorted)\n",
    "# dfGadsLatest = get_latest_entries(dfGadsSorted)\n",
    "\n",
    "# sizeGadsLatest = dfGadsLatest.shape\n",
    "\n",
    "# print(f\"Size of GADS db after filtering for only latest reported year: {sizeGadsLatest[0]}, {sizeGadsLatest[1]}\")\n",
    "\n",
    "# gadsLatestAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "# dfGadsLatest.to_excel(gadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UnitID, UtilityCode, UtilityName, UnitCode, UnitName, UtilityUnitCode, RatingMW, RatingMW_grp, UnitTypeCode, UnitTypeCodeDesc, UnitStatusName, CommercialDT, CommercialDT_grp, UnitRetireDT, UnitRetireDT_grp, UnitTimeZoneCode, StateName, CountryName, EIACode, FuelCode, FuelCodeDesc, BlockNERCID, BlockUtilityCode, BlockUnitCode, BlockUnitName, CreationDT, UpdateDT, CompanyName, CompanyCode, NERCID, NERCID_AliasID, RegionCode, SubRegionName, ExtractionDT, DeletionDT, NERC_DataPullDT, ID_SK, Rnk, AliasID, IsCurrent]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4e50cdc-e341-4196-9080-44974bdf5fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db before filtering: 11624, 40\n",
      "There are 895 unique companies owning tlines in the entire GADS database.\n"
     ]
    }
   ],
   "source": [
    "gadsFileAddr = os.path.join(rawDataFolder, \"GADS inventory 2024.csv\")\n",
    "dfGads0 = pd.read_csv(gadsFileAddr)\n",
    "sizeGads0 = dfGads0.shape\n",
    "print(f\"Size of GADS db before filtering: {sizeGads0[0]}, {sizeGads0[1]}\")\n",
    "companyNamesGads0 = set(dfGads0.CompanyName)\n",
    "numCompaniesGads0 = len(companyNamesGads0)\n",
    "print(f\"There are {numCompaniesGads0} unique companies owning tlines in the entire GADS database.\")\n",
    "# display(dfgads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4b944c-5ef2-48f9-9b18-ea292e5b33f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db after filtering: 0, 40\n"
     ]
    }
   ],
   "source": [
    "dfGads = dfGads0.copy()\n",
    "# dfGads = dfGads[dfGads['CompanyName'].isin(companyNamesVelo2Gads)]\n",
    "# voltageClassesGads0 = set(dfGads['VoltageClassCodeName'])\n",
    "# print(voltageClassesGads0)\n",
    "# voltageClassesAllowedGads = voltageClassesGads0.copy()\n",
    "# voltageClassesAllowedGads.discard(\"0-99 kV\")\n",
    "\n",
    "# dfGads = dfGads[dfGads['VoltageClassCodeName'].isin(voltageClassesAllowedGads)]\n",
    "dfGads = filter_states(dfGads)\n",
    "sizeGads = dfGads.shape\n",
    "print(f\"Size of GADS db after filtering: {sizeGads[0]}, {sizeGads[1]}\")\n",
    "\n",
    "# dfGadsSorted = sort_and_shift_columns(dfGads)\n",
    "\n",
    "# gadsSortedAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "# dfGadsSorted.to_excel(gadsSortedAddr, index=False)\n",
    "\n",
    "# # dfGadsLatest = filter_tlines_by_latest_reported_year(dfGadsSorted)\n",
    "# dfGadsLatest = get_latest_entries(dfGadsSorted)\n",
    "\n",
    "# sizeGadsLatest = dfGadsLatest.shape\n",
    "\n",
    "# print(f\"Size of GADS db after filtering for only latest reported year: {sizeGadsLatest[0]}, {sizeGadsLatest[1]}\")\n",
    "\n",
    "# gadsLatestAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "# dfGadsLatest.to_excel(gadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UnitID, UtilityCode, UtilityName, UnitCode, UnitName, UtilityUnitCode, RatingMW, RatingMW_grp, UnitTypeCode, UnitTypeCodeDesc, UnitStatusName, CommercialDT, CommercialDT_grp, UnitRetireDT, UnitRetireDT_grp, UnitTimeZoneCode, StateName, CountryName, EIACode, FuelCode, FuelCodeDesc, BlockNERCID, BlockUtilityCode, BlockUnitCode, BlockUnitName, CreationDT, UpdateDT, CompanyName, CompanyCode, NERCID, NERCID_AliasID, RegionCode, SubRegionName, ExtractionDT, DeletionDT, NERC_DataPullDT, ID_SK, Rnk, AliasID, IsCurrent]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfGasd0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfGasd0\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfGasd0' is not defined"
     ]
    }
   ],
   "source": [
    "dfGasd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5225</td>\n",
       "      <td>934</td>\n",
       "      <td>Mid-Set Cogeneration Company</td>\n",
       "      <td>301</td>\n",
       "      <td>Mid-Set Cogeneration #1</td>\n",
       "      <td>934301</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>860</td>\n",
       "      <td>Co-generator Block\\t</td>\n",
       "      <td>...</td>\n",
       "      <td>0x8F556D9551A5DC25589FF741B87A4310</td>\n",
       "      <td>WECC</td>\n",
       "      <td>WECC</td>\n",
       "      <td>2017-03-02 16:20:01.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-22 23:22:38.307</td>\n",
       "      <td>4675</td>\n",
       "      <td>1</td>\n",
       "      <td>0xC283EE6CE291A7CAD48AA411619603E9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10108</td>\n",
       "      <td>209</td>\n",
       "      <td>VINELAND MUNICIPAL ELECTRIC UTILITIES</td>\n",
       "      <td>391</td>\n",
       "      <td>Vineland CT 11</td>\n",
       "      <td>209391</td>\n",
       "      <td>59.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5967F80A0B5CBF7817E63C8F228F5885</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - PJM</td>\n",
       "      <td>2017-02-13 15:55:00.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-22 23:22:38.307</td>\n",
       "      <td>9148</td>\n",
       "      <td>1</td>\n",
       "      <td>0xF65721851DF7CAB86A39D862240A53D9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12135</td>\n",
       "      <td>630</td>\n",
       "      <td>Minnesota Municipal Power Agency</td>\n",
       "      <td>801</td>\n",
       "      <td>Shakopee Energy Park</td>\n",
       "      <td>630801</td>\n",
       "      <td>46.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>...</td>\n",
       "      <td>0xA99FDBEE11D34711CF8BE164BAA2E434</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2017-02-14 20:20:02.077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-22 23:22:38.307</td>\n",
       "      <td>11005</td>\n",
       "      <td>1</td>\n",
       "      <td>0xCB702F1DCCE6057310203FABAC054AB6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1215</td>\n",
       "      <td>450</td>\n",
       "      <td>Buckeye Power</td>\n",
       "      <td>360</td>\n",
       "      <td>GREENVILLE #1</td>\n",
       "      <td>450360</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0xF97C22645CBF0B981BB097D4A5F230F8</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 15:30:00.513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 16:00:05.970</td>\n",
       "      <td>11017</td>\n",
       "      <td>1</td>\n",
       "      <td>0x486F65135155CF15856A9AB68D2A559D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1216</td>\n",
       "      <td>450</td>\n",
       "      <td>Buckeye Power</td>\n",
       "      <td>361</td>\n",
       "      <td>GREENVILLE #2</td>\n",
       "      <td>450361</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0xF97C22645CBF0B981BB097D4A5F230F8</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 15:30:00.513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 16:00:05.970</td>\n",
       "      <td>11018</td>\n",
       "      <td>1</td>\n",
       "      <td>0x8D9B6D4F15F3ABDCA36A0E55FC141E1B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11619</th>\n",
       "      <td>10149</td>\n",
       "      <td>917</td>\n",
       "      <td>Idaho Power Company</td>\n",
       "      <td>544</td>\n",
       "      <td>MILNER #2</td>\n",
       "      <td>917544</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Pumped Storage/Hydro</td>\n",
       "      <td>...</td>\n",
       "      <td>0xF074C7196E9E0B1908E2C3D3D5E4FA00</td>\n",
       "      <td>WECC</td>\n",
       "      <td>WECC</td>\n",
       "      <td>2024-05-15 21:15:00.520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-15 22:00:10.187</td>\n",
       "      <td>36316</td>\n",
       "      <td>1</td>\n",
       "      <td>0xBCB86FAE353770C036BDE208D5F48B69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11620</th>\n",
       "      <td>10150</td>\n",
       "      <td>917</td>\n",
       "      <td>Idaho Power Company</td>\n",
       "      <td>545</td>\n",
       "      <td>MILNER #3</td>\n",
       "      <td>917545</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Pumped Storage/Hydro</td>\n",
       "      <td>...</td>\n",
       "      <td>0xF074C7196E9E0B1908E2C3D3D5E4FA00</td>\n",
       "      <td>WECC</td>\n",
       "      <td>WECC</td>\n",
       "      <td>2024-05-15 21:25:00.570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-15 22:00:10.187</td>\n",
       "      <td>36317</td>\n",
       "      <td>1</td>\n",
       "      <td>0x2A498FD1E7D7391C5D0B8527EF7BE55B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11621</th>\n",
       "      <td>11706</td>\n",
       "      <td>2F9</td>\n",
       "      <td>Racine Hydro</td>\n",
       "      <td>500</td>\n",
       "      <td>Racine #1</td>\n",
       "      <td>2F9500</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Pumped Storage/Hydro</td>\n",
       "      <td>...</td>\n",
       "      <td>0x93B9959FAF5F568A1E80FD3BBDE20CD1</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - PJM</td>\n",
       "      <td>2024-05-16 07:20:00.233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-16 08:00:08.747</td>\n",
       "      <td>36318</td>\n",
       "      <td>1</td>\n",
       "      <td>0x5174E0425DB7E4922B2BF88051B2C653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11622</th>\n",
       "      <td>11707</td>\n",
       "      <td>2F9</td>\n",
       "      <td>Racine Hydro</td>\n",
       "      <td>501</td>\n",
       "      <td>Racine #2</td>\n",
       "      <td>2F9501</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Pumped Storage/Hydro</td>\n",
       "      <td>...</td>\n",
       "      <td>0x93B9959FAF5F568A1E80FD3BBDE20CD1</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - PJM</td>\n",
       "      <td>2024-05-16 07:20:00.233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-16 08:00:08.747</td>\n",
       "      <td>36319</td>\n",
       "      <td>1</td>\n",
       "      <td>0x60ED78B8304296D01A94C4E947EEA2AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11623</th>\n",
       "      <td>5329</td>\n",
       "      <td>619</td>\n",
       "      <td>Muscatine Power &amp; Water</td>\n",
       "      <td>181</td>\n",
       "      <td>MUSCATINE #8A</td>\n",
       "      <td>619181</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>...</td>\n",
       "      <td>0xFE5607BE3DF9C3BA10EAEEDBBBF91D21</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-16 12:40:00.173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-16 13:00:09.350</td>\n",
       "      <td>36320</td>\n",
       "      <td>1</td>\n",
       "      <td>0x6ABDDF84A0AFC6877DAAFF7E4A4AF85F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11624 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UnitID UtilityCode                            UtilityName  UnitCode  \\\n",
       "0        5225         934           Mid-Set Cogeneration Company       301   \n",
       "1       10108         209  VINELAND MUNICIPAL ELECTRIC UTILITIES       391   \n",
       "2       12135         630       Minnesota Municipal Power Agency       801   \n",
       "3        1215         450                          Buckeye Power       360   \n",
       "4        1216         450                          Buckeye Power       361   \n",
       "...       ...         ...                                    ...       ...   \n",
       "11619   10149         917                    Idaho Power Company       544   \n",
       "11620   10150         917                    Idaho Power Company       545   \n",
       "11621   11706         2F9                           Racine Hydro       500   \n",
       "11622   11707         2F9                           Racine Hydro       501   \n",
       "11623    5329         619                Muscatine Power & Water       181   \n",
       "\n",
       "                      UnitName UtilityUnitCode  RatingMW  RatingMW_grp  \\\n",
       "0      Mid-Set Cogeneration #1          934301      35.0           1.0   \n",
       "1               Vineland CT 11          209391      59.9           1.0   \n",
       "2         Shakopee Energy Park          630801      46.7           1.0   \n",
       "3                GREENVILLE #1          450360      58.0           1.0   \n",
       "4                GREENVILLE #2          450361      58.0           1.0   \n",
       "...                        ...             ...       ...           ...   \n",
       "11619                MILNER #2          917544      12.1           1.0   \n",
       "11620                MILNER #3          917545       0.8           1.0   \n",
       "11621                Racine #1          2F9500      24.0           1.0   \n",
       "11622                Racine #2          2F9501      24.0           1.0   \n",
       "11623            MUSCATINE #8A          619181      18.0           1.0   \n",
       "\n",
       "       UnitTypeCode                                 UnitTypeCodeDesc  ...  \\\n",
       "0               860                             Co-generator Block\\t  ...   \n",
       "1               300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "2               800                                    Miscellaneous  ...   \n",
       "3               300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "4               300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "...             ...                                              ...  ...   \n",
       "11619           500                             Pumped Storage/Hydro  ...   \n",
       "11620           500                             Pumped Storage/Hydro  ...   \n",
       "11621           500                             Pumped Storage/Hydro  ...   \n",
       "11622           500                             Pumped Storage/Hydro  ...   \n",
       "11623           800                                    Miscellaneous  ...   \n",
       "\n",
       "                           NERCID_AliasID RegionCode  SubRegionName  \\\n",
       "0      0x8F556D9551A5DC25589FF741B87A4310       WECC           WECC   \n",
       "1      0x5967F80A0B5CBF7817E63C8F228F5885        RFC      RFC - PJM   \n",
       "2      0xA99FDBEE11D34711CF8BE164BAA2E434        MRO            MRO   \n",
       "3      0xF97C22645CBF0B981BB097D4A5F230F8        RFC            RFC   \n",
       "4      0xF97C22645CBF0B981BB097D4A5F230F8        RFC            RFC   \n",
       "...                                   ...        ...            ...   \n",
       "11619  0xF074C7196E9E0B1908E2C3D3D5E4FA00       WECC           WECC   \n",
       "11620  0xF074C7196E9E0B1908E2C3D3D5E4FA00       WECC           WECC   \n",
       "11621  0x93B9959FAF5F568A1E80FD3BBDE20CD1        RFC      RFC - PJM   \n",
       "11622  0x93B9959FAF5F568A1E80FD3BBDE20CD1        RFC      RFC - PJM   \n",
       "11623  0xFE5607BE3DF9C3BA10EAEEDBBBF91D21        MRO            MRO   \n",
       "\n",
       "                  ExtractionDT DeletionDT          NERC_DataPullDT  ID_SK Rnk  \\\n",
       "0      2017-03-02 16:20:01.033        NaN  2017-03-22 23:22:38.307   4675   1   \n",
       "1      2017-02-13 15:55:00.647        NaN  2017-03-22 23:22:38.307   9148   1   \n",
       "2      2017-02-14 20:20:02.077        NaN  2017-03-22 23:22:38.307  11005   1   \n",
       "3      2017-03-23 15:30:00.513        NaN  2017-03-23 16:00:05.970  11017   1   \n",
       "4      2017-03-23 15:30:00.513        NaN  2017-03-23 16:00:05.970  11018   1   \n",
       "...                        ...        ...                      ...    ...  ..   \n",
       "11619  2024-05-15 21:15:00.520        NaN  2024-05-15 22:00:10.187  36316   1   \n",
       "11620  2024-05-15 21:25:00.570        NaN  2024-05-15 22:00:10.187  36317   1   \n",
       "11621  2024-05-16 07:20:00.233        NaN  2024-05-16 08:00:08.747  36318   1   \n",
       "11622  2024-05-16 07:20:00.233        NaN  2024-05-16 08:00:08.747  36319   1   \n",
       "11623  2024-05-16 12:40:00.173        NaN  2024-05-16 13:00:09.350  36320   1   \n",
       "\n",
       "                                  AliasID IsCurrent  \n",
       "0      0xC283EE6CE291A7CAD48AA411619603E9         1  \n",
       "1      0xF65721851DF7CAB86A39D862240A53D9         1  \n",
       "2      0xCB702F1DCCE6057310203FABAC054AB6         1  \n",
       "3      0x486F65135155CF15856A9AB68D2A559D         1  \n",
       "4      0x8D9B6D4F15F3ABDCA36A0E55FC141E1B         1  \n",
       "...                                   ...       ...  \n",
       "11619  0xBCB86FAE353770C036BDE208D5F48B69         1  \n",
       "11620  0x2A498FD1E7D7391C5D0B8527EF7BE55B         1  \n",
       "11621  0x5174E0425DB7E4922B2BF88051B2C653         1  \n",
       "11622  0x60ED78B8304296D01A94C4E947EEA2AD         1  \n",
       "11623  0x6ABDDF84A0AFC6877DAAFF7E4A4AF85F         1  \n",
       "\n",
       "[11624 rows x 40 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "11619    False\n",
       "11620    False\n",
       "11621    False\n",
       "11622    False\n",
       "11623    False\n",
       "Name: StateName, Length: 11624, dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads0['StateName'] == \"Wisconsin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9428</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>117</td>\n",
       "      <td>Port Washington #1</td>\n",
       "      <td>521117</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11053</td>\n",
       "      <td>1</td>\n",
       "      <td>0xAC063A7AFE8B135AC23ADD451A06A71E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9429</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>118</td>\n",
       "      <td>Oak Creek #1</td>\n",
       "      <td>521118</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11054</td>\n",
       "      <td>1</td>\n",
       "      <td>0xEB8BF986B7DF680841C7F62D662840DB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9432</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>127</td>\n",
       "      <td>Port Washington #2</td>\n",
       "      <td>521127</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11057</td>\n",
       "      <td>1</td>\n",
       "      <td>0x0ADB5861D864A6D3CF9D86E3CBF5E2EA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9433</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>128</td>\n",
       "      <td>Oak Creek #2</td>\n",
       "      <td>521128</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11058</td>\n",
       "      <td>1</td>\n",
       "      <td>0x59E17F2C453768E91FFC76A75E2FED8E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9435</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>137</td>\n",
       "      <td>Port Washington #3</td>\n",
       "      <td>521137</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11060</td>\n",
       "      <td>1</td>\n",
       "      <td>0x1FF49127A6342F6A97162FE4699826AE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>5082</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>302</td>\n",
       "      <td>Fitchburg #2</td>\n",
       "      <td>520302</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 18:45:00.450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 19:00:09.220</td>\n",
       "      <td>36036</td>\n",
       "      <td>1</td>\n",
       "      <td>0x43751F2C67170C9959832FBD2E449F00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>5083</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>311</td>\n",
       "      <td>Sycamore #1</td>\n",
       "      <td>520311</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 19:30:00.483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 20:00:04.643</td>\n",
       "      <td>36037</td>\n",
       "      <td>1</td>\n",
       "      <td>0xFE77204045354BC6505076B51F6DA00B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>5084</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>312</td>\n",
       "      <td>Sycamore #2</td>\n",
       "      <td>520312</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 19:20:00.893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 20:00:04.643</td>\n",
       "      <td>36038</td>\n",
       "      <td>1</td>\n",
       "      <td>0x53B0C590CDB68E7F5345B3F263690596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>5088</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>333</td>\n",
       "      <td>West Marinette</td>\n",
       "      <td>520333</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 20:10:00.487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 21:00:11.157</td>\n",
       "      <td>36041</td>\n",
       "      <td>1</td>\n",
       "      <td>0x638071A3508EE8EEFF24F603D635D303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>5085</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>321</td>\n",
       "      <td>Nine Springs</td>\n",
       "      <td>520321</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-08 14:50:00.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-08 15:00:06.520</td>\n",
       "      <td>36044</td>\n",
       "      <td>1</td>\n",
       "      <td>0xD7F7DF04DE02D8B01B0861D41F98B99C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UnitID UtilityCode                   UtilityName  UnitCode  \\\n",
       "10       9428         521  Wisconsin Electric Power Co.       117   \n",
       "11       9429         521  Wisconsin Electric Power Co.       118   \n",
       "13       9432         521  Wisconsin Electric Power Co.       127   \n",
       "14       9433         521  Wisconsin Electric Power Co.       128   \n",
       "16       9435         521  Wisconsin Electric Power Co.       137   \n",
       "...       ...         ...                           ...       ...   \n",
       "11381    5082         520  Madison Gas and Electric Co.       302   \n",
       "11382    5083         520  Madison Gas and Electric Co.       311   \n",
       "11383    5084         520  Madison Gas and Electric Co.       312   \n",
       "11384    5088         520  Madison Gas and Electric Co.       333   \n",
       "11385    5085         520  Madison Gas and Electric Co.       321   \n",
       "\n",
       "                 UnitName UtilityUnitCode  RatingMW  RatingMW_grp  \\\n",
       "10     Port Washington #1          521117      80.0           1.0   \n",
       "11           Oak Creek #1          521118     120.0           2.0   \n",
       "13     Port Washington #2          521127      80.0           1.0   \n",
       "14           Oak Creek #2          521128     120.0           2.0   \n",
       "16     Port Washington #3          521137      80.0           1.0   \n",
       "...                   ...             ...       ...           ...   \n",
       "11381        Fitchburg #2          520302      30.0           1.0   \n",
       "11382         Sycamore #1          520311      21.0           1.0   \n",
       "11383         Sycamore #2          520312      23.0           1.0   \n",
       "11384      West Marinette          520333     106.0           2.0   \n",
       "11385        Nine Springs          520321      19.0           1.0   \n",
       "\n",
       "       UnitTypeCode                                 UnitTypeCodeDesc  ...  \\\n",
       "10              100                                     Fossil-Steam  ...   \n",
       "11              100                                     Fossil-Steam  ...   \n",
       "13              100                                     Fossil-Steam  ...   \n",
       "14              100                                     Fossil-Steam  ...   \n",
       "16              100                                     Fossil-Steam  ...   \n",
       "...             ...                                              ...  ...   \n",
       "11381           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11382           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11383           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11384           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11385           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "\n",
       "                           NERCID_AliasID RegionCode  SubRegionName  \\\n",
       "10     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "11     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "13     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "14     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "16     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "...                                   ...        ...            ...   \n",
       "11381  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11382  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11383  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11384  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11385  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "\n",
       "                  ExtractionDT DeletionDT          NERC_DataPullDT  ID_SK Rnk  \\\n",
       "10     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11053   1   \n",
       "11     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11054   1   \n",
       "13     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11057   1   \n",
       "14     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11058   1   \n",
       "16     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11060   1   \n",
       "...                        ...        ...                      ...    ...  ..   \n",
       "11381  2024-05-07 18:45:00.450        NaN  2024-05-07 19:00:09.220  36036   1   \n",
       "11382  2024-05-07 19:30:00.483        NaN  2024-05-07 20:00:04.643  36037   1   \n",
       "11383  2024-05-07 19:20:00.893        NaN  2024-05-07 20:00:04.643  36038   1   \n",
       "11384  2024-05-07 20:10:00.487        NaN  2024-05-07 21:00:11.157  36041   1   \n",
       "11385  2024-05-08 14:50:00.323        NaN  2024-05-08 15:00:06.520  36044   1   \n",
       "\n",
       "                                  AliasID IsCurrent  \n",
       "10     0xAC063A7AFE8B135AC23ADD451A06A71E         1  \n",
       "11     0xEB8BF986B7DF680841C7F62D662840DB         1  \n",
       "13     0x0ADB5861D864A6D3CF9D86E3CBF5E2EA         1  \n",
       "14     0x59E17F2C453768E91FFC76A75E2FED8E         1  \n",
       "16     0x1FF49127A6342F6A97162FE4699826AE         1  \n",
       "...                                   ...       ...  \n",
       "11381  0x43751F2C67170C9959832FBD2E449F00         1  \n",
       "11382  0xFE77204045354BC6505076B51F6DA00B         1  \n",
       "11383  0x53B0C590CDB68E7F5345B3F263690596         1  \n",
       "11384  0x638071A3508EE8EEFF24F603D635D303         1  \n",
       "11385  0xD7F7DF04DE02D8B01B0861D41F98B99C         1  \n",
       "\n",
       "[228 rows x 40 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads0[dfGads0['StateName'] == \"Wisconsin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>4508</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>125</td>\n",
       "      <td>EAGLE Valley #1</td>\n",
       "      <td>413125</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13639</td>\n",
       "      <td>1</td>\n",
       "      <td>0x1C255D6419A52890CCAE63904564E991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>4509</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>126</td>\n",
       "      <td>EAGLE Valley #2</td>\n",
       "      <td>413126</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13640</td>\n",
       "      <td>1</td>\n",
       "      <td>0xE917D86162CA232656CB3B54A30DCD7B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>4510</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>127</td>\n",
       "      <td>EAGLE Valley #3</td>\n",
       "      <td>413127</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13641</td>\n",
       "      <td>1</td>\n",
       "      <td>0x5271044ACCEA0A0F2CBC9B39FE58B1C7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>4511</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>128</td>\n",
       "      <td>EAGLE Valley #4</td>\n",
       "      <td>413128</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13642</td>\n",
       "      <td>1</td>\n",
       "      <td>0x73B33B1A61D17611441B231AF16C092E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>4512</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>129</td>\n",
       "      <td>EAGLE Valley #5</td>\n",
       "      <td>413129</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13643</td>\n",
       "      <td>1</td>\n",
       "      <td>0xA5CEA9DBACC29DF547C67BB6EBA2A0ED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>2576</td>\n",
       "      <td>430</td>\n",
       "      <td>Cinergy</td>\n",
       "      <td>143</td>\n",
       "      <td>GIBSON #3</td>\n",
       "      <td>430143</td>\n",
       "      <td>618.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x7E2A1071640F863D8C2F1D5FE99CA3AE</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - MISO</td>\n",
       "      <td>2024-05-01 18:35:00.503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-01 19:00:06.147</td>\n",
       "      <td>35904</td>\n",
       "      <td>1</td>\n",
       "      <td>0xDF015FBF99DFCD9D775CE3C7CAE33B9B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>2577</td>\n",
       "      <td>430</td>\n",
       "      <td>Cinergy</td>\n",
       "      <td>144</td>\n",
       "      <td>GIBSON #4</td>\n",
       "      <td>430144</td>\n",
       "      <td>618.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x7E2A1071640F863D8C2F1D5FE99CA3AE</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - MISO</td>\n",
       "      <td>2024-05-01 18:35:00.503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-01 19:00:06.147</td>\n",
       "      <td>35905</td>\n",
       "      <td>1</td>\n",
       "      <td>0x8F07B6470DCB795D657252BE3CAD0758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11342</th>\n",
       "      <td>12352</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>348</td>\n",
       "      <td>Eagle Valley GT1</td>\n",
       "      <td>413348</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851</td>\n",
       "      <td>CC GT units\\t</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - MISO</td>\n",
       "      <td>2024-05-03 14:40:00.350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-03 15:00:12.127</td>\n",
       "      <td>35975</td>\n",
       "      <td>1</td>\n",
       "      <td>0xA5B1273E1394170B7F45FECFF5F95AAC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11343</th>\n",
       "      <td>12353</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>349</td>\n",
       "      <td>Eagle Valley GT2</td>\n",
       "      <td>413349</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851</td>\n",
       "      <td>CC GT units\\t</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - MISO</td>\n",
       "      <td>2024-05-03 14:45:00.510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-03 15:00:12.127</td>\n",
       "      <td>35976</td>\n",
       "      <td>1</td>\n",
       "      <td>0x6F0B4E33E90D65A8A29F0FF016548E97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11344</th>\n",
       "      <td>12354</td>\n",
       "      <td>413</td>\n",
       "      <td>Indianapolis Power &amp; Light Company</td>\n",
       "      <td>138</td>\n",
       "      <td>Eagle Valley STG1</td>\n",
       "      <td>413138</td>\n",
       "      <td>265.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>852</td>\n",
       "      <td>CC steam units</td>\n",
       "      <td>...</td>\n",
       "      <td>0x1521DD6F9E7C099C891D31F85A3D1153</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC - MISO</td>\n",
       "      <td>2024-05-03 14:40:00.350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-03 15:00:12.127</td>\n",
       "      <td>35977</td>\n",
       "      <td>1</td>\n",
       "      <td>0xFDDAEF692883DF79344A1CBE0C45DF4D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UnitID UtilityCode                         UtilityName  UnitCode  \\\n",
       "570      4508         413  Indianapolis Power & Light Company       125   \n",
       "571      4509         413  Indianapolis Power & Light Company       126   \n",
       "572      4510         413  Indianapolis Power & Light Company       127   \n",
       "573      4511         413  Indianapolis Power & Light Company       128   \n",
       "574      4512         413  Indianapolis Power & Light Company       129   \n",
       "...       ...         ...                                 ...       ...   \n",
       "11275    2576         430                             Cinergy       143   \n",
       "11276    2577         430                             Cinergy       144   \n",
       "11342   12352         413  Indianapolis Power & Light Company       348   \n",
       "11343   12353         413  Indianapolis Power & Light Company       349   \n",
       "11344   12354         413  Indianapolis Power & Light Company       138   \n",
       "\n",
       "                UnitName UtilityUnitCode  RatingMW  RatingMW_grp  \\\n",
       "570      EAGLE Valley #1          413125      46.0           1.0   \n",
       "571      EAGLE Valley #2          413126      46.0           1.0   \n",
       "572      EAGLE Valley #3          413127      48.0           1.0   \n",
       "573      EAGLE Valley #4          413128      69.0           1.0   \n",
       "574      EAGLE Valley #5          413129      69.0           1.0   \n",
       "...                  ...             ...       ...           ...   \n",
       "11275          GIBSON #3          430143     618.0           3.0   \n",
       "11276          GIBSON #4          430144     618.0           3.0   \n",
       "11342   Eagle Valley GT1          413348     230.0           3.0   \n",
       "11343   Eagle Valley GT2          413349     230.0           3.0   \n",
       "11344  Eagle Valley STG1          413138     265.0           3.0   \n",
       "\n",
       "       UnitTypeCode UnitTypeCodeDesc  ...                      NERCID_AliasID  \\\n",
       "570             100     Fossil-Steam  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "571             100     Fossil-Steam  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "572             100     Fossil-Steam  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "573             100     Fossil-Steam  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "574             100     Fossil-Steam  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "...             ...              ...  ...                                 ...   \n",
       "11275           100     Fossil-Steam  ...  0x7E2A1071640F863D8C2F1D5FE99CA3AE   \n",
       "11276           100     Fossil-Steam  ...  0x7E2A1071640F863D8C2F1D5FE99CA3AE   \n",
       "11342           851    CC GT units\\t  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "11343           851    CC GT units\\t  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "11344           852   CC steam units  ...  0x1521DD6F9E7C099C891D31F85A3D1153   \n",
       "\n",
       "      RegionCode  SubRegionName             ExtractionDT DeletionDT  \\\n",
       "570          RFC            RFC  2018-05-17 19:05:01.080        NaN   \n",
       "571          RFC            RFC  2018-05-17 19:05:01.080        NaN   \n",
       "572          RFC            RFC  2018-05-17 19:05:01.080        NaN   \n",
       "573          RFC            RFC  2018-05-17 19:05:01.080        NaN   \n",
       "574          RFC            RFC  2018-05-17 19:05:01.080        NaN   \n",
       "...          ...            ...                      ...        ...   \n",
       "11275        RFC     RFC - MISO  2024-05-01 18:35:00.503        NaN   \n",
       "11276        RFC     RFC - MISO  2024-05-01 18:35:00.503        NaN   \n",
       "11342        RFC     RFC - MISO  2024-05-03 14:40:00.350        NaN   \n",
       "11343        RFC     RFC - MISO  2024-05-03 14:45:00.510        NaN   \n",
       "11344        RFC     RFC - MISO  2024-05-03 14:40:00.350        NaN   \n",
       "\n",
       "               NERC_DataPullDT  ID_SK Rnk                             AliasID  \\\n",
       "570    2018-05-17 20:00:05.287  13639   1  0x1C255D6419A52890CCAE63904564E991   \n",
       "571    2018-05-17 20:00:05.287  13640   1  0xE917D86162CA232656CB3B54A30DCD7B   \n",
       "572    2018-05-17 20:00:05.287  13641   1  0x5271044ACCEA0A0F2CBC9B39FE58B1C7   \n",
       "573    2018-05-17 20:00:05.287  13642   1  0x73B33B1A61D17611441B231AF16C092E   \n",
       "574    2018-05-17 20:00:05.287  13643   1  0xA5CEA9DBACC29DF547C67BB6EBA2A0ED   \n",
       "...                        ...    ...  ..                                 ...   \n",
       "11275  2024-05-01 19:00:06.147  35904   1  0xDF015FBF99DFCD9D775CE3C7CAE33B9B   \n",
       "11276  2024-05-01 19:00:06.147  35905   1  0x8F07B6470DCB795D657252BE3CAD0758   \n",
       "11342  2024-05-03 15:00:12.127  35975   1  0xA5B1273E1394170B7F45FECFF5F95AAC   \n",
       "11343  2024-05-03 15:00:12.127  35976   1  0x6F0B4E33E90D65A8A29F0FF016548E97   \n",
       "11344  2024-05-03 15:00:12.127  35977   1  0xFDDAEF692883DF79344A1CBE0C45DF4D   \n",
       "\n",
       "      IsCurrent  \n",
       "570           1  \n",
       "571           1  \n",
       "572           1  \n",
       "573           1  \n",
       "574           1  \n",
       "...         ...  \n",
       "11275         1  \n",
       "11276         1  \n",
       "11342         1  \n",
       "11343         1  \n",
       "11344         1  \n",
       "\n",
       "[254 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads0[dfGads0['StateName'] == \"Indiana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>12274</td>\n",
       "      <td>545</td>\n",
       "      <td>Prairie Power, Inc</td>\n",
       "      <td>306</td>\n",
       "      <td>Alsey Unit 6</td>\n",
       "      <td>545306</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x77135E77DE03E2F16CB940C3B3074AB9</td>\n",
       "      <td>SERC</td>\n",
       "      <td>Gateway</td>\n",
       "      <td>2018-01-31 14:15:00.810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-31 15:00:01.470</td>\n",
       "      <td>12055</td>\n",
       "      <td>1</td>\n",
       "      <td>0x3328FC6DA5E4C36D6A1666B6E44A7385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2829</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>101</td>\n",
       "      <td>COLLINS #1</td>\n",
       "      <td>510101</td>\n",
       "      <td>554.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13084</td>\n",
       "      <td>1</td>\n",
       "      <td>0x3E22C8F14AC30EF4E3F90858F57917A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2830</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>102</td>\n",
       "      <td>COLLINS #2</td>\n",
       "      <td>510102</td>\n",
       "      <td>554.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13085</td>\n",
       "      <td>1</td>\n",
       "      <td>0xA742DD440617C11B42B9E193110C83F4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2831</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>103</td>\n",
       "      <td>COLLINS #3</td>\n",
       "      <td>510103</td>\n",
       "      <td>530.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13086</td>\n",
       "      <td>1</td>\n",
       "      <td>0x92861ABF4F8815A455AA5518708660CC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2832</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>104</td>\n",
       "      <td>COLLINS #4</td>\n",
       "      <td>510104</td>\n",
       "      <td>530.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13087</td>\n",
       "      <td>1</td>\n",
       "      <td>0x38B27BFE548DF9F526A05221EEDDCC94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11213</th>\n",
       "      <td>2361</td>\n",
       "      <td>528</td>\n",
       "      <td>Kincaid Generation, LLC</td>\n",
       "      <td>113</td>\n",
       "      <td>KINCAID #2</td>\n",
       "      <td>528113</td>\n",
       "      <td>580.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x83C96E5B8B7FC1ADED8C380AEEA60908</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-04-29 18:30:00.597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-29 19:00:12.270</td>\n",
       "      <td>35785</td>\n",
       "      <td>1</td>\n",
       "      <td>0x588F4A0760D365899662B1D5D00A8320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>3957</td>\n",
       "      <td>526</td>\n",
       "      <td>GenOn Energy (RELIANT ENERGY)</td>\n",
       "      <td>315</td>\n",
       "      <td>SHELBY CT E</td>\n",
       "      <td>526315</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x4D7467E7A84C0A46AD8D18586B45E93B</td>\n",
       "      <td>SERC</td>\n",
       "      <td>SERC</td>\n",
       "      <td>2024-04-29 23:50:00.453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 00:00:07.970</td>\n",
       "      <td>35810</td>\n",
       "      <td>1</td>\n",
       "      <td>0x9CE4931D42518BB2822B58C06E56A3AF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239</th>\n",
       "      <td>3958</td>\n",
       "      <td>526</td>\n",
       "      <td>GenOn Energy (RELIANT ENERGY)</td>\n",
       "      <td>316</td>\n",
       "      <td>SHELBY CT F</td>\n",
       "      <td>526316</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x4D7467E7A84C0A46AD8D18586B45E93B</td>\n",
       "      <td>SERC</td>\n",
       "      <td>SERC</td>\n",
       "      <td>2024-04-29 23:55:01.163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 00:00:07.970</td>\n",
       "      <td>35811</td>\n",
       "      <td>1</td>\n",
       "      <td>0x5D8AE84A1767961050DCDB622F4511FB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>3959</td>\n",
       "      <td>526</td>\n",
       "      <td>GenOn Energy (RELIANT ENERGY)</td>\n",
       "      <td>317</td>\n",
       "      <td>SHELBY CT G</td>\n",
       "      <td>526317</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x4D7467E7A84C0A46AD8D18586B45E93B</td>\n",
       "      <td>SERC</td>\n",
       "      <td>SERC</td>\n",
       "      <td>2024-04-29 23:55:01.163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 00:00:07.970</td>\n",
       "      <td>35812</td>\n",
       "      <td>1</td>\n",
       "      <td>0xC1C419578B15102BB692B6FEA54C4588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>3960</td>\n",
       "      <td>526</td>\n",
       "      <td>GenOn Energy (RELIANT ENERGY)</td>\n",
       "      <td>318</td>\n",
       "      <td>SHELBY CT H</td>\n",
       "      <td>526318</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x4D7467E7A84C0A46AD8D18586B45E93B</td>\n",
       "      <td>SERC</td>\n",
       "      <td>SERC</td>\n",
       "      <td>2024-04-30 00:00:00.460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 00:00:07.970</td>\n",
       "      <td>35813</td>\n",
       "      <td>1</td>\n",
       "      <td>0x2B1EAB65679A43B302C458155D1005E7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UnitID UtilityCode                    UtilityName  UnitCode  \\\n",
       "101     12274         545             Prairie Power, Inc       306   \n",
       "294      2829         510          Edison Mission Energy       101   \n",
       "295      2830         510          Edison Mission Energy       102   \n",
       "296      2831         510          Edison Mission Energy       103   \n",
       "297      2832         510          Edison Mission Energy       104   \n",
       "...       ...         ...                            ...       ...   \n",
       "11213    2361         528        Kincaid Generation, LLC       113   \n",
       "11238    3957         526  GenOn Energy (RELIANT ENERGY)       315   \n",
       "11239    3958         526  GenOn Energy (RELIANT ENERGY)       316   \n",
       "11240    3959         526  GenOn Energy (RELIANT ENERGY)       317   \n",
       "11241    3960         526  GenOn Energy (RELIANT ENERGY)       318   \n",
       "\n",
       "           UnitName UtilityUnitCode  RatingMW  RatingMW_grp  UnitTypeCode  \\\n",
       "101    Alsey Unit 6          545306      45.0           1.0           300   \n",
       "294      COLLINS #1          510101     554.0           3.0           100   \n",
       "295      COLLINS #2          510102     554.0           3.0           100   \n",
       "296      COLLINS #3          510103     530.0           3.0           100   \n",
       "297      COLLINS #4          510104     530.0           3.0           100   \n",
       "...             ...             ...       ...           ...           ...   \n",
       "11213    KINCAID #2          528113     580.0           3.0           100   \n",
       "11238   SHELBY CT E          526315      44.0           1.0           300   \n",
       "11239   SHELBY CT F          526316      44.0           1.0           300   \n",
       "11240   SHELBY CT G          526317      44.0           1.0           300   \n",
       "11241   SHELBY CT H          526318      44.0           1.0           300   \n",
       "\n",
       "                                      UnitTypeCodeDesc  ...  \\\n",
       "101    Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "294                                       Fossil-Steam  ...   \n",
       "295                                       Fossil-Steam  ...   \n",
       "296                                       Fossil-Steam  ...   \n",
       "297                                       Fossil-Steam  ...   \n",
       "...                                                ...  ...   \n",
       "11213                                     Fossil-Steam  ...   \n",
       "11238  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11239  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11240  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11241  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "\n",
       "                           NERCID_AliasID RegionCode  SubRegionName  \\\n",
       "101    0x77135E77DE03E2F16CB940C3B3074AB9       SERC        Gateway   \n",
       "294    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "295    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "296    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "297    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "...                                   ...        ...            ...   \n",
       "11213  0x83C96E5B8B7FC1ADED8C380AEEA60908        MRO            MRO   \n",
       "11238  0x4D7467E7A84C0A46AD8D18586B45E93B       SERC           SERC   \n",
       "11239  0x4D7467E7A84C0A46AD8D18586B45E93B       SERC           SERC   \n",
       "11240  0x4D7467E7A84C0A46AD8D18586B45E93B       SERC           SERC   \n",
       "11241  0x4D7467E7A84C0A46AD8D18586B45E93B       SERC           SERC   \n",
       "\n",
       "                  ExtractionDT DeletionDT          NERC_DataPullDT  ID_SK Rnk  \\\n",
       "101    2018-01-31 14:15:00.810        NaN  2018-01-31 15:00:01.470  12055   1   \n",
       "294    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13084   1   \n",
       "295    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13085   1   \n",
       "296    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13086   1   \n",
       "297    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13087   1   \n",
       "...                        ...        ...                      ...    ...  ..   \n",
       "11213  2024-04-29 18:30:00.597        NaN  2024-04-29 19:00:12.270  35785   1   \n",
       "11238  2024-04-29 23:50:00.453        NaN  2024-04-30 00:00:07.970  35810   1   \n",
       "11239  2024-04-29 23:55:01.163        NaN  2024-04-30 00:00:07.970  35811   1   \n",
       "11240  2024-04-29 23:55:01.163        NaN  2024-04-30 00:00:07.970  35812   1   \n",
       "11241  2024-04-30 00:00:00.460        NaN  2024-04-30 00:00:07.970  35813   1   \n",
       "\n",
       "                                  AliasID IsCurrent  \n",
       "101    0x3328FC6DA5E4C36D6A1666B6E44A7385         1  \n",
       "294    0x3E22C8F14AC30EF4E3F90858F57917A1         1  \n",
       "295    0xA742DD440617C11B42B9E193110C83F4         1  \n",
       "296    0x92861ABF4F8815A455AA5518708660CC         1  \n",
       "297    0x38B27BFE548DF9F526A05221EEDDCC94         1  \n",
       "...                                   ...       ...  \n",
       "11213  0x588F4A0760D365899662B1D5D00A8320         1  \n",
       "11238  0x9CE4931D42518BB2822B58C06E56A3AF         1  \n",
       "11239  0x5D8AE84A1767961050DCDB622F4511FB         1  \n",
       "11240  0xC1C419578B15102BB692B6FEA54C4588         1  \n",
       "11241  0x2B1EAB65679A43B302C458155D1005E7         1  \n",
       "\n",
       "[336 rows x 40 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads0[dfGads0['StateName'] == \"Illinois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a017fc14-9ea4-497d-ac0d-230ea3737ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_states(dfGads, states_to_keep=[\"Illinois\", \"Indiana\", \"Wisconsin\"]):\n",
    "    # Define the list of state names to filter\n",
    "    # states_to_keep = [\"IL\", \"IN\", \"WI\"]\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    dfFiltered = dfGads[dfGads[\"StateName\"].isin(states_to_keep)]\n",
    "\n",
    "    return dfFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9428</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>117</td>\n",
       "      <td>Port Washington #1</td>\n",
       "      <td>521117</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11053</td>\n",
       "      <td>1</td>\n",
       "      <td>0xAC063A7AFE8B135AC23ADD451A06A71E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9429</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>118</td>\n",
       "      <td>Oak Creek #1</td>\n",
       "      <td>521118</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11054</td>\n",
       "      <td>1</td>\n",
       "      <td>0xEB8BF986B7DF680841C7F62D662840DB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9432</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>127</td>\n",
       "      <td>Port Washington #2</td>\n",
       "      <td>521127</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11057</td>\n",
       "      <td>1</td>\n",
       "      <td>0x0ADB5861D864A6D3CF9D86E3CBF5E2EA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9433</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>128</td>\n",
       "      <td>Oak Creek #2</td>\n",
       "      <td>521128</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11058</td>\n",
       "      <td>1</td>\n",
       "      <td>0x59E17F2C453768E91FFC76A75E2FED8E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9435</td>\n",
       "      <td>521</td>\n",
       "      <td>Wisconsin Electric Power Co.</td>\n",
       "      <td>137</td>\n",
       "      <td>Port Washington #3</td>\n",
       "      <td>521137</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x039386647F44BC49D31ACC98C07983BB</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2017-03-23 18:45:00.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 19:00:00.843</td>\n",
       "      <td>11060</td>\n",
       "      <td>1</td>\n",
       "      <td>0x1FF49127A6342F6A97162FE4699826AE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>5082</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>302</td>\n",
       "      <td>Fitchburg #2</td>\n",
       "      <td>520302</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 18:45:00.450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 19:00:09.220</td>\n",
       "      <td>36036</td>\n",
       "      <td>1</td>\n",
       "      <td>0x43751F2C67170C9959832FBD2E449F00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>5083</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>311</td>\n",
       "      <td>Sycamore #1</td>\n",
       "      <td>520311</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 19:30:00.483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 20:00:04.643</td>\n",
       "      <td>36037</td>\n",
       "      <td>1</td>\n",
       "      <td>0xFE77204045354BC6505076B51F6DA00B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>5084</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>312</td>\n",
       "      <td>Sycamore #2</td>\n",
       "      <td>520312</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 19:20:00.893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 20:00:04.643</td>\n",
       "      <td>36038</td>\n",
       "      <td>1</td>\n",
       "      <td>0x53B0C590CDB68E7F5345B3F263690596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>5088</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>333</td>\n",
       "      <td>West Marinette</td>\n",
       "      <td>520333</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-07 20:10:00.487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-07 21:00:11.157</td>\n",
       "      <td>36041</td>\n",
       "      <td>1</td>\n",
       "      <td>0x638071A3508EE8EEFF24F603D635D303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>5085</td>\n",
       "      <td>520</td>\n",
       "      <td>Madison Gas and Electric Co.</td>\n",
       "      <td>321</td>\n",
       "      <td>Nine Springs</td>\n",
       "      <td>520321</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>...</td>\n",
       "      <td>0x5B627CCFD6ECD814C078E6F95CF56156</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-08 14:50:00.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-08 15:00:06.520</td>\n",
       "      <td>36044</td>\n",
       "      <td>1</td>\n",
       "      <td>0xD7F7DF04DE02D8B01B0861D41F98B99C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UnitID UtilityCode                   UtilityName  UnitCode  \\\n",
       "10       9428         521  Wisconsin Electric Power Co.       117   \n",
       "11       9429         521  Wisconsin Electric Power Co.       118   \n",
       "13       9432         521  Wisconsin Electric Power Co.       127   \n",
       "14       9433         521  Wisconsin Electric Power Co.       128   \n",
       "16       9435         521  Wisconsin Electric Power Co.       137   \n",
       "...       ...         ...                           ...       ...   \n",
       "11381    5082         520  Madison Gas and Electric Co.       302   \n",
       "11382    5083         520  Madison Gas and Electric Co.       311   \n",
       "11383    5084         520  Madison Gas and Electric Co.       312   \n",
       "11384    5088         520  Madison Gas and Electric Co.       333   \n",
       "11385    5085         520  Madison Gas and Electric Co.       321   \n",
       "\n",
       "                 UnitName UtilityUnitCode  RatingMW  RatingMW_grp  \\\n",
       "10     Port Washington #1          521117      80.0           1.0   \n",
       "11           Oak Creek #1          521118     120.0           2.0   \n",
       "13     Port Washington #2          521127      80.0           1.0   \n",
       "14           Oak Creek #2          521128     120.0           2.0   \n",
       "16     Port Washington #3          521137      80.0           1.0   \n",
       "...                   ...             ...       ...           ...   \n",
       "11381        Fitchburg #2          520302      30.0           1.0   \n",
       "11382         Sycamore #1          520311      21.0           1.0   \n",
       "11383         Sycamore #2          520312      23.0           1.0   \n",
       "11384      West Marinette          520333     106.0           2.0   \n",
       "11385        Nine Springs          520321      19.0           1.0   \n",
       "\n",
       "       UnitTypeCode                                 UnitTypeCodeDesc  ...  \\\n",
       "10              100                                     Fossil-Steam  ...   \n",
       "11              100                                     Fossil-Steam  ...   \n",
       "13              100                                     Fossil-Steam  ...   \n",
       "14              100                                     Fossil-Steam  ...   \n",
       "16              100                                     Fossil-Steam  ...   \n",
       "...             ...                                              ...  ...   \n",
       "11381           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11382           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11383           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11384           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "11385           300  Gas Turbine/Jet Engine (Simple Cycle Operation)  ...   \n",
       "\n",
       "                           NERCID_AliasID RegionCode  SubRegionName  \\\n",
       "10     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "11     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "13     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "14     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "16     0x039386647F44BC49D31ACC98C07983BB        RFC            RFC   \n",
       "...                                   ...        ...            ...   \n",
       "11381  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11382  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11383  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11384  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "11385  0x5B627CCFD6ECD814C078E6F95CF56156        MRO            MRO   \n",
       "\n",
       "                  ExtractionDT DeletionDT          NERC_DataPullDT  ID_SK Rnk  \\\n",
       "10     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11053   1   \n",
       "11     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11054   1   \n",
       "13     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11057   1   \n",
       "14     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11058   1   \n",
       "16     2017-03-23 18:45:00.360        NaN  2017-03-23 19:00:00.843  11060   1   \n",
       "...                        ...        ...                      ...    ...  ..   \n",
       "11381  2024-05-07 18:45:00.450        NaN  2024-05-07 19:00:09.220  36036   1   \n",
       "11382  2024-05-07 19:30:00.483        NaN  2024-05-07 20:00:04.643  36037   1   \n",
       "11383  2024-05-07 19:20:00.893        NaN  2024-05-07 20:00:04.643  36038   1   \n",
       "11384  2024-05-07 20:10:00.487        NaN  2024-05-07 21:00:11.157  36041   1   \n",
       "11385  2024-05-08 14:50:00.323        NaN  2024-05-08 15:00:06.520  36044   1   \n",
       "\n",
       "                                  AliasID IsCurrent  \n",
       "10     0xAC063A7AFE8B135AC23ADD451A06A71E         1  \n",
       "11     0xEB8BF986B7DF680841C7F62D662840DB         1  \n",
       "13     0x0ADB5861D864A6D3CF9D86E3CBF5E2EA         1  \n",
       "14     0x59E17F2C453768E91FFC76A75E2FED8E         1  \n",
       "16     0x1FF49127A6342F6A97162FE4699826AE         1  \n",
       "...                                   ...       ...  \n",
       "11381  0x43751F2C67170C9959832FBD2E449F00         1  \n",
       "11382  0xFE77204045354BC6505076B51F6DA00B         1  \n",
       "11383  0x53B0C590CDB68E7F5345B3F263690596         1  \n",
       "11384  0x638071A3508EE8EEFF24F603D635D303         1  \n",
       "11385  0xD7F7DF04DE02D8B01B0861D41F98B99C         1  \n",
       "\n",
       "[818 rows x 40 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_states(dfGads0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212a93cc-b1c8-44ce-b097-679fb892fb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db after filtering: 818, 40\n"
     ]
    }
   ],
   "source": [
    "dfGads = dfGads0.copy()\n",
    "# dfGads = dfGads[dfGads['CompanyName'].isin(companyNamesVelo2Gads)]\n",
    "# voltageClassesGads0 = set(dfGads['VoltageClassCodeName'])\n",
    "# print(voltageClassesGads0)\n",
    "# voltageClassesAllowedGads = voltageClassesGads0.copy()\n",
    "# voltageClassesAllowedGads.discard(\"0-99 kV\")\n",
    "\n",
    "# dfGads = dfGads[dfGads['VoltageClassCodeName'].isin(voltageClassesAllowedGads)]\n",
    "dfGads = filter_states(dfGads0)\n",
    "sizeGads = dfGads.shape\n",
    "print(f\"Size of GADS db after filtering: {sizeGads[0]}, {sizeGads[1]}\")\n",
    "\n",
    "# dfGadsSorted = sort_and_shift_columns(dfGads)\n",
    "\n",
    "# gadsSortedAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "# dfGadsSorted.to_excel(gadsSortedAddr, index=False)\n",
    "\n",
    "# # dfGadsLatest = filter_tlines_by_latest_reported_year(dfGadsSorted)\n",
    "# dfGadsLatest = get_latest_entries(dfGadsSorted)\n",
    "\n",
    "# sizeGadsLatest = dfGadsLatest.shape\n",
    "\n",
    "# print(f\"Size of GADS db after filtering for only latest reported year: {sizeGadsLatest[0]}, {sizeGadsLatest[1]}\")\n",
    "\n",
    "# gadsLatestAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "# dfGadsLatest.to_excel(gadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       4040\n",
       "11       4039\n",
       "13       4040\n",
       "14       4039\n",
       "16       4040\n",
       "         ... \n",
       "11381    3991\n",
       "11382    3993\n",
       "11383    3993\n",
       "11384    7799\n",
       "11385    9674\n",
       "Name: EIACode, Length: 818, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads['EIACode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23d17bac-3643-42ac-86fb-35dddf79b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_states(dfGads, states_to_keep=[\"Illinois\", \"Indiana\", \"Wisconsin\"]):\n",
    "    # Define the list of state names to filter\n",
    "    # states_to_keep = [\"IL\", \"IN\", \"WI\"]\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    dfFiltered = dfGads[dfGads[\"StateName\"].isin(states_to_keep)]\n",
    "\n",
    "    return dfFiltered\n",
    "\n",
    "def filter_by_eia_code(dfVelo, dfGads):\n",
    "    # Get the unique 'EIA ID' values from dfVelo\n",
    "    eia_ids = dfVelo[\"EIA ID\"].unique()\n",
    "\n",
    "    # Filter dfGads to include only rows where 'EIACode' is in the list of 'EIA ID' values\n",
    "    dfFiltered = dfGads[dfGads[\"EIACode\"].isin(eia_ids)]\n",
    "\n",
    "    return dfFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plant Name</th>\n",
       "      <th>Plant Operator Name</th>\n",
       "      <th>Operating Cap MW</th>\n",
       "      <th>Planned Cap MW</th>\n",
       "      <th>Retired Cap MW</th>\n",
       "      <th>Canceled Cap MW</th>\n",
       "      <th>Mothballed Cap MW</th>\n",
       "      <th>Description</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Proposed</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Source</th>\n",
       "      <th>EIA ID</th>\n",
       "      <th>Layer_ID</th>\n",
       "      <th>Rec_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9521 US 14 Solar 1 LLC</td>\n",
       "      <td>9521 US 14 Solar 1 LLC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 PL SOL PV(s)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>Mchenry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>Lat and Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>32460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lincoln Solar</td>\n",
       "      <td>Allco Finance Group Ltd</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 OP SOL PV(s)</td>\n",
       "      <td>Merrillville</td>\n",
       "      <td>IN</td>\n",
       "      <td>Lake</td>\n",
       "      <td>46410.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>FERC eLibrary</td>\n",
       "      <td>58496</td>\n",
       "      <td>69</td>\n",
       "      <td>11844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portage Solar</td>\n",
       "      <td>Allco Finance Group Ltd</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 OP SOL PV(s)</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>IN</td>\n",
       "      <td>Porter</td>\n",
       "      <td>46368.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>FERC eLibrary</td>\n",
       "      <td>60046</td>\n",
       "      <td>69</td>\n",
       "      <td>11824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argo Power Project</td>\n",
       "      <td>Alliant Energy Corp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>687.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 CN NG CC(s)</td>\n",
       "      <td>Bedford Park</td>\n",
       "      <td>IL</td>\n",
       "      <td>Cook</td>\n",
       "      <td>60501.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>Hitachi Energy</td>\n",
       "      <td>906</td>\n",
       "      <td>69</td>\n",
       "      <td>8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alsip Paper Condominium Associates</td>\n",
       "      <td>Alsip Paper Condominium Association</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 RE NG GT(s)</td>\n",
       "      <td>Alsip</td>\n",
       "      <td>IL</td>\n",
       "      <td>Cook</td>\n",
       "      <td>60658.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Hitachi Energy</td>\n",
       "      <td>10406</td>\n",
       "      <td>69</td>\n",
       "      <td>8234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Wolfcastle Project</td>\n",
       "      <td>Wolfcastle Solar LLC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 OP SOL PV(s)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>Dekalb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Latitude and Longitude</td>\n",
       "      <td>64736</td>\n",
       "      <td>69</td>\n",
       "      <td>28249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Woodlawn II Project</td>\n",
       "      <td>Woodlawn Solar II LLC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 OP SOL PV(s)</td>\n",
       "      <td>Crete</td>\n",
       "      <td>IL</td>\n",
       "      <td>Will</td>\n",
       "      <td>60417.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Latitude and Longitude</td>\n",
       "      <td>64733</td>\n",
       "      <td>69</td>\n",
       "      <td>28250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Woodlawn Project</td>\n",
       "      <td>Woodlawn Solar LLC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1 OP SOL PV(s)</td>\n",
       "      <td>Crete</td>\n",
       "      <td>IL</td>\n",
       "      <td>Will</td>\n",
       "      <td>60417.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Latitude and Longitude</td>\n",
       "      <td>64785</td>\n",
       "      <td>69</td>\n",
       "      <td>28251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Zion Municipal Landfill Solar</td>\n",
       "      <td>Zion (City of)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0</td>\n",
       "      <td>1 CN SOL PV(s)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>Lake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>Street Address</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>22809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>Zion Energy LLC</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3 OP NG GT(s), 2 CN NG GT(s)</td>\n",
       "      <td>Zion</td>\n",
       "      <td>IL</td>\n",
       "      <td>Lake</td>\n",
       "      <td>60099.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerial Imagery</td>\n",
       "      <td>55392</td>\n",
       "      <td>69</td>\n",
       "      <td>10811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Plant Name                  Plant Operator Name  \\\n",
       "0                9521 US 14 Solar 1 LLC               9521 US 14 Solar 1 LLC   \n",
       "1                         Lincoln Solar              Allco Finance Group Ltd   \n",
       "2                         Portage Solar              Allco Finance Group Ltd   \n",
       "3                    Argo Power Project                  Alliant Energy Corp   \n",
       "4    Alsip Paper Condominium Associates  Alsip Paper Condominium Association   \n",
       "..                                  ...                                  ...   \n",
       "286                  Wolfcastle Project                 Wolfcastle Solar LLC   \n",
       "287                 Woodlawn II Project                Woodlawn Solar II LLC   \n",
       "288                    Woodlawn Project                   Woodlawn Solar LLC   \n",
       "289       Zion Municipal Landfill Solar                       Zion (City of)   \n",
       "290                  Zion Energy Center                      Zion Energy LLC   \n",
       "\n",
       "     Operating Cap MW  Planned Cap MW  Retired Cap MW  Canceled Cap MW  \\\n",
       "0                 0.0             2.0             0.0             0.00   \n",
       "1                 1.5             0.0             0.0             0.00   \n",
       "2                 1.5             0.0             0.0             0.00   \n",
       "3                 0.0             0.0             0.0           687.00   \n",
       "4                 0.0             0.0             6.9             0.00   \n",
       "..                ...             ...             ...              ...   \n",
       "286               2.0             0.0             0.0             0.00   \n",
       "287               2.0             0.0             0.0             0.00   \n",
       "288               2.0             0.0             0.0             0.00   \n",
       "289               0.0             0.0             0.0             2.43   \n",
       "290             546.0             0.0             0.0           304.00   \n",
       "\n",
       "     Mothballed Cap MW                   Description          City State  \\\n",
       "0                    0                1 PL SOL PV(s)           NaN    IL   \n",
       "1                    0                1 OP SOL PV(s)  Merrillville    IN   \n",
       "2                    0                1 OP SOL PV(s)    Valparaiso    IN   \n",
       "3                    0                 1 CN NG CC(s)  Bedford Park    IL   \n",
       "4                    0                 1 RE NG GT(s)         Alsip    IL   \n",
       "..                 ...                           ...           ...   ...   \n",
       "286                  0                1 OP SOL PV(s)           NaN    IL   \n",
       "287                  0                1 OP SOL PV(s)         Crete    IL   \n",
       "288                  0                1 OP SOL PV(s)         Crete    IL   \n",
       "289                  0                1 CN SOL PV(s)           NaN    IL   \n",
       "290                  0  3 OP NG GT(s), 2 CN NG GT(s)          Zion    IL   \n",
       "\n",
       "      County  ZIP Code Proposed  Location Code                  Source EIA ID  \\\n",
       "0    Mchenry       NaN        T              2            Lat and Long    NaN   \n",
       "1       Lake   46410.0        F              3           FERC eLibrary  58496   \n",
       "2     Porter   46368.0        F              3           FERC eLibrary  60046   \n",
       "3       Cook   60501.0        T              3          Hitachi Energy    906   \n",
       "4       Cook   60658.0        F              3          Hitachi Energy  10406   \n",
       "..       ...       ...      ...            ...                     ...    ...   \n",
       "286   Dekalb       NaN        F              2  Latitude and Longitude  64736   \n",
       "287     Will   60417.0        F              2  Latitude and Longitude  64733   \n",
       "288     Will   60417.0        F              2  Latitude and Longitude  64785   \n",
       "289     Lake       NaN        T              2          Street Address    NaN   \n",
       "290     Lake   60099.0        F              1          Aerial Imagery  55392   \n",
       "\n",
       "     Layer_ID  Rec_ID  \n",
       "0          69   32460  \n",
       "1          69   11844  \n",
       "2          69   11824  \n",
       "3          69    8180  \n",
       "4          69    8234  \n",
       "..        ...     ...  \n",
       "286        69   28249  \n",
       "287        69   28250  \n",
       "288        69   28251  \n",
       "289        69   22809  \n",
       "290        69   10811  \n",
       "\n",
       "[291 rows x 18 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1      58496\n",
       "2      60046\n",
       "3        906\n",
       "4      10406\n",
       "       ...  \n",
       "286    64736\n",
       "287    64733\n",
       "288    64785\n",
       "289      NaN\n",
       "290    55392\n",
       "Name: EIA ID, Length: 291, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo['EIA ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       4040\n",
       "11       4039\n",
       "13       4040\n",
       "14       4039\n",
       "16       4040\n",
       "         ... \n",
       "11381    3991\n",
       "11382    3993\n",
       "11383    3993\n",
       "11384    7799\n",
       "11385    9674\n",
       "Name: EIACode, Length: 818, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGads['EIACode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGadsFiltered = filter_by_eia_code(dfVelo, dfGads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitID</th>\n",
       "      <th>UtilityCode</th>\n",
       "      <th>UtilityName</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>UtilityUnitCode</th>\n",
       "      <th>RatingMW</th>\n",
       "      <th>RatingMW_grp</th>\n",
       "      <th>UnitTypeCode</th>\n",
       "      <th>UnitTypeCodeDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>NERCID_AliasID</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>SubRegionName</th>\n",
       "      <th>ExtractionDT</th>\n",
       "      <th>DeletionDT</th>\n",
       "      <th>NERC_DataPullDT</th>\n",
       "      <th>ID_SK</th>\n",
       "      <th>Rnk</th>\n",
       "      <th>AliasID</th>\n",
       "      <th>IsCurrent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2829</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>101</td>\n",
       "      <td>COLLINS #1</td>\n",
       "      <td>510101</td>\n",
       "      <td>554.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13084</td>\n",
       "      <td>1</td>\n",
       "      <td>0x3E22C8F14AC30EF4E3F90858F57917A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2830</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>102</td>\n",
       "      <td>COLLINS #2</td>\n",
       "      <td>510102</td>\n",
       "      <td>554.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13085</td>\n",
       "      <td>1</td>\n",
       "      <td>0xA742DD440617C11B42B9E193110C83F4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2831</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>103</td>\n",
       "      <td>COLLINS #3</td>\n",
       "      <td>510103</td>\n",
       "      <td>530.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13086</td>\n",
       "      <td>1</td>\n",
       "      <td>0x92861ABF4F8815A455AA5518708660CC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2832</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>104</td>\n",
       "      <td>COLLINS #4</td>\n",
       "      <td>510104</td>\n",
       "      <td>530.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13087</td>\n",
       "      <td>1</td>\n",
       "      <td>0x38B27BFE548DF9F526A05221EEDDCC94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2833</td>\n",
       "      <td>510</td>\n",
       "      <td>Edison Mission Energy</td>\n",
       "      <td>105</td>\n",
       "      <td>COLLINS #5</td>\n",
       "      <td>510105</td>\n",
       "      <td>530.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x3EB7A81A4A916415991F1222F16BEB36</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2018-05-17 19:05:01.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-17 20:00:05.287</td>\n",
       "      <td>13088</td>\n",
       "      <td>1</td>\n",
       "      <td>0x0802695A0C9BFFE68BC4B9761EB43EA0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>3392</td>\n",
       "      <td>506</td>\n",
       "      <td>Exelon (ComEd)</td>\n",
       "      <td>125</td>\n",
       "      <td>RIDGELAND #1</td>\n",
       "      <td>506125</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x7A934D0BCD299CBB52A3966013A53769</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2023-07-25 20:20:00.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 21:00:08.007</td>\n",
       "      <td>33507</td>\n",
       "      <td>1</td>\n",
       "      <td>0xACD96BACE0F36E67E10D88053F324B9F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9898</th>\n",
       "      <td>3393</td>\n",
       "      <td>506</td>\n",
       "      <td>Exelon (ComEd)</td>\n",
       "      <td>126</td>\n",
       "      <td>RIDGELAND #2</td>\n",
       "      <td>506126</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x7A934D0BCD299CBB52A3966013A53769</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2023-07-25 20:20:00.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 21:00:08.007</td>\n",
       "      <td>33508</td>\n",
       "      <td>1</td>\n",
       "      <td>0x141AC8E2E957E7F4B6BE018EB00C70EE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>3394</td>\n",
       "      <td>506</td>\n",
       "      <td>Exelon (ComEd)</td>\n",
       "      <td>127</td>\n",
       "      <td>RIDGELAND #3</td>\n",
       "      <td>506127</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x7A934D0BCD299CBB52A3966013A53769</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2023-07-25 20:20:00.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 21:00:08.007</td>\n",
       "      <td>33509</td>\n",
       "      <td>1</td>\n",
       "      <td>0x83788DA62C59B57BD6DD616927661A63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>3395</td>\n",
       "      <td>506</td>\n",
       "      <td>Exelon (ComEd)</td>\n",
       "      <td>128</td>\n",
       "      <td>RIDGELAND #4</td>\n",
       "      <td>506128</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Fossil-Steam</td>\n",
       "      <td>...</td>\n",
       "      <td>0x7A934D0BCD299CBB52A3966013A53769</td>\n",
       "      <td>RFC</td>\n",
       "      <td>RFC</td>\n",
       "      <td>2023-07-25 20:20:00.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 21:00:08.007</td>\n",
       "      <td>33510</td>\n",
       "      <td>1</td>\n",
       "      <td>0x110C8A705ABC8068E95FDDB246019BC9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>7471</td>\n",
       "      <td>543</td>\n",
       "      <td>River Falls Municipal Utilities</td>\n",
       "      <td>401</td>\n",
       "      <td>River Falls Diesel</td>\n",
       "      <td>543401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>Internal Combustion/Reciprocating Engines</td>\n",
       "      <td>...</td>\n",
       "      <td>0x66E8C0CB9FFD5A87ADB7C6741B3A6BCD</td>\n",
       "      <td>MRO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2023-10-26 14:40:00.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-26 15:00:11.860</td>\n",
       "      <td>33916</td>\n",
       "      <td>1</td>\n",
       "      <td>0xE8F014721F7EBEDF6428982B7341D98F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UnitID UtilityCode                      UtilityName  UnitCode  \\\n",
       "294      2829         510            Edison Mission Energy       101   \n",
       "295      2830         510            Edison Mission Energy       102   \n",
       "296      2831         510            Edison Mission Energy       103   \n",
       "297      2832         510            Edison Mission Energy       104   \n",
       "298      2833         510            Edison Mission Energy       105   \n",
       "...       ...         ...                              ...       ...   \n",
       "9897     3392         506                   Exelon (ComEd)       125   \n",
       "9898     3393         506                   Exelon (ComEd)       126   \n",
       "9899     3394         506                   Exelon (ComEd)       127   \n",
       "9900     3395         506                   Exelon (ComEd)       128   \n",
       "10010    7471         543  River Falls Municipal Utilities       401   \n",
       "\n",
       "                 UnitName UtilityUnitCode  RatingMW  RatingMW_grp  \\\n",
       "294            COLLINS #1          510101     554.0           3.0   \n",
       "295            COLLINS #2          510102     554.0           3.0   \n",
       "296            COLLINS #3          510103     530.0           3.0   \n",
       "297            COLLINS #4          510104     530.0           3.0   \n",
       "298            COLLINS #5          510105     530.0           3.0   \n",
       "...                   ...             ...       ...           ...   \n",
       "9897         RIDGELAND #1          506125     160.0           2.0   \n",
       "9898         RIDGELAND #2          506126     160.0           2.0   \n",
       "9899         RIDGELAND #3          506127     160.0           2.0   \n",
       "9900         RIDGELAND #4          506128     160.0           2.0   \n",
       "10010  River Falls Diesel          543401       NaN           NaN   \n",
       "\n",
       "       UnitTypeCode                           UnitTypeCodeDesc  ...  \\\n",
       "294             100                               Fossil-Steam  ...   \n",
       "295             100                               Fossil-Steam  ...   \n",
       "296             100                               Fossil-Steam  ...   \n",
       "297             100                               Fossil-Steam  ...   \n",
       "298             100                               Fossil-Steam  ...   \n",
       "...             ...                                        ...  ...   \n",
       "9897            100                               Fossil-Steam  ...   \n",
       "9898            100                               Fossil-Steam  ...   \n",
       "9899            100                               Fossil-Steam  ...   \n",
       "9900            100                               Fossil-Steam  ...   \n",
       "10010           400  Internal Combustion/Reciprocating Engines  ...   \n",
       "\n",
       "                           NERCID_AliasID RegionCode  SubRegionName  \\\n",
       "294    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "295    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "296    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "297    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "298    0x3EB7A81A4A916415991F1222F16BEB36        RFC            RFC   \n",
       "...                                   ...        ...            ...   \n",
       "9897   0x7A934D0BCD299CBB52A3966013A53769        RFC            RFC   \n",
       "9898   0x7A934D0BCD299CBB52A3966013A53769        RFC            RFC   \n",
       "9899   0x7A934D0BCD299CBB52A3966013A53769        RFC            RFC   \n",
       "9900   0x7A934D0BCD299CBB52A3966013A53769        RFC            RFC   \n",
       "10010  0x66E8C0CB9FFD5A87ADB7C6741B3A6BCD        MRO            MRO   \n",
       "\n",
       "                  ExtractionDT DeletionDT          NERC_DataPullDT  ID_SK Rnk  \\\n",
       "294    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13084   1   \n",
       "295    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13085   1   \n",
       "296    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13086   1   \n",
       "297    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13087   1   \n",
       "298    2018-05-17 19:05:01.080        NaN  2018-05-17 20:00:05.287  13088   1   \n",
       "...                        ...        ...                      ...    ...  ..   \n",
       "9897   2023-07-25 20:20:00.200        NaN  2023-07-25 21:00:08.007  33507   1   \n",
       "9898   2023-07-25 20:20:00.200        NaN  2023-07-25 21:00:08.007  33508   1   \n",
       "9899   2023-07-25 20:20:00.200        NaN  2023-07-25 21:00:08.007  33509   1   \n",
       "9900   2023-07-25 20:20:00.200        NaN  2023-07-25 21:00:08.007  33510   1   \n",
       "10010  2023-10-26 14:40:00.097        NaN  2023-10-26 15:00:11.860  33916   1   \n",
       "\n",
       "                                  AliasID IsCurrent  \n",
       "294    0x3E22C8F14AC30EF4E3F90858F57917A1         1  \n",
       "295    0xA742DD440617C11B42B9E193110C83F4         1  \n",
       "296    0x92861ABF4F8815A455AA5518708660CC         1  \n",
       "297    0x38B27BFE548DF9F526A05221EEDDCC94         1  \n",
       "298    0x0802695A0C9BFFE68BC4B9761EB43EA0         1  \n",
       "...                                   ...       ...  \n",
       "9897   0xACD96BACE0F36E67E10D88053F324B9F         1  \n",
       "9898   0x141AC8E2E957E7F4B6BE018EB00C70EE         1  \n",
       "9899   0x83788DA62C59B57BD6DD616927661A63         1  \n",
       "9900   0x110C8A705ABC8068E95FDDB246019BC9         1  \n",
       "10010  0xE8F014721F7EBEDF6428982B7341D98F         1  \n",
       "\n",
       "[133 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfGadsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91b818cf-8afa-4172-8d62-e3367756e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of GADS db after filtering: 818, 40\n"
     ]
    }
   ],
   "source": [
    "dfGads = dfGads0.copy()\n",
    "# dfGads = dfGads[dfGads['CompanyName'].isin(companyNamesVelo2Gads)]\n",
    "# voltageClassesGads0 = set(dfGads['VoltageClassCodeName'])\n",
    "# print(voltageClassesGads0)\n",
    "# voltageClassesAllowedGads = voltageClassesGads0.copy()\n",
    "# voltageClassesAllowedGads.discard(\"0-99 kV\")\n",
    "\n",
    "# dfGads = dfGads[dfGads['VoltageClassCodeName'].isin(voltageClassesAllowedGads)]\n",
    "dfGads = filter_states(dfGads0)\n",
    "sizeGads = dfGads.shape\n",
    "print(f\"Size of GADS db after filtering: {sizeGads[0]}, {sizeGads[1]}\")\n",
    "\n",
    "# dfGadsSorted = sort_and_shift_columns(dfGads)\n",
    "\n",
    "# gadsSortedAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Sorted.xlsx\")\n",
    "\n",
    "# dfGadsSorted.to_excel(gadsSortedAddr, index=False)\n",
    "\n",
    "# # dfGadsLatest = filter_tlines_by_latest_reported_year(dfGadsSorted)\n",
    "# dfGadsLatest = get_latest_entries(dfGadsSorted)\n",
    "\n",
    "# sizeGadsLatest = dfGadsLatest.shape\n",
    "\n",
    "# print(f\"Size of GADS db after filtering for only latest reported year: {sizeGadsLatest[0]}, {sizeGadsLatest[1]}\")\n",
    "\n",
    "# gadsLatestAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Latest.xlsx\")\n",
    "\n",
    "# dfGadsLatest.to_excel(gadsLatestAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "434465a4-bd41-4a9c-b693-c190744096b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatch = filter_by_eia_code(dfVelo, dfGads)\n",
    "# dfMatch = get_matched_entries(dfVeloSorted, dfGadsLatest)\n",
    "# matchAddr = os.path.join(processedDataFolder, \"dfGads-Chicago-Ohare-Matched.xlsx\")\n",
    "matchAddr = os.path.join(\n",
    "    processedDataFolder, \"dfGads-\" + components + \"-\" + location + \"-Matched\" + ext\n",
    ")\n",
    "dfMatch.to_excel(matchAddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      32460\n",
       "1      11844\n",
       "2      11824\n",
       "3       8180\n",
       "4       8234\n",
       "       ...  \n",
       "286    28249\n",
       "287    28250\n",
       "288    28251\n",
       "289    22809\n",
       "290    10811\n",
       "Name: Rec_ID, Length: 291, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVelo['Rec_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3362acdf-ad3e-4bcf-8848-08eeb6311deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_states(dfGads, states_to_keep=[\"Illinois\", \"Indiana\", \"Wisconsin\"]):\n",
    "    # Define the list of state names to filter\n",
    "    # states_to_keep = [\"IL\", \"IN\", \"WI\"]\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    dfFiltered = dfGads[dfGads[\"StateName\"].isin(states_to_keep)]\n",
    "\n",
    "    return dfFiltered\n",
    "\n",
    "def filter_by_eia_code0(dfVelo, dfGads):\n",
    "    # Get the unique 'EIA ID' values from dfVelo\n",
    "    eia_ids = dfVelo[\"EIA ID\"].unique()\n",
    "\n",
    "    # Filter dfGads to include only rows where 'EIACode' is in the list of 'EIA ID' values\n",
    "    dfFiltered = dfGads[dfGads[\"EIACode\"].isin(eia_ids)]\n",
    "\n",
    "    return dfFiltered\n",
    "\n",
    "\n",
    "def filter_by_eia_code(dfVelo, dfGads):\n",
    "    # Merge the two DataFrames on 'EIA ID' and 'EIACode' columns\n",
    "    dfMerged = pd.merge(\n",
    "        dfGads,\n",
    "        dfVelo[[\"EIA ID\", \"Rec_ID\"]],\n",
    "        left_on=\"EIACode\",\n",
    "        right_on=\"EIA ID\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # Drop the duplicate 'EIA ID' column from the merge\n",
    "    dfFiltered = dfMerged.drop(columns=[\"EIA ID\"])\n",
    "\n",
    "    return dfFiltered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
